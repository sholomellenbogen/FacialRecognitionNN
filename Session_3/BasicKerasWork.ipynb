{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Science Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this session we want to familiarize ourselves with how to go from a dataset and a question to a model that can answer that question using machine learning; specifically Keras. This is squarely in the realm of data science, but as you will see these are techniques that you will want to add into your workflow.\n",
    "\n",
    "There are five basic steps that we will want to cover:\n",
    "  1. Initial data exploration\n",
    "    - visulizations, scatter plots, some dimensionality reduction, etc\n",
    "  2. Data clean up\n",
    "    - Organizing the data based on what it will be used for\n",
    "  3. Model building\n",
    "    - Making a predictive model based on the data if supervised learning\n",
    "  4. Model testing\n",
    "    - Does it actually work? does it generalize? does it need to?\n",
    "  5. Repeat from step 1 until satisfied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this work we'll be taking a look at the Fisher Iris dataset. As we go through the notebook I'll point out how to use numpy, matplotlib and keras to accomplish the goals we've set out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will _not_ be providing the dataset here. Instead I encourage you to find the Fisher Iris dataset in the wild."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal for today is to make a model that can use the features from the Fisher Iris dataset, to predict the species of the iris."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Initial Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you find the dataset name it data.tsv. Make sure it is a tab separated file with the following schema\n",
    "\n",
    "Dataset Order (int, unique), Sepal Length (float), Sepal Width (float), Petal Length (float), Petal Width (float), Class (string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll have to load in the file to do some work with it. In python this is easy to do with the _open_ built-in function. It takes as arguments the name of the file and the mode: reading, writing, appending.\n",
    "\n",
    "Instead of manually closing the file, we will use the _with_ keyword to make a context manager that will automaticall close the file when we're done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.tsv') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all the lines in a list, we can print a line to see what we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'150\\t5.9\\t3\\t5.1\\t1.8\\tvirginica\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[149]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should clean it up. We won't need the dataset order, so we can throw that away, and we should make our four features into numbers so that we can start plotting. Having the species as a string is fine, but it would be more useful to assing a number to each species."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do all of these things, I recommend taking a look at the string method _split_. We should be able to split each string along the '\\t', so that each line will then be a list. Then we should turn all the features into floats using the _float_ built-in function. This should work if the string looks like a number. Lastly we should turn the strings into integers.\n",
    "\n",
    "You should implement that yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for line in lines:\n",
    "    # Split the string\n",
    "    parts = line.split(\"\\t\")\n",
    "#     print(parts[5])\n",
    "    # Go through each of the parts and turn them into floats\n",
    "    sepal_lenth = float(parts[1])\n",
    "    sepal_width = float(parts[2])\n",
    "    petal_length = float(parts[3])\n",
    "    petal_width = float(parts[4])\n",
    "    \n",
    "#     # Make the species name into an integer\n",
    "    if \"setosa\" in parts[5] : \n",
    "        species = 0\n",
    "    elif \"virginica\" in parts[5] : \n",
    "        species=1\n",
    "    else : \n",
    "        species=2\n",
    "    \n",
    "#     # Append everything into the data list\n",
    "    data.append( [sepal_lenth, sepal_width, petal_length, petal_width, species] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy arrays are incredible useful data types (though Pandas data-frames are becoming more and more popular). We will turn the data into a numpy array for easy indexing. Before that we need to import the library into workspace, and give it the short name np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to do some visulizations. For this we'll use matplotlib's pyplot interface. If you've ever used MATLAB then this will look familiar. Again we need to import this first, and give it a short name (for convenience). When in a jupyter notebook, we also need to insert the magic command _%matplotlib inline_, to make sure that our plots show up in line in our notebook. This substitutes the show command that we would normally have to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can move on to do some numpy indexing. We index numpy arrays with square brackets []. If the array has more than one dimension, then we can use a comma to index each dimension. What's really nice is that we can use the colon : to fetch all the elements of that dimension.\n",
    "\n",
    "So for example _array[:,0]_, will fetch all the elements in the first dimension, and then grab the first element from that list. _array[4,:]_ will fetch all the elements of the second dimension, and then grab the fifth element of the first dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anyways, we want to plot the data, to see what we're dealing with. We'll be doing that using a scatter plot. We want to choose the color of the dot depending on the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(data.shape[0]):\n",
    "    datum = data[i,:]\n",
    "    if datum[-1]==0:\n",
    "        color = 'blue'\n",
    "    elif datum[-1]==1:\n",
    "        color = 'red'\n",
    "    elif datum[-1]==2:\n",
    "        color = 'green'\n",
    "    else:\n",
    "        print('There is somehting wrong with your class labels')\n",
    "        continue\n",
    "    plt.scatter(datum[0], datum[1], color=color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can grab the code above and try to do plots using the other feature combinations. Alternatively you can come up with much shorter code to make the same plots (one way is with numpy fancy mask indexing, or realizing that the data is already orgnized by class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A small aside on how to use jupyter notebooks\n",
    "You can press _esc_ to enter command mode. In command mode you can do lots in neat things, like copying and pasting entire cells (move to it with the arrows keys, press c, and then v), enter markdown mode (press m) [incidentally, this is how I write these cells], delete celss (press d twice), and many others. The help button has a keyboard shortcuts menu with more.\n",
    "\n",
    "#### End aside"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a general idea of what the data looks like, we can start forming some intuition. It is very clear that one of the classes is linearly separable, while the other might not even be non-linearly separable. This is good to know, it sets expectations for what might be possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Data clean up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've already done some pre-processing to get the data into a plotable format, but depending on what kind of model we want to use we might need to do some more clean up.\n",
    "Since we're planning on using an MLP, we will want to make the data array X, and the label array Y. These need to have shapes of (number of examples, number of features) for X, and (number of examples, 3) for Y.\n",
    "\n",
    "After we've done that, we'll actually want to _normalize_ or _whiten_ the data. Normalization is any procedure to constraint the values of the data into a regime that is good for our network. Generally people choose to transform the data so that the smallest value for each feature is 0 and the highest is 1.\n",
    "\n",
    "Whitening, is a similar idea, but instead, we're looking to have the data have a mean of 0 and a standard deviation of 1 (ie be the stereotypical normal distribution). We can do this using numpy to find the mean and standard deviation of each feature, and then subtracting the mean and dividing by the standard deviation.\n",
    "\n",
    "For now I'd recommend going with normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the labels, we actually want to make this into a one-hot encoding. This means that if we have class 0 we want to have the label [1, 0, 0], class 1 label [0, 1, 0] and class 2 label [0, 0, 1]. Keras has functions that can do this for us, but I'll show a naive way of doing the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1) Make the data (X) and label (Y) arrays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X is (150, 4)\n",
      "The shape of Y is (150,)\n"
     ]
    }
   ],
   "source": [
    "X = data[:,0:4]\n",
    "Y = data[:,4]\n",
    "\n",
    "print('The shape of X is {}'.format(X.shape))\n",
    "print('The shape of Y is {}'.format(Y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the shape is not quite correct for the label array. We can fix this by using the reshape method. So long as the product of the shape dimensions is equal, you can have reshape the array. For example:\n",
    "\n",
    "z is shape (10,4)\n",
    "you can reshape it to:\n",
    "  - (2,5,4)\n",
    "  - (10, 2, 2)\n",
    "  - (20,2)\n",
    "  - (1,10,4)\n",
    "\n",
    "but not to:\n",
    "  - (5,16)\n",
    "  - (3,5,4)\n",
    "  - (1,1,41)\n",
    "  \n",
    "This is just useful to know.\n",
    "\n",
    "You should always, double check that the array in the new form still has a shape that makes sense to you!\n",
    "If you understand how C-arrays work, then the re-shaping makes some sense, but always always double check, don't assume!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ys = []\n",
    "# for label in Y:\n",
    "#     if label==0:\n",
    "#         ys.append([1,0,0])\n",
    "#     elif label==1:\n",
    "#         ys.append([0,1,0])\n",
    "#     elif label==2:\n",
    "#         ys.append([0,0,1])\n",
    "#     else:\n",
    "#         print('Somthing is wrong with your labels!')\n",
    "#         continue\n",
    "\n",
    "# Y = np.array(ys)\n",
    "# print('The shape of Y is {}'.format(Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of Y is (150, 3)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import utils\n",
    "if Y.shape != (150,3) :\n",
    "    Y = utils.to_categorical(Y, num_classes=3)\n",
    "print('The shape of Y is {}'.format(Y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to normalize our features. For each feature we should find the min, and the max. Then subtract the min from all and then divide the max (if it's not clear why this is true, then pull a sheet of paper and prove it to yourself.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this for all the features at once! We can ask numpy to find the min and max for each feature, and then using NumPy's broadcasting rules subtract and divide for all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The feature-wise min [4.3 2.  1.  0.1]\n"
     ]
    }
   ],
   "source": [
    "minimum = np.min(X, axis=0) # We want the first axis (axis=0) to collapse the first dimension\n",
    "print('The feature-wise min {}'.format(minimum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The feature-wise max [7.9 4.4 6.9 2.5]\n"
     ]
    }
   ],
   "source": [
    "maximum = np.max(X, axis=0) # We want the first axis (axis=0) to collapse the first dimension\n",
    "print('The feature-wise max {}'.format(maximum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use broadcasting. When numpy sees you doing math with arrays that are not the same shape, it tries to expand the smaller array to be the same shape as the larger array. It will do this by copying the smaller array over and over. In our case we have the data array with shape (150,4) and the minimum array with shape (4,). Numpy will broadcast the minimum array to (150,4), so we can actually do the arithmetic.\n",
    "\n",
    "Broadcasting is really useful to save yourself dozens of lines of code, but it sucks when it happens and you don't know! You should always have a mental map of how big your arrays are, and what shapes they have so that you are not surprised!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (X - minimum)/maximum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to start building our predictive model. To do that we will be using Keras. Again we have to import it, but this time we will be importing only the pieces we need. Keras has really good documentation, that I strongly recommened you read at their site [Keras.io](https://www.Keras.io)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()  # Make the scaffold for a sequential model (go from one layer straight into the next)\n",
    "\n",
    "# model.add(Dense(10, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# Add a dense layer (typical NN layer) with ten neurons, and a sigmoid activation function\n",
    "# For the first layer of each keras model you need to specify what shape the data examples will have\n",
    "model.add( Dense(5, input_shape=(4,), activation='sigmoid') )\n",
    "\n",
    "# We can add as many layers as we want using the same syntax.\n",
    "# After the first layer Keras can auto cast the shapes from one layer to the next\n",
    "model.add( Dense(5, activation='sigmoid') )\n",
    "\n",
    "# For our last layer we need to have Dense layer have as many outputs as we need\n",
    "model.add( Dense(3, activation='softmax') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are choosing the softmax activation to normalize the output at the end (the sum of the last array will always be one). This is preparation of using cross entropy as our loss function to force our model to learn a probabily distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we have our model, we need to _compile_ it. Keras will actually write C++ code for us and compile it. This is usually a 100 fold speed up from raw Python. If you have a GPU and installed the gpu version of tensorflow as your Keras backend you can get an extra 10 to a 100 fold speed up as well.\n",
    "\n",
    "We have to tell Keras what loss function we will want to minimize and also want optimization algorithm to use. For now we will use the default categorical crossentropy and the stochastic gradient descent. You can always tweak the defaults yourself, or even make your own. We will also ask Keras to keep track of an extra metric: the accuracy. This won't be used for training but it will give us a good sense of how our model is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a compiled model we need to train it. To do so we need to provide it data. Keras makes it easy to do this by using the _fit_ method. It is also good practice to have a testing set. This is a set of data that will not be used in the training of the model, but that we will use to see how well the model generalizes. Keras also makes it easy by letting us supply our own testing data, or asking the fit method to split our data into a training and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/2000\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 1.1211 - acc: 0.2593 - val_loss: 1.0094 - val_acc: 1.0000\n",
      "Epoch 2/2000\n",
      "135/135 [==============================] - 0s 471us/step - loss: 1.1094 - acc: 0.2889 - val_loss: 1.0716 - val_acc: 1.0000\n",
      "Epoch 3/2000\n",
      "135/135 [==============================] - 0s 407us/step - loss: 1.1027 - acc: 0.0963 - val_loss: 1.1222 - val_acc: 0.0000e+00\n",
      "Epoch 4/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 1.0980 - acc: 0.1704 - val_loss: 1.1641 - val_acc: 0.0000e+00\n",
      "Epoch 5/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 1.0953 - acc: 0.0593 - val_loss: 1.1974 - val_acc: 0.0000e+00\n",
      "Epoch 6/2000\n",
      "135/135 [==============================] - 0s 391us/step - loss: 1.0939 - acc: 0.0741 - val_loss: 1.2203 - val_acc: 0.0000e+00\n",
      "Epoch 7/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 1.0931 - acc: 0.2519 - val_loss: 1.2404 - val_acc: 0.0000e+00\n",
      "Epoch 8/2000\n",
      "135/135 [==============================] - 0s 406us/step - loss: 1.0922 - acc: 0.0444 - val_loss: 1.2564 - val_acc: 0.0000e+00\n",
      "Epoch 9/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 1.0915 - acc: 0.0074 - val_loss: 1.2722 - val_acc: 0.0000e+00\n",
      "Epoch 10/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 1.0910 - acc: 0.0963 - val_loss: 1.2840 - val_acc: 0.0000e+00\n",
      "Epoch 11/2000\n",
      "135/135 [==============================] - 0s 503us/step - loss: 1.0911 - acc: 0.0815 - val_loss: 1.2933 - val_acc: 0.0000e+00\n",
      "Epoch 12/2000\n",
      "135/135 [==============================] - 0s 407us/step - loss: 1.0908 - acc: 0.1481 - val_loss: 1.3012 - val_acc: 0.0000e+00\n",
      "Epoch 13/2000\n",
      "135/135 [==============================] - 0s 399us/step - loss: 1.0905 - acc: 0.0074 - val_loss: 1.3042 - val_acc: 0.0000e+00\n",
      "Epoch 14/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 1.0905 - acc: 0.0296 - val_loss: 1.3090 - val_acc: 0.0000e+00\n",
      "Epoch 15/2000\n",
      "135/135 [==============================] - 0s 399us/step - loss: 1.0903 - acc: 0.0444 - val_loss: 1.3121 - val_acc: 0.0000e+00\n",
      "Epoch 16/2000\n",
      "135/135 [==============================] - 0s 399us/step - loss: 1.0902 - acc: 0.0148 - val_loss: 1.3136 - val_acc: 0.0000e+00\n",
      "Epoch 17/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 1.0898 - acc: 0.3259 - val_loss: 1.3143 - val_acc: 0.0000e+00\n",
      "Epoch 18/2000\n",
      "135/135 [==============================] - 0s 399us/step - loss: 1.0897 - acc: 0.0519 - val_loss: 1.3125 - val_acc: 0.0000e+00\n",
      "Epoch 19/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 1.0901 - acc: 0.1704 - val_loss: 1.3147 - val_acc: 0.0000e+00\n",
      "Epoch 20/2000\n",
      "135/135 [==============================] - 0s 407us/step - loss: 1.0898 - acc: 0.0963 - val_loss: 1.3171 - val_acc: 0.0000e+00\n",
      "Epoch 21/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 1.0893 - acc: 0.0148 - val_loss: 1.3192 - val_acc: 0.0000e+00\n",
      "Epoch 22/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 1.0897 - acc: 0.0667 - val_loss: 1.3207 - val_acc: 0.0000e+00\n",
      "Epoch 23/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 1.0891 - acc: 0.0370 - val_loss: 1.3190 - val_acc: 0.0000e+00\n",
      "Epoch 24/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 1.0894 - acc: 0.0370 - val_loss: 1.3166 - val_acc: 0.0000e+00\n",
      "Epoch 25/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 1.0888 - acc: 0.1259 - val_loss: 1.3183 - val_acc: 0.0000e+00\n",
      "Epoch 26/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 1.0888 - acc: 0.0000e+00 - val_loss: 1.3189 - val_acc: 0.0000e+00\n",
      "Epoch 27/2000\n",
      "135/135 [==============================] - 0s 399us/step - loss: 1.0889 - acc: 0.0741 - val_loss: 1.3201 - val_acc: 0.0000e+00\n",
      "Epoch 28/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 1.0884 - acc: 0.2074 - val_loss: 1.3172 - val_acc: 0.0000e+00\n",
      "Epoch 29/2000\n",
      "135/135 [==============================] - 0s 406us/step - loss: 1.0880 - acc: 0.1111 - val_loss: 1.3182 - val_acc: 0.0000e+00\n",
      "Epoch 30/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 1.0884 - acc: 0.1037 - val_loss: 1.3192 - val_acc: 0.0000e+00\n",
      "Epoch 31/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 1.0887 - acc: 0.2519 - val_loss: 1.3207 - val_acc: 0.0000e+00\n",
      "Epoch 32/2000\n",
      "135/135 [==============================] - 0s 406us/step - loss: 1.0880 - acc: 0.1185 - val_loss: 1.3214 - val_acc: 0.0000e+00\n",
      "Epoch 33/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 1.0880 - acc: 0.0741 - val_loss: 1.3196 - val_acc: 0.0000e+00\n",
      "Epoch 34/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 1.0883 - acc: 0.1111 - val_loss: 1.3207 - val_acc: 0.0000e+00\n",
      "Epoch 35/2000\n",
      "135/135 [==============================] - 0s 348us/step - loss: 1.0877 - acc: 0.0815 - val_loss: 1.3219 - val_acc: 0.0000e+00\n",
      "Epoch 36/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 1.0878 - acc: 0.1259 - val_loss: 1.3182 - val_acc: 0.0000e+00\n",
      "Epoch 37/2000\n",
      "135/135 [==============================] - 0s 414us/step - loss: 1.0874 - acc: 0.1556 - val_loss: 1.3162 - val_acc: 0.0000e+00\n",
      "Epoch 38/2000\n",
      "135/135 [==============================] - 0s 399us/step - loss: 1.0881 - acc: 0.0519 - val_loss: 1.3136 - val_acc: 0.0000e+00\n",
      "Epoch 39/2000\n",
      "135/135 [==============================] - 0s 406us/step - loss: 1.0873 - acc: 0.0593 - val_loss: 1.3110 - val_acc: 0.0000e+00\n",
      "Epoch 40/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 1.0871 - acc: 0.1259 - val_loss: 1.3137 - val_acc: 0.0000e+00\n",
      "Epoch 41/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 1.0865 - acc: 0.0074 - val_loss: 1.3152 - val_acc: 0.0000e+00\n",
      "Epoch 42/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 1.0867 - acc: 0.2815 - val_loss: 1.3129 - val_acc: 0.0000e+00\n",
      "Epoch 43/2000\n",
      "135/135 [==============================] - 0s 303us/step - loss: 1.0866 - acc: 0.1259 - val_loss: 1.3149 - val_acc: 0.0000e+00\n",
      "Epoch 44/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 1.0863 - acc: 0.0667 - val_loss: 1.3148 - val_acc: 0.0000e+00\n",
      "Epoch 45/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 1.0869 - acc: 0.0296 - val_loss: 1.3140 - val_acc: 0.0000e+00\n",
      "Epoch 46/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 1.0860 - acc: 0.0889 - val_loss: 1.3155 - val_acc: 0.0000e+00\n",
      "Epoch 47/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 1.0860 - acc: 0.2815 - val_loss: 1.3094 - val_acc: 0.0000e+00\n",
      "Epoch 48/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 1.0866 - acc: 0.0963 - val_loss: 1.3118 - val_acc: 0.0000e+00\n",
      "Epoch 49/2000\n",
      "135/135 [==============================] - 0s 406us/step - loss: 1.0863 - acc: 0.0519 - val_loss: 1.3113 - val_acc: 0.0000e+00\n",
      "Epoch 50/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 1.0854 - acc: 0.0519 - val_loss: 1.3108 - val_acc: 0.0000e+00\n",
      "Epoch 51/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 1.0858 - acc: 0.1185 - val_loss: 1.3129 - val_acc: 0.0000e+00\n",
      "Epoch 52/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 1.0853 - acc: 0.0222 - val_loss: 1.3116 - val_acc: 0.0000e+00\n",
      "Epoch 53/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 1.0855 - acc: 0.1704 - val_loss: 1.3140 - val_acc: 0.0000e+00\n",
      "Epoch 54/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 1.0859 - acc: 0.0519 - val_loss: 1.3095 - val_acc: 0.0000e+00\n",
      "Epoch 55/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 1.0852 - acc: 0.0222 - val_loss: 1.3077 - val_acc: 0.0000e+00\n",
      "Epoch 56/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 1.0851 - acc: 0.1926 - val_loss: 1.3059 - val_acc: 0.0000e+00\n",
      "Epoch 57/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 1.0848 - acc: 0.0815 - val_loss: 1.3081 - val_acc: 0.0000e+00\n",
      "Epoch 58/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 1.0849 - acc: 0.0519 - val_loss: 1.3122 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 1.0842 - acc: 0.0667 - val_loss: 1.3090 - val_acc: 0.0000e+00\n",
      "Epoch 60/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 1.0845 - acc: 0.0667 - val_loss: 1.3077 - val_acc: 0.0000e+00\n",
      "Epoch 61/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 1.0844 - acc: 0.0074 - val_loss: 1.3101 - val_acc: 0.0000e+00\n",
      "Epoch 62/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 1.0848 - acc: 0.1407 - val_loss: 1.3126 - val_acc: 0.0000e+00\n",
      "Epoch 63/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 1.0837 - acc: 0.0889 - val_loss: 1.3149 - val_acc: 0.0000e+00\n",
      "Epoch 64/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 1.0845 - acc: 0.2370 - val_loss: 1.3136 - val_acc: 0.0000e+00\n",
      "Epoch 65/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 1.0848 - acc: 0.0667 - val_loss: 1.3143 - val_acc: 0.0000e+00\n",
      "Epoch 66/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 1.0832 - acc: 0.0148 - val_loss: 1.3122 - val_acc: 0.0000e+00\n",
      "Epoch 67/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 1.0834 - acc: 0.0963 - val_loss: 1.3121 - val_acc: 0.0000e+00\n",
      "Epoch 68/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 1.0837 - acc: 0.0148 - val_loss: 1.3123 - val_acc: 0.0000e+00\n",
      "Epoch 69/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 1.0833 - acc: 0.2222 - val_loss: 1.3114 - val_acc: 0.0000e+00\n",
      "Epoch 70/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 1.0828 - acc: 0.0444 - val_loss: 1.3095 - val_acc: 0.0000e+00\n",
      "Epoch 71/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 1.0834 - acc: 0.0667 - val_loss: 1.3109 - val_acc: 0.0000e+00\n",
      "Epoch 72/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 1.0829 - acc: 0.3037 - val_loss: 1.3090 - val_acc: 0.0000e+00\n",
      "Epoch 73/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 1.0830 - acc: 0.1259 - val_loss: 1.3042 - val_acc: 0.0000e+00\n",
      "Epoch 74/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 1.0818 - acc: 0.0370 - val_loss: 1.3034 - val_acc: 0.0000e+00\n",
      "Epoch 75/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 1.0819 - acc: 0.0444 - val_loss: 1.3045 - val_acc: 0.0000e+00\n",
      "Epoch 76/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 1.0820 - acc: 0.1259 - val_loss: 1.3070 - val_acc: 0.0000e+00\n",
      "Epoch 77/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 1.0820 - acc: 0.1333 - val_loss: 1.3086 - val_acc: 0.0000e+00\n",
      "Epoch 78/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 1.0815 - acc: 0.0963 - val_loss: 1.3074 - val_acc: 0.0000e+00\n",
      "Epoch 79/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 1.0817 - acc: 0.1556 - val_loss: 1.3067 - val_acc: 0.0000e+00\n",
      "Epoch 80/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 1.0814 - acc: 0.1481 - val_loss: 1.3048 - val_acc: 0.0000e+00\n",
      "Epoch 81/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 1.0807 - acc: 0.0741 - val_loss: 1.3053 - val_acc: 0.0000e+00\n",
      "Epoch 82/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 1.0809 - acc: 0.2741 - val_loss: 1.3044 - val_acc: 0.0000e+00\n",
      "Epoch 83/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 1.0816 - acc: 0.1037 - val_loss: 1.3030 - val_acc: 0.0000e+00\n",
      "Epoch 84/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 1.0813 - acc: 0.0370 - val_loss: 1.3067 - val_acc: 0.0000e+00\n",
      "Epoch 85/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 1.0808 - acc: 0.2741 - val_loss: 1.3062 - val_acc: 0.0000e+00\n",
      "Epoch 86/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 1.0804 - acc: 0.0593 - val_loss: 1.3029 - val_acc: 0.0000e+00\n",
      "Epoch 87/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 1.0804 - acc: 0.0074 - val_loss: 1.3025 - val_acc: 0.0000e+00\n",
      "Epoch 88/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 1.0799 - acc: 0.0963 - val_loss: 1.3006 - val_acc: 0.0000e+00\n",
      "Epoch 89/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 1.0811 - acc: 0.2000 - val_loss: 1.3001 - val_acc: 0.0000e+00\n",
      "Epoch 90/2000\n",
      "135/135 [==============================] - 0s 399us/step - loss: 1.0804 - acc: 0.1037 - val_loss: 1.3016 - val_acc: 0.0000e+00\n",
      "Epoch 91/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 1.0803 - acc: 0.0148 - val_loss: 1.3018 - val_acc: 0.0000e+00\n",
      "Epoch 92/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 1.0801 - acc: 0.0593 - val_loss: 1.2995 - val_acc: 0.0000e+00\n",
      "Epoch 93/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 1.0803 - acc: 0.0963 - val_loss: 1.2987 - val_acc: 0.0000e+00\n",
      "Epoch 94/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 1.0794 - acc: 0.1111 - val_loss: 1.2979 - val_acc: 0.0000e+00\n",
      "Epoch 95/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 1.0794 - acc: 0.0074 - val_loss: 1.2970 - val_acc: 0.0000e+00\n",
      "Epoch 96/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 1.0787 - acc: 0.1704 - val_loss: 1.2945 - val_acc: 0.0000e+00\n",
      "Epoch 97/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 1.0786 - acc: 0.0667 - val_loss: 1.2940 - val_acc: 0.0000e+00\n",
      "Epoch 98/2000\n",
      "135/135 [==============================] - 0s 414us/step - loss: 1.0785 - acc: 0.1185 - val_loss: 1.2952 - val_acc: 0.0000e+00\n",
      "Epoch 99/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 1.0782 - acc: 0.0296 - val_loss: 1.2953 - val_acc: 0.0000e+00\n",
      "Epoch 100/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 1.0784 - acc: 0.2296 - val_loss: 1.2943 - val_acc: 0.0000e+00\n",
      "Epoch 101/2000\n",
      "135/135 [==============================] - 0s 414us/step - loss: 1.0777 - acc: 0.1481 - val_loss: 1.2926 - val_acc: 0.0000e+00\n",
      "Epoch 102/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 1.0784 - acc: 0.1630 - val_loss: 1.2951 - val_acc: 0.0000e+00\n",
      "Epoch 103/2000\n",
      "135/135 [==============================] - 0s 310us/step - loss: 1.0777 - acc: 0.3037 - val_loss: 1.2965 - val_acc: 0.0000e+00\n",
      "Epoch 104/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 1.0777 - acc: 0.1556 - val_loss: 1.2965 - val_acc: 0.0000e+00\n",
      "Epoch 105/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 1.0774 - acc: 0.1481 - val_loss: 1.2956 - val_acc: 0.0000e+00\n",
      "Epoch 106/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 1.0781 - acc: 0.0148 - val_loss: 1.2941 - val_acc: 0.0000e+00\n",
      "Epoch 107/2000\n",
      "135/135 [==============================] - 0s 406us/step - loss: 1.0767 - acc: 0.1704 - val_loss: 1.2944 - val_acc: 0.0000e+00\n",
      "Epoch 108/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 1.0767 - acc: 0.0889 - val_loss: 1.2953 - val_acc: 0.0000e+00\n",
      "Epoch 109/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 1.0764 - acc: 0.0889 - val_loss: 1.2961 - val_acc: 0.0000e+00\n",
      "Epoch 110/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 1.0769 - acc: 0.0963 - val_loss: 1.2939 - val_acc: 0.0000e+00\n",
      "Epoch 111/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 1.0760 - acc: 0.1630 - val_loss: 1.2916 - val_acc: 0.0000e+00\n",
      "Epoch 112/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 1.0764 - acc: 0.1185 - val_loss: 1.2933 - val_acc: 0.0000e+00\n",
      "Epoch 113/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 1.0754 - acc: 0.1481 - val_loss: 1.2926 - val_acc: 0.0000e+00\n",
      "Epoch 114/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 1.0760 - acc: 0.1037 - val_loss: 1.2925 - val_acc: 0.0000e+00\n",
      "Epoch 115/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 1.0753 - acc: 0.1185 - val_loss: 1.2935 - val_acc: 0.0000e+00\n",
      "Epoch 116/2000\n",
      "135/135 [==============================] - 0s 318us/step - loss: 1.0754 - acc: 0.2370 - val_loss: 1.2927 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 1.0746 - acc: 0.0815 - val_loss: 1.2950 - val_acc: 0.0000e+00\n",
      "Epoch 118/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 1.0745 - acc: 0.1630 - val_loss: 1.2938 - val_acc: 0.0000e+00\n",
      "Epoch 119/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 1.0742 - acc: 0.1704 - val_loss: 1.2900 - val_acc: 0.0000e+00\n",
      "Epoch 120/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 1.0737 - acc: 0.2593 - val_loss: 1.2884 - val_acc: 0.0000e+00\n",
      "Epoch 121/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 1.0740 - acc: 0.1185 - val_loss: 1.2846 - val_acc: 0.0000e+00\n",
      "Epoch 122/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 1.0740 - acc: 0.0889 - val_loss: 1.2847 - val_acc: 0.0000e+00\n",
      "Epoch 123/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 1.0735 - acc: 0.1185 - val_loss: 1.2833 - val_acc: 0.0000e+00\n",
      "Epoch 124/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 1.0735 - acc: 0.3037 - val_loss: 1.2845 - val_acc: 0.0000e+00\n",
      "Epoch 125/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 1.0728 - acc: 0.1556 - val_loss: 1.2826 - val_acc: 0.0000e+00\n",
      "Epoch 126/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 1.0727 - acc: 0.2667 - val_loss: 1.2820 - val_acc: 0.0000e+00\n",
      "Epoch 127/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 1.0727 - acc: 0.2000 - val_loss: 1.2862 - val_acc: 0.0000e+00\n",
      "Epoch 128/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 1.0724 - acc: 0.1481 - val_loss: 1.2837 - val_acc: 0.0000e+00\n",
      "Epoch 129/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 1.0717 - acc: 0.1185 - val_loss: 1.2816 - val_acc: 0.0000e+00\n",
      "Epoch 130/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 1.0711 - acc: 0.0741 - val_loss: 1.2810 - val_acc: 0.0000e+00\n",
      "Epoch 131/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 1.0709 - acc: 0.0370 - val_loss: 1.2824 - val_acc: 0.0000e+00\n",
      "Epoch 132/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 1.0711 - acc: 0.2148 - val_loss: 1.2836 - val_acc: 0.0000e+00\n",
      "Epoch 133/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 1.0706 - acc: 0.1259 - val_loss: 1.2831 - val_acc: 0.0000e+00\n",
      "Epoch 134/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 1.0714 - acc: 0.0741 - val_loss: 1.2828 - val_acc: 0.0000e+00\n",
      "Epoch 135/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 1.0706 - acc: 0.1259 - val_loss: 1.2803 - val_acc: 0.0000e+00\n",
      "Epoch 136/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 1.0699 - acc: 0.1630 - val_loss: 1.2792 - val_acc: 0.0000e+00\n",
      "Epoch 137/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 1.0703 - acc: 0.2222 - val_loss: 1.2768 - val_acc: 0.0000e+00\n",
      "Epoch 138/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 1.0690 - acc: 0.1704 - val_loss: 1.2737 - val_acc: 0.0000e+00\n",
      "Epoch 139/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 1.0695 - acc: 0.2074 - val_loss: 1.2708 - val_acc: 0.0000e+00\n",
      "Epoch 140/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 1.0688 - acc: 0.2296 - val_loss: 1.2715 - val_acc: 0.0000e+00\n",
      "Epoch 141/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 1.0688 - acc: 0.2815 - val_loss: 1.2734 - val_acc: 0.0000e+00\n",
      "Epoch 142/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 1.0683 - acc: 0.0963 - val_loss: 1.2779 - val_acc: 0.0000e+00\n",
      "Epoch 143/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 1.0678 - acc: 0.2667 - val_loss: 1.2788 - val_acc: 0.0000e+00\n",
      "Epoch 144/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 1.0675 - acc: 0.1481 - val_loss: 1.2786 - val_acc: 0.0000e+00\n",
      "Epoch 145/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 1.0673 - acc: 0.2148 - val_loss: 1.2763 - val_acc: 0.0000e+00\n",
      "Epoch 146/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 1.0673 - acc: 0.1704 - val_loss: 1.2719 - val_acc: 0.0000e+00\n",
      "Epoch 147/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 1.0671 - acc: 0.2963 - val_loss: 1.2693 - val_acc: 0.0000e+00\n",
      "Epoch 148/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 1.0659 - acc: 0.1926 - val_loss: 1.2680 - val_acc: 0.0000e+00\n",
      "Epoch 149/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 1.0665 - acc: 0.1481 - val_loss: 1.2677 - val_acc: 0.0000e+00\n",
      "Epoch 150/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 1.0664 - acc: 0.0519 - val_loss: 1.2702 - val_acc: 0.0000e+00\n",
      "Epoch 151/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 1.0651 - acc: 0.2815 - val_loss: 1.2703 - val_acc: 0.0000e+00\n",
      "Epoch 152/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 1.0652 - acc: 0.2667 - val_loss: 1.2690 - val_acc: 0.0000e+00\n",
      "Epoch 153/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 1.0651 - acc: 0.2519 - val_loss: 1.2702 - val_acc: 0.0000e+00\n",
      "Epoch 154/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 1.0642 - acc: 0.3185 - val_loss: 1.2698 - val_acc: 0.0000e+00\n",
      "Epoch 155/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 1.0642 - acc: 0.2963 - val_loss: 1.2731 - val_acc: 0.0000e+00\n",
      "Epoch 156/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 1.0639 - acc: 0.2222 - val_loss: 1.2715 - val_acc: 0.0000e+00\n",
      "Epoch 157/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 1.0631 - acc: 0.2444 - val_loss: 1.2678 - val_acc: 0.0000e+00\n",
      "Epoch 158/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 1.0626 - acc: 0.2667 - val_loss: 1.2674 - val_acc: 0.0000e+00\n",
      "Epoch 159/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 1.0622 - acc: 0.3185 - val_loss: 1.2664 - val_acc: 0.0000e+00\n",
      "Epoch 160/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 1.0620 - acc: 0.2667 - val_loss: 1.2678 - val_acc: 0.0000e+00\n",
      "Epoch 161/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 1.0616 - acc: 0.2963 - val_loss: 1.2668 - val_acc: 0.0000e+00\n",
      "Epoch 162/2000\n",
      "135/135 [==============================] - 0s 318us/step - loss: 1.0614 - acc: 0.3481 - val_loss: 1.2666 - val_acc: 0.0000e+00\n",
      "Epoch 163/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 1.0612 - acc: 0.2222 - val_loss: 1.2666 - val_acc: 0.0000e+00\n",
      "Epoch 164/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 1.0605 - acc: 0.3259 - val_loss: 1.2661 - val_acc: 0.0000e+00\n",
      "Epoch 165/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 1.0602 - acc: 0.2963 - val_loss: 1.2669 - val_acc: 0.0000e+00\n",
      "Epoch 166/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 1.0603 - acc: 0.2519 - val_loss: 1.2642 - val_acc: 0.0000e+00\n",
      "Epoch 167/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 1.0594 - acc: 0.3037 - val_loss: 1.2601 - val_acc: 0.0000e+00\n",
      "Epoch 168/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 1.0586 - acc: 0.3333 - val_loss: 1.2589 - val_acc: 0.0000e+00\n",
      "Epoch 169/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 1.0582 - acc: 0.2889 - val_loss: 1.2608 - val_acc: 0.0000e+00\n",
      "Epoch 170/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 1.0578 - acc: 0.3481 - val_loss: 1.2571 - val_acc: 0.0000e+00\n",
      "Epoch 171/2000\n",
      "135/135 [==============================] - 0s 399us/step - loss: 1.0575 - acc: 0.3407 - val_loss: 1.2555 - val_acc: 0.0000e+00\n",
      "Epoch 172/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 1.0568 - acc: 0.2815 - val_loss: 1.2526 - val_acc: 0.0000e+00\n",
      "Epoch 173/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 1.0565 - acc: 0.3407 - val_loss: 1.2496 - val_acc: 0.0000e+00\n",
      "Epoch 174/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 1.0570 - acc: 0.3259 - val_loss: 1.2543 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 1.0555 - acc: 0.3111 - val_loss: 1.2529 - val_acc: 0.0000e+00\n",
      "Epoch 176/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 1.0551 - acc: 0.3704 - val_loss: 1.2545 - val_acc: 0.0000e+00\n",
      "Epoch 177/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 1.0549 - acc: 0.3185 - val_loss: 1.2521 - val_acc: 0.0000e+00\n",
      "Epoch 178/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 1.0543 - acc: 0.4074 - val_loss: 1.2535 - val_acc: 0.0000e+00\n",
      "Epoch 179/2000\n",
      "135/135 [==============================] - 0s 323us/step - loss: 1.0536 - acc: 0.3630 - val_loss: 1.2560 - val_acc: 0.0000e+00\n",
      "Epoch 180/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 1.0529 - acc: 0.3778 - val_loss: 1.2518 - val_acc: 0.0000e+00\n",
      "Epoch 181/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 1.0529 - acc: 0.4148 - val_loss: 1.2498 - val_acc: 0.0000e+00\n",
      "Epoch 182/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 1.0519 - acc: 0.3778 - val_loss: 1.2469 - val_acc: 0.0000e+00\n",
      "Epoch 183/2000\n",
      "135/135 [==============================] - 0s 502us/step - loss: 1.0513 - acc: 0.4148 - val_loss: 1.2472 - val_acc: 0.0000e+00\n",
      "Epoch 184/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 1.0512 - acc: 0.3778 - val_loss: 1.2447 - val_acc: 0.0000e+00\n",
      "Epoch 185/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 1.0505 - acc: 0.4519 - val_loss: 1.2403 - val_acc: 0.0000e+00\n",
      "Epoch 186/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 1.0501 - acc: 0.4593 - val_loss: 1.2366 - val_acc: 0.0000e+00\n",
      "Epoch 187/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 1.0498 - acc: 0.4741 - val_loss: 1.2311 - val_acc: 0.0000e+00\n",
      "Epoch 188/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 1.0490 - acc: 0.4000 - val_loss: 1.2329 - val_acc: 0.0000e+00\n",
      "Epoch 189/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 1.0482 - acc: 0.4296 - val_loss: 1.2350 - val_acc: 0.0000e+00\n",
      "Epoch 190/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 1.0477 - acc: 0.5037 - val_loss: 1.2327 - val_acc: 0.0000e+00\n",
      "Epoch 191/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 1.0470 - acc: 0.4444 - val_loss: 1.2284 - val_acc: 0.0000e+00\n",
      "Epoch 192/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 1.0471 - acc: 0.5259 - val_loss: 1.2285 - val_acc: 0.0000e+00\n",
      "Epoch 193/2000\n",
      "135/135 [==============================] - 0s 406us/step - loss: 1.0459 - acc: 0.5111 - val_loss: 1.2275 - val_acc: 0.0000e+00\n",
      "Epoch 194/2000\n",
      "135/135 [==============================] - 0s 458us/step - loss: 1.0456 - acc: 0.4148 - val_loss: 1.2290 - val_acc: 0.0000e+00\n",
      "Epoch 195/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 1.0447 - acc: 0.5111 - val_loss: 1.2283 - val_acc: 0.0000e+00\n",
      "Epoch 196/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 1.0438 - acc: 0.4444 - val_loss: 1.2265 - val_acc: 0.0000e+00\n",
      "Epoch 197/2000\n",
      "135/135 [==============================] - 0s 391us/step - loss: 1.0435 - acc: 0.4519 - val_loss: 1.2252 - val_acc: 0.0000e+00\n",
      "Epoch 198/2000\n",
      "135/135 [==============================] - 0s 406us/step - loss: 1.0423 - acc: 0.5333 - val_loss: 1.2223 - val_acc: 0.0000e+00\n",
      "Epoch 199/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 1.0419 - acc: 0.5259 - val_loss: 1.2194 - val_acc: 0.0000e+00\n",
      "Epoch 200/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 1.0415 - acc: 0.5185 - val_loss: 1.2170 - val_acc: 0.0000e+00\n",
      "Epoch 201/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 1.0409 - acc: 0.5259 - val_loss: 1.2179 - val_acc: 0.0000e+00\n",
      "Epoch 202/2000\n",
      "135/135 [==============================] - 0s 399us/step - loss: 1.0405 - acc: 0.4074 - val_loss: 1.2180 - val_acc: 0.0000e+00\n",
      "Epoch 203/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 1.0391 - acc: 0.6370 - val_loss: 1.2171 - val_acc: 0.0000e+00\n",
      "Epoch 204/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 1.0383 - acc: 0.5407 - val_loss: 1.2166 - val_acc: 0.0000e+00\n",
      "Epoch 205/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 1.0380 - acc: 0.5333 - val_loss: 1.2144 - val_acc: 0.0000e+00\n",
      "Epoch 206/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 1.0368 - acc: 0.6074 - val_loss: 1.2146 - val_acc: 0.0000e+00\n",
      "Epoch 207/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 1.0357 - acc: 0.5556 - val_loss: 1.2144 - val_acc: 0.0000e+00\n",
      "Epoch 208/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 1.0356 - acc: 0.4963 - val_loss: 1.2115 - val_acc: 0.0000e+00\n",
      "Epoch 209/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 1.0349 - acc: 0.4444 - val_loss: 1.2093 - val_acc: 0.0000e+00\n",
      "Epoch 210/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 1.0338 - acc: 0.4593 - val_loss: 1.2088 - val_acc: 0.0000e+00\n",
      "Epoch 211/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 1.0326 - acc: 0.4000 - val_loss: 1.2076 - val_acc: 0.0000e+00\n",
      "Epoch 212/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 1.0321 - acc: 0.6741 - val_loss: 1.2053 - val_acc: 0.0000e+00\n",
      "Epoch 213/2000\n",
      "135/135 [==============================] - 0s 399us/step - loss: 1.0311 - acc: 0.7037 - val_loss: 1.2051 - val_acc: 0.0000e+00\n",
      "Epoch 214/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 1.0310 - acc: 0.4889 - val_loss: 1.2075 - val_acc: 0.0000e+00\n",
      "Epoch 215/2000\n",
      "135/135 [==============================] - 0s 318us/step - loss: 1.0292 - acc: 0.7037 - val_loss: 1.2076 - val_acc: 0.0000e+00\n",
      "Epoch 216/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 1.0287 - acc: 0.6815 - val_loss: 1.2024 - val_acc: 0.0000e+00\n",
      "Epoch 217/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 1.0278 - acc: 0.6074 - val_loss: 1.1956 - val_acc: 0.0000e+00\n",
      "Epoch 218/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 1.0264 - acc: 0.6963 - val_loss: 1.1967 - val_acc: 0.0000e+00\n",
      "Epoch 219/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 1.0259 - acc: 0.6074 - val_loss: 1.1967 - val_acc: 0.0000e+00\n",
      "Epoch 220/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 1.0253 - acc: 0.6444 - val_loss: 1.1953 - val_acc: 0.0000e+00\n",
      "Epoch 221/2000\n",
      "135/135 [==============================] - 0s 303us/step - loss: 1.0234 - acc: 0.6296 - val_loss: 1.1942 - val_acc: 0.0000e+00\n",
      "Epoch 222/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 1.0234 - acc: 0.6222 - val_loss: 1.1888 - val_acc: 0.0000e+00\n",
      "Epoch 223/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 1.0218 - acc: 0.5852 - val_loss: 1.1857 - val_acc: 0.0000e+00\n",
      "Epoch 224/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 1.0215 - acc: 0.6593 - val_loss: 1.1867 - val_acc: 0.0000e+00\n",
      "Epoch 225/2000\n",
      "135/135 [==============================] - 0s 335us/step - loss: 1.0203 - acc: 0.6296 - val_loss: 1.1863 - val_acc: 0.0000e+00\n",
      "Epoch 226/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 1.0190 - acc: 0.7259 - val_loss: 1.1871 - val_acc: 0.0000e+00\n",
      "Epoch 227/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 1.0171 - acc: 0.6889 - val_loss: 1.1858 - val_acc: 0.0000e+00\n",
      "Epoch 228/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 1.0169 - acc: 0.6889 - val_loss: 1.1860 - val_acc: 0.0000e+00\n",
      "Epoch 229/2000\n",
      "135/135 [==============================] - 0s 318us/step - loss: 1.0155 - acc: 0.4741 - val_loss: 1.1803 - val_acc: 0.0000e+00\n",
      "Epoch 230/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 1.0143 - acc: 0.6741 - val_loss: 1.1766 - val_acc: 0.0000e+00\n",
      "Epoch 231/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 1.0134 - acc: 0.7037 - val_loss: 1.1757 - val_acc: 0.0000e+00\n",
      "Epoch 232/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 1.0120 - acc: 0.6963 - val_loss: 1.1734 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/2000\n",
      "135/135 [==============================] - 0s 310us/step - loss: 1.0105 - acc: 0.6000 - val_loss: 1.1729 - val_acc: 0.0000e+00\n",
      "Epoch 234/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 1.0097 - acc: 0.6741 - val_loss: 1.1693 - val_acc: 0.0000e+00\n",
      "Epoch 235/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 1.0083 - acc: 0.6963 - val_loss: 1.1654 - val_acc: 0.0000e+00\n",
      "Epoch 236/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 1.0070 - acc: 0.5926 - val_loss: 1.1630 - val_acc: 0.0000e+00\n",
      "Epoch 237/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 1.0057 - acc: 0.7333 - val_loss: 1.1647 - val_acc: 0.0000e+00\n",
      "Epoch 238/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 1.0041 - acc: 0.7259 - val_loss: 1.1646 - val_acc: 0.0000e+00\n",
      "Epoch 239/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 1.0033 - acc: 0.5778 - val_loss: 1.1587 - val_acc: 0.0000e+00\n",
      "Epoch 240/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 1.0019 - acc: 0.7037 - val_loss: 1.1553 - val_acc: 0.0000e+00\n",
      "Epoch 241/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 1.0011 - acc: 0.6741 - val_loss: 1.1554 - val_acc: 0.0000e+00\n",
      "Epoch 242/2000\n",
      "135/135 [==============================] - 0s 318us/step - loss: 0.9992 - acc: 0.6741 - val_loss: 1.1552 - val_acc: 0.0000e+00\n",
      "Epoch 243/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.9981 - acc: 0.6148 - val_loss: 1.1539 - val_acc: 0.0000e+00\n",
      "Epoch 244/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.9965 - acc: 0.7185 - val_loss: 1.1472 - val_acc: 0.0000e+00\n",
      "Epoch 245/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.9951 - acc: 0.7333 - val_loss: 1.1476 - val_acc: 0.0000e+00\n",
      "Epoch 246/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.9938 - acc: 0.7259 - val_loss: 1.1428 - val_acc: 0.0000e+00\n",
      "Epoch 247/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.9923 - acc: 0.7037 - val_loss: 1.1430 - val_acc: 0.0000e+00\n",
      "Epoch 248/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.9910 - acc: 0.6815 - val_loss: 1.1386 - val_acc: 0.0000e+00\n",
      "Epoch 249/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.9893 - acc: 0.7111 - val_loss: 1.1336 - val_acc: 0.0000e+00\n",
      "Epoch 250/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.9876 - acc: 0.7407 - val_loss: 1.1322 - val_acc: 0.0000e+00\n",
      "Epoch 251/2000\n",
      "135/135 [==============================] - 0s 376us/step - loss: 0.9861 - acc: 0.7333 - val_loss: 1.1300 - val_acc: 0.0000e+00\n",
      "Epoch 252/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.9842 - acc: 0.7185 - val_loss: 1.1276 - val_acc: 0.0000e+00\n",
      "Epoch 253/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.9825 - acc: 0.7333 - val_loss: 1.1255 - val_acc: 0.0000e+00\n",
      "Epoch 254/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.9811 - acc: 0.6815 - val_loss: 1.1241 - val_acc: 0.0000e+00\n",
      "Epoch 255/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.9794 - acc: 0.7185 - val_loss: 1.1227 - val_acc: 0.0000e+00\n",
      "Epoch 256/2000\n",
      "135/135 [==============================] - 0s 406us/step - loss: 0.9777 - acc: 0.7407 - val_loss: 1.1180 - val_acc: 0.0000e+00\n",
      "Epoch 257/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.9764 - acc: 0.6741 - val_loss: 1.1160 - val_acc: 0.0000e+00\n",
      "Epoch 258/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.9742 - acc: 0.7185 - val_loss: 1.1127 - val_acc: 0.0000e+00\n",
      "Epoch 259/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.9727 - acc: 0.6889 - val_loss: 1.1098 - val_acc: 0.0000e+00\n",
      "Epoch 260/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.9705 - acc: 0.7111 - val_loss: 1.1063 - val_acc: 0.0000e+00\n",
      "Epoch 261/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.9686 - acc: 0.7407 - val_loss: 1.1039 - val_acc: 0.0000e+00\n",
      "Epoch 262/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.9666 - acc: 0.7111 - val_loss: 1.0991 - val_acc: 0.0000e+00\n",
      "Epoch 263/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.9654 - acc: 0.7407 - val_loss: 1.0931 - val_acc: 0.0000e+00\n",
      "Epoch 264/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.9630 - acc: 0.7259 - val_loss: 1.0945 - val_acc: 0.0000e+00\n",
      "Epoch 265/2000\n",
      "135/135 [==============================] - 0s 376us/step - loss: 0.9609 - acc: 0.7407 - val_loss: 1.0936 - val_acc: 0.0000e+00\n",
      "Epoch 266/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.9594 - acc: 0.7259 - val_loss: 1.0890 - val_acc: 0.0000e+00\n",
      "Epoch 267/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.9574 - acc: 0.7556 - val_loss: 1.0885 - val_acc: 0.0000e+00\n",
      "Epoch 268/2000\n",
      "135/135 [==============================] - 0s 399us/step - loss: 0.9548 - acc: 0.7556 - val_loss: 1.0861 - val_acc: 0.0000e+00\n",
      "Epoch 269/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.9531 - acc: 0.7259 - val_loss: 1.0822 - val_acc: 0.0667\n",
      "Epoch 270/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.9507 - acc: 0.7630 - val_loss: 1.0810 - val_acc: 0.0667\n",
      "Epoch 271/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.9483 - acc: 0.7778 - val_loss: 1.0822 - val_acc: 0.0000e+00\n",
      "Epoch 272/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.9460 - acc: 0.7481 - val_loss: 1.0773 - val_acc: 0.1333\n",
      "Epoch 273/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.9440 - acc: 0.7407 - val_loss: 1.0729 - val_acc: 0.1333\n",
      "Epoch 274/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.9414 - acc: 0.7778 - val_loss: 1.0692 - val_acc: 0.2000\n",
      "Epoch 275/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.9396 - acc: 0.7556 - val_loss: 1.0657 - val_acc: 0.2000\n",
      "Epoch 276/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.9373 - acc: 0.8074 - val_loss: 1.0653 - val_acc: 0.2000\n",
      "Epoch 277/2000\n",
      "135/135 [==============================] - 0s 318us/step - loss: 0.9352 - acc: 0.7481 - val_loss: 1.0607 - val_acc: 0.2667\n",
      "Epoch 278/2000\n",
      "135/135 [==============================] - 0s 406us/step - loss: 0.9322 - acc: 0.7630 - val_loss: 1.0555 - val_acc: 0.3333\n",
      "Epoch 279/2000\n",
      "135/135 [==============================] - 0s 421us/step - loss: 0.9303 - acc: 0.7704 - val_loss: 1.0506 - val_acc: 0.3333\n",
      "Epoch 280/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.9278 - acc: 0.7704 - val_loss: 1.0440 - val_acc: 0.3333\n",
      "Epoch 281/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.9250 - acc: 0.7778 - val_loss: 1.0396 - val_acc: 0.3333\n",
      "Epoch 282/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.9228 - acc: 0.7926 - val_loss: 1.0370 - val_acc: 0.3333\n",
      "Epoch 283/2000\n",
      "135/135 [==============================] - 0s 310us/step - loss: 0.9196 - acc: 0.8000 - val_loss: 1.0341 - val_acc: 0.4000\n",
      "Epoch 284/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.9176 - acc: 0.8000 - val_loss: 1.0326 - val_acc: 0.4667\n",
      "Epoch 285/2000\n",
      "135/135 [==============================] - 0s 399us/step - loss: 0.9153 - acc: 0.8148 - val_loss: 1.0311 - val_acc: 0.4667\n",
      "Epoch 286/2000\n",
      "135/135 [==============================] - 0s 318us/step - loss: 0.9127 - acc: 0.7852 - val_loss: 1.0257 - val_acc: 0.5333\n",
      "Epoch 287/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.9098 - acc: 0.8148 - val_loss: 1.0209 - val_acc: 0.5333\n",
      "Epoch 288/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.9066 - acc: 0.7926 - val_loss: 1.0173 - val_acc: 0.5333\n",
      "Epoch 289/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.9043 - acc: 0.7926 - val_loss: 1.0107 - val_acc: 0.5333\n",
      "Epoch 290/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.9009 - acc: 0.8444 - val_loss: 1.0100 - val_acc: 0.5333\n",
      "Epoch 291/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 465us/step - loss: 0.8985 - acc: 0.8519 - val_loss: 1.0091 - val_acc: 0.5333\n",
      "Epoch 292/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.8952 - acc: 0.8519 - val_loss: 1.0072 - val_acc: 0.5333\n",
      "Epoch 293/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.8929 - acc: 0.8222 - val_loss: 1.0005 - val_acc: 0.5333\n",
      "Epoch 294/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.8901 - acc: 0.8667 - val_loss: 0.9992 - val_acc: 0.5333\n",
      "Epoch 295/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.8866 - acc: 0.8519 - val_loss: 0.9954 - val_acc: 0.5333\n",
      "Epoch 296/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.8842 - acc: 0.8519 - val_loss: 0.9916 - val_acc: 0.6000\n",
      "Epoch 297/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.8806 - acc: 0.8593 - val_loss: 0.9872 - val_acc: 0.6000\n",
      "Epoch 298/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.8772 - acc: 0.8296 - val_loss: 0.9789 - val_acc: 0.6000\n",
      "Epoch 299/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.8744 - acc: 0.8519 - val_loss: 0.9752 - val_acc: 0.6000\n",
      "Epoch 300/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.8711 - acc: 0.8741 - val_loss: 0.9729 - val_acc: 0.6000\n",
      "Epoch 301/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.8678 - acc: 0.8667 - val_loss: 0.9704 - val_acc: 0.6000\n",
      "Epoch 302/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.8654 - acc: 0.8815 - val_loss: 0.9706 - val_acc: 0.6000\n",
      "Epoch 303/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.8627 - acc: 0.8519 - val_loss: 0.9664 - val_acc: 0.6000\n",
      "Epoch 304/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.8584 - acc: 0.8519 - val_loss: 0.9600 - val_acc: 0.6000\n",
      "Epoch 305/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.8551 - acc: 0.8815 - val_loss: 0.9580 - val_acc: 0.6000\n",
      "Epoch 306/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.8522 - acc: 0.8815 - val_loss: 0.9552 - val_acc: 0.6000\n",
      "Epoch 307/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.8488 - acc: 0.8741 - val_loss: 0.9501 - val_acc: 0.6000\n",
      "Epoch 308/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.8456 - acc: 0.8889 - val_loss: 0.9459 - val_acc: 0.6000\n",
      "Epoch 309/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.8418 - acc: 0.8889 - val_loss: 0.9429 - val_acc: 0.6000\n",
      "Epoch 310/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.8385 - acc: 0.9111 - val_loss: 0.9423 - val_acc: 0.6000\n",
      "Epoch 311/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.8351 - acc: 0.8741 - val_loss: 0.9349 - val_acc: 0.6667\n",
      "Epoch 312/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.8308 - acc: 0.8741 - val_loss: 0.9291 - val_acc: 0.6667\n",
      "Epoch 313/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.8284 - acc: 0.8889 - val_loss: 0.9250 - val_acc: 0.6667\n",
      "Epoch 314/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.8238 - acc: 0.9185 - val_loss: 0.9247 - val_acc: 0.6667\n",
      "Epoch 315/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.8204 - acc: 0.9111 - val_loss: 0.9218 - val_acc: 0.6667\n",
      "Epoch 316/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.8169 - acc: 0.8889 - val_loss: 0.9179 - val_acc: 0.6667\n",
      "Epoch 317/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.8132 - acc: 0.8889 - val_loss: 0.9115 - val_acc: 0.6667\n",
      "Epoch 318/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.8097 - acc: 0.8963 - val_loss: 0.9060 - val_acc: 0.6667\n",
      "Epoch 319/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.8065 - acc: 0.9185 - val_loss: 0.9044 - val_acc: 0.6667\n",
      "Epoch 320/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.8023 - acc: 0.8815 - val_loss: 0.8965 - val_acc: 0.6667\n",
      "Epoch 321/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.7993 - acc: 0.9333 - val_loss: 0.8982 - val_acc: 0.6667\n",
      "Epoch 322/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.7953 - acc: 0.9259 - val_loss: 0.8956 - val_acc: 0.6667\n",
      "Epoch 323/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.7912 - acc: 0.9037 - val_loss: 0.8918 - val_acc: 0.6667\n",
      "Epoch 324/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.7875 - acc: 0.8963 - val_loss: 0.8869 - val_acc: 0.6667\n",
      "Epoch 325/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.7837 - acc: 0.9037 - val_loss: 0.8844 - val_acc: 0.6667\n",
      "Epoch 326/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.7802 - acc: 0.9259 - val_loss: 0.8821 - val_acc: 0.6667\n",
      "Epoch 327/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.7762 - acc: 0.9111 - val_loss: 0.8769 - val_acc: 0.6667\n",
      "Epoch 328/2000\n",
      "135/135 [==============================] - 0s 318us/step - loss: 0.7725 - acc: 0.9259 - val_loss: 0.8748 - val_acc: 0.6667\n",
      "Epoch 329/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.7688 - acc: 0.8889 - val_loss: 0.8682 - val_acc: 0.7333\n",
      "Epoch 330/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.7653 - acc: 0.9259 - val_loss: 0.8644 - val_acc: 0.7333\n",
      "Epoch 331/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.7607 - acc: 0.9407 - val_loss: 0.8617 - val_acc: 0.7333\n",
      "Epoch 332/2000\n",
      "135/135 [==============================] - 0s 310us/step - loss: 0.7570 - acc: 0.9185 - val_loss: 0.8581 - val_acc: 0.7333\n",
      "Epoch 333/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.7536 - acc: 0.9111 - val_loss: 0.8540 - val_acc: 0.8000\n",
      "Epoch 334/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.7499 - acc: 0.9185 - val_loss: 0.8491 - val_acc: 0.8667\n",
      "Epoch 335/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.7456 - acc: 0.9333 - val_loss: 0.8467 - val_acc: 0.8667\n",
      "Epoch 336/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.7418 - acc: 0.9333 - val_loss: 0.8419 - val_acc: 0.8667\n",
      "Epoch 337/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.7383 - acc: 0.9259 - val_loss: 0.8368 - val_acc: 0.8667\n",
      "Epoch 338/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.7343 - acc: 0.9407 - val_loss: 0.8351 - val_acc: 0.8667\n",
      "Epoch 339/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.7306 - acc: 0.9333 - val_loss: 0.8308 - val_acc: 0.8667\n",
      "Epoch 340/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.7262 - acc: 0.9481 - val_loss: 0.8281 - val_acc: 0.8667\n",
      "Epoch 341/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.7225 - acc: 0.9407 - val_loss: 0.8252 - val_acc: 0.8667\n",
      "Epoch 342/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.7186 - acc: 0.9407 - val_loss: 0.8232 - val_acc: 0.8667\n",
      "Epoch 343/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.7152 - acc: 0.9407 - val_loss: 0.8195 - val_acc: 0.8667\n",
      "Epoch 344/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.7110 - acc: 0.9407 - val_loss: 0.8172 - val_acc: 0.8667\n",
      "Epoch 345/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.7073 - acc: 0.9407 - val_loss: 0.8119 - val_acc: 0.8667\n",
      "Epoch 346/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.7037 - acc: 0.9481 - val_loss: 0.8085 - val_acc: 0.8667\n",
      "Epoch 347/2000\n",
      "135/135 [==============================] - 0s 318us/step - loss: 0.7000 - acc: 0.9481 - val_loss: 0.8044 - val_acc: 0.8667\n",
      "Epoch 348/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.6959 - acc: 0.9333 - val_loss: 0.8010 - val_acc: 0.8667\n",
      "Epoch 349/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.6922 - acc: 0.9333 - val_loss: 0.7976 - val_acc: 0.8667\n",
      "Epoch 350/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 355us/step - loss: 0.6885 - acc: 0.9333 - val_loss: 0.7941 - val_acc: 0.8667\n",
      "Epoch 351/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.6847 - acc: 0.9407 - val_loss: 0.7904 - val_acc: 0.8667\n",
      "Epoch 352/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.6816 - acc: 0.9407 - val_loss: 0.7890 - val_acc: 0.8667\n",
      "Epoch 353/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.6773 - acc: 0.9111 - val_loss: 0.7820 - val_acc: 0.8667\n",
      "Epoch 354/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.6736 - acc: 0.9407 - val_loss: 0.7801 - val_acc: 0.8667\n",
      "Epoch 355/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.6700 - acc: 0.9407 - val_loss: 0.7793 - val_acc: 0.8667\n",
      "Epoch 356/2000\n",
      "135/135 [==============================] - 0s 363us/step - loss: 0.6665 - acc: 0.9407 - val_loss: 0.7768 - val_acc: 0.8667\n",
      "Epoch 357/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.6625 - acc: 0.9259 - val_loss: 0.7711 - val_acc: 0.8667\n",
      "Epoch 358/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.6593 - acc: 0.9481 - val_loss: 0.7690 - val_acc: 0.8667\n",
      "Epoch 359/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.6555 - acc: 0.9556 - val_loss: 0.7689 - val_acc: 0.8667\n",
      "Epoch 360/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.6519 - acc: 0.9481 - val_loss: 0.7684 - val_acc: 0.8667\n",
      "Epoch 361/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.6486 - acc: 0.9333 - val_loss: 0.7632 - val_acc: 0.8667\n",
      "Epoch 362/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.6452 - acc: 0.9481 - val_loss: 0.7604 - val_acc: 0.8667\n",
      "Epoch 363/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.6416 - acc: 0.9407 - val_loss: 0.7581 - val_acc: 0.8667\n",
      "Epoch 364/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.6382 - acc: 0.9407 - val_loss: 0.7545 - val_acc: 0.8667\n",
      "Epoch 365/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.6348 - acc: 0.9481 - val_loss: 0.7523 - val_acc: 0.8667\n",
      "Epoch 366/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.6317 - acc: 0.9481 - val_loss: 0.7521 - val_acc: 0.8667\n",
      "Epoch 367/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.6281 - acc: 0.9407 - val_loss: 0.7496 - val_acc: 0.8667\n",
      "Epoch 368/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.6252 - acc: 0.9481 - val_loss: 0.7497 - val_acc: 0.8667\n",
      "Epoch 369/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.6210 - acc: 0.9481 - val_loss: 0.7482 - val_acc: 0.8667\n",
      "Epoch 370/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.6179 - acc: 0.9407 - val_loss: 0.7473 - val_acc: 0.8667\n",
      "Epoch 371/2000\n",
      "135/135 [==============================] - 0s 310us/step - loss: 0.6148 - acc: 0.9333 - val_loss: 0.7409 - val_acc: 0.8667\n",
      "Epoch 372/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.6117 - acc: 0.9407 - val_loss: 0.7404 - val_acc: 0.8667\n",
      "Epoch 373/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.6085 - acc: 0.9333 - val_loss: 0.7369 - val_acc: 0.8667\n",
      "Epoch 374/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.6057 - acc: 0.9407 - val_loss: 0.7351 - val_acc: 0.8667\n",
      "Epoch 375/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.6021 - acc: 0.9481 - val_loss: 0.7344 - val_acc: 0.8667\n",
      "Epoch 376/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.5993 - acc: 0.9407 - val_loss: 0.7313 - val_acc: 0.8667\n",
      "Epoch 377/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.5961 - acc: 0.9333 - val_loss: 0.7269 - val_acc: 0.8667\n",
      "Epoch 378/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.5932 - acc: 0.9407 - val_loss: 0.7239 - val_acc: 0.8667\n",
      "Epoch 379/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.5902 - acc: 0.9481 - val_loss: 0.7230 - val_acc: 0.8667\n",
      "Epoch 380/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.5876 - acc: 0.9481 - val_loss: 0.7224 - val_acc: 0.8667\n",
      "Epoch 381/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.5845 - acc: 0.9481 - val_loss: 0.7217 - val_acc: 0.8667\n",
      "Epoch 382/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.5813 - acc: 0.9481 - val_loss: 0.7213 - val_acc: 0.8667\n",
      "Epoch 383/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.5783 - acc: 0.9481 - val_loss: 0.7194 - val_acc: 0.8667\n",
      "Epoch 384/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.5759 - acc: 0.9556 - val_loss: 0.7196 - val_acc: 0.8667\n",
      "Epoch 385/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.5731 - acc: 0.9407 - val_loss: 0.7170 - val_acc: 0.8667\n",
      "Epoch 386/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.5701 - acc: 0.9407 - val_loss: 0.7144 - val_acc: 0.8667\n",
      "Epoch 387/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.5673 - acc: 0.9407 - val_loss: 0.7111 - val_acc: 0.8667\n",
      "Epoch 388/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.5647 - acc: 0.9333 - val_loss: 0.7080 - val_acc: 0.8667\n",
      "Epoch 389/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.5621 - acc: 0.9481 - val_loss: 0.7084 - val_acc: 0.8667\n",
      "Epoch 390/2000\n",
      "135/135 [==============================] - 0s 488us/step - loss: 0.5591 - acc: 0.9481 - val_loss: 0.7062 - val_acc: 0.8667\n",
      "Epoch 391/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.5567 - acc: 0.9481 - val_loss: 0.7058 - val_acc: 0.8667\n",
      "Epoch 392/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.5540 - acc: 0.9407 - val_loss: 0.7040 - val_acc: 0.8667\n",
      "Epoch 393/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.5515 - acc: 0.9259 - val_loss: 0.7006 - val_acc: 0.8667\n",
      "Epoch 394/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.5490 - acc: 0.9481 - val_loss: 0.6994 - val_acc: 0.8667\n",
      "Epoch 395/2000\n",
      "135/135 [==============================] - 0s 502us/step - loss: 0.5465 - acc: 0.9481 - val_loss: 0.7003 - val_acc: 0.8667\n",
      "Epoch 396/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.5442 - acc: 0.9407 - val_loss: 0.6985 - val_acc: 0.8667\n",
      "Epoch 397/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.5413 - acc: 0.9481 - val_loss: 0.6999 - val_acc: 0.8667\n",
      "Epoch 398/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.5393 - acc: 0.9407 - val_loss: 0.6991 - val_acc: 0.8667\n",
      "Epoch 399/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.5366 - acc: 0.9407 - val_loss: 0.6975 - val_acc: 0.8667\n",
      "Epoch 400/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.5344 - acc: 0.9333 - val_loss: 0.6951 - val_acc: 0.8667\n",
      "Epoch 401/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.5318 - acc: 0.9407 - val_loss: 0.6936 - val_acc: 0.8667\n",
      "Epoch 402/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.5298 - acc: 0.9407 - val_loss: 0.6923 - val_acc: 0.8667\n",
      "Epoch 403/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.5277 - acc: 0.9407 - val_loss: 0.6905 - val_acc: 0.8667\n",
      "Epoch 404/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.5254 - acc: 0.9407 - val_loss: 0.6885 - val_acc: 0.8667\n",
      "Epoch 405/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.5233 - acc: 0.9259 - val_loss: 0.6846 - val_acc: 0.8667\n",
      "Epoch 406/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.5208 - acc: 0.9407 - val_loss: 0.6842 - val_acc: 0.8667\n",
      "Epoch 407/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.5188 - acc: 0.9185 - val_loss: 0.6815 - val_acc: 0.8667\n",
      "Epoch 408/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.5165 - acc: 0.9407 - val_loss: 0.6813 - val_acc: 0.8667\n",
      "Epoch 409/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 340us/step - loss: 0.5147 - acc: 0.9407 - val_loss: 0.6804 - val_acc: 0.8667\n",
      "Epoch 410/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.5125 - acc: 0.9407 - val_loss: 0.6807 - val_acc: 0.8667\n",
      "Epoch 411/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.5103 - acc: 0.9407 - val_loss: 0.6792 - val_acc: 0.8667\n",
      "Epoch 412/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.5081 - acc: 0.9407 - val_loss: 0.6775 - val_acc: 0.8667\n",
      "Epoch 413/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.5066 - acc: 0.9407 - val_loss: 0.6757 - val_acc: 0.8667\n",
      "Epoch 414/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.5043 - acc: 0.9407 - val_loss: 0.6771 - val_acc: 0.8667\n",
      "Epoch 415/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.5026 - acc: 0.9407 - val_loss: 0.6768 - val_acc: 0.8667\n",
      "Epoch 416/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.5005 - acc: 0.9407 - val_loss: 0.6759 - val_acc: 0.8667\n",
      "Epoch 417/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.4987 - acc: 0.9407 - val_loss: 0.6743 - val_acc: 0.8667\n",
      "Epoch 418/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.4967 - acc: 0.9407 - val_loss: 0.6720 - val_acc: 0.8667\n",
      "Epoch 419/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.4948 - acc: 0.9481 - val_loss: 0.6710 - val_acc: 0.8667\n",
      "Epoch 420/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.4930 - acc: 0.9481 - val_loss: 0.6707 - val_acc: 0.8667\n",
      "Epoch 421/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.4915 - acc: 0.9407 - val_loss: 0.6707 - val_acc: 0.8667\n",
      "Epoch 422/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.4896 - acc: 0.9481 - val_loss: 0.6714 - val_acc: 0.8667\n",
      "Epoch 423/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.4876 - acc: 0.9481 - val_loss: 0.6711 - val_acc: 0.8667\n",
      "Epoch 424/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.4858 - acc: 0.9407 - val_loss: 0.6694 - val_acc: 0.8667\n",
      "Epoch 425/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.4841 - acc: 0.9407 - val_loss: 0.6692 - val_acc: 0.8667\n",
      "Epoch 426/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.4823 - acc: 0.9407 - val_loss: 0.6671 - val_acc: 0.8667\n",
      "Epoch 427/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.4809 - acc: 0.9407 - val_loss: 0.6657 - val_acc: 0.8667\n",
      "Epoch 428/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.4791 - acc: 0.9407 - val_loss: 0.6636 - val_acc: 0.8667\n",
      "Epoch 429/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.4779 - acc: 0.9481 - val_loss: 0.6655 - val_acc: 0.8667\n",
      "Epoch 430/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.4759 - acc: 0.9407 - val_loss: 0.6631 - val_acc: 0.8667\n",
      "Epoch 431/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.4747 - acc: 0.9481 - val_loss: 0.6636 - val_acc: 0.8667\n",
      "Epoch 432/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.4725 - acc: 0.9481 - val_loss: 0.6636 - val_acc: 0.8667\n",
      "Epoch 433/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.4714 - acc: 0.9407 - val_loss: 0.6607 - val_acc: 0.8667\n",
      "Epoch 434/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.4699 - acc: 0.9407 - val_loss: 0.6584 - val_acc: 0.8667\n",
      "Epoch 435/2000\n",
      "135/135 [==============================] - 0s 370us/step - loss: 0.4681 - acc: 0.9407 - val_loss: 0.6564 - val_acc: 0.8667\n",
      "Epoch 436/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.4666 - acc: 0.9333 - val_loss: 0.6532 - val_acc: 0.8667\n",
      "Epoch 437/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.4650 - acc: 0.9481 - val_loss: 0.6543 - val_acc: 0.8667\n",
      "Epoch 438/2000\n",
      "135/135 [==============================] - 0s 370us/step - loss: 0.4634 - acc: 0.9407 - val_loss: 0.6536 - val_acc: 0.8667\n",
      "Epoch 439/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.4619 - acc: 0.9481 - val_loss: 0.6527 - val_acc: 0.8667\n",
      "Epoch 440/2000\n",
      "135/135 [==============================] - 0s 354us/step - loss: 0.4607 - acc: 0.9407 - val_loss: 0.6530 - val_acc: 0.8667\n",
      "Epoch 441/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.4592 - acc: 0.9481 - val_loss: 0.6518 - val_acc: 0.8667\n",
      "Epoch 442/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.4577 - acc: 0.9481 - val_loss: 0.6518 - val_acc: 0.8667\n",
      "Epoch 443/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.4560 - acc: 0.9407 - val_loss: 0.6498 - val_acc: 0.8667\n",
      "Epoch 444/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.4548 - acc: 0.9481 - val_loss: 0.6500 - val_acc: 0.8667\n",
      "Epoch 445/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.4535 - acc: 0.9407 - val_loss: 0.6489 - val_acc: 0.8667\n",
      "Epoch 446/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.4520 - acc: 0.9407 - val_loss: 0.6462 - val_acc: 0.8667\n",
      "Epoch 447/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.4505 - acc: 0.9407 - val_loss: 0.6447 - val_acc: 0.8667\n",
      "Epoch 448/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.4492 - acc: 0.9407 - val_loss: 0.6422 - val_acc: 0.8667\n",
      "Epoch 449/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 0.4483 - acc: 0.9481 - val_loss: 0.6403 - val_acc: 0.8667\n",
      "Epoch 450/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.4467 - acc: 0.9481 - val_loss: 0.6399 - val_acc: 0.8667\n",
      "Epoch 451/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.4453 - acc: 0.9407 - val_loss: 0.6388 - val_acc: 0.8667\n",
      "Epoch 452/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.4443 - acc: 0.9407 - val_loss: 0.6400 - val_acc: 0.8667\n",
      "Epoch 453/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.4428 - acc: 0.9481 - val_loss: 0.6397 - val_acc: 0.8667\n",
      "Epoch 454/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.4415 - acc: 0.9481 - val_loss: 0.6359 - val_acc: 0.8667\n",
      "Epoch 455/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.4405 - acc: 0.9481 - val_loss: 0.6364 - val_acc: 0.8667\n",
      "Epoch 456/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.4388 - acc: 0.9407 - val_loss: 0.6344 - val_acc: 0.8667\n",
      "Epoch 457/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.4375 - acc: 0.9481 - val_loss: 0.6324 - val_acc: 0.8667\n",
      "Epoch 458/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.4366 - acc: 0.9481 - val_loss: 0.6330 - val_acc: 0.8667\n",
      "Epoch 459/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.4355 - acc: 0.9481 - val_loss: 0.6316 - val_acc: 0.8667\n",
      "Epoch 460/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.4342 - acc: 0.9556 - val_loss: 0.6330 - val_acc: 0.8667\n",
      "Epoch 461/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.4329 - acc: 0.9556 - val_loss: 0.6312 - val_acc: 0.8667\n",
      "Epoch 462/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.4316 - acc: 0.9407 - val_loss: 0.6287 - val_acc: 0.8667\n",
      "Epoch 463/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.4304 - acc: 0.9481 - val_loss: 0.6272 - val_acc: 0.8667\n",
      "Epoch 464/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.4292 - acc: 0.9407 - val_loss: 0.6238 - val_acc: 0.8667\n",
      "Epoch 465/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.4280 - acc: 0.9481 - val_loss: 0.6237 - val_acc: 0.8667\n",
      "Epoch 466/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.4269 - acc: 0.9556 - val_loss: 0.6245 - val_acc: 0.8667\n",
      "Epoch 467/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.4257 - acc: 0.9481 - val_loss: 0.6234 - val_acc: 0.8667\n",
      "Epoch 468/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 362us/step - loss: 0.4249 - acc: 0.9481 - val_loss: 0.6225 - val_acc: 0.8667\n",
      "Epoch 469/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.4237 - acc: 0.9481 - val_loss: 0.6207 - val_acc: 0.8667\n",
      "Epoch 470/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.4224 - acc: 0.9481 - val_loss: 0.6195 - val_acc: 0.8667\n",
      "Epoch 471/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.4213 - acc: 0.9481 - val_loss: 0.6199 - val_acc: 0.8667\n",
      "Epoch 472/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.4202 - acc: 0.9481 - val_loss: 0.6184 - val_acc: 0.8667\n",
      "Epoch 473/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.4193 - acc: 0.9407 - val_loss: 0.6145 - val_acc: 0.8667\n",
      "Epoch 474/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.4186 - acc: 0.9481 - val_loss: 0.6135 - val_acc: 0.8667\n",
      "Epoch 475/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.4170 - acc: 0.9481 - val_loss: 0.6129 - val_acc: 0.8667\n",
      "Epoch 476/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.4158 - acc: 0.9556 - val_loss: 0.6145 - val_acc: 0.8667\n",
      "Epoch 477/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.4151 - acc: 0.9481 - val_loss: 0.6146 - val_acc: 0.8667\n",
      "Epoch 478/2000\n",
      "135/135 [==============================] - 0s 495us/step - loss: 0.4138 - acc: 0.9481 - val_loss: 0.6126 - val_acc: 0.8667\n",
      "Epoch 479/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.4129 - acc: 0.9481 - val_loss: 0.6105 - val_acc: 0.8667\n",
      "Epoch 480/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.4117 - acc: 0.9556 - val_loss: 0.6110 - val_acc: 0.8667\n",
      "Epoch 481/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.4106 - acc: 0.9556 - val_loss: 0.6120 - val_acc: 0.8667\n",
      "Epoch 482/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.4096 - acc: 0.9481 - val_loss: 0.6091 - val_acc: 0.8667\n",
      "Epoch 483/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.4085 - acc: 0.9556 - val_loss: 0.6087 - val_acc: 0.8667\n",
      "Epoch 484/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.4078 - acc: 0.9407 - val_loss: 0.6048 - val_acc: 0.8667\n",
      "Epoch 485/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.4067 - acc: 0.9481 - val_loss: 0.6020 - val_acc: 0.8667\n",
      "Epoch 486/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.4057 - acc: 0.9556 - val_loss: 0.6019 - val_acc: 0.8667\n",
      "Epoch 487/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.4044 - acc: 0.9556 - val_loss: 0.6020 - val_acc: 0.8667\n",
      "Epoch 488/2000\n",
      "135/135 [==============================] - 0s 414us/step - loss: 0.4036 - acc: 0.9630 - val_loss: 0.6037 - val_acc: 0.8667\n",
      "Epoch 489/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.4026 - acc: 0.9481 - val_loss: 0.6005 - val_acc: 0.8667\n",
      "Epoch 490/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.4013 - acc: 0.9556 - val_loss: 0.5992 - val_acc: 0.8667\n",
      "Epoch 491/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.4003 - acc: 0.9556 - val_loss: 0.5990 - val_acc: 0.8667\n",
      "Epoch 492/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.4001 - acc: 0.9556 - val_loss: 0.5993 - val_acc: 0.8667\n",
      "Epoch 493/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.3984 - acc: 0.9481 - val_loss: 0.5971 - val_acc: 0.8667\n",
      "Epoch 494/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.3981 - acc: 0.9481 - val_loss: 0.5964 - val_acc: 0.8667\n",
      "Epoch 495/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.3967 - acc: 0.9481 - val_loss: 0.5940 - val_acc: 0.8667\n",
      "Epoch 496/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.3959 - acc: 0.9556 - val_loss: 0.5941 - val_acc: 0.8667\n",
      "Epoch 497/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.3947 - acc: 0.9481 - val_loss: 0.5915 - val_acc: 0.8667\n",
      "Epoch 498/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.3937 - acc: 0.9481 - val_loss: 0.5892 - val_acc: 0.9333\n",
      "Epoch 499/2000\n",
      "135/135 [==============================] - 0s 310us/step - loss: 0.3930 - acc: 0.9481 - val_loss: 0.5879 - val_acc: 0.9333\n",
      "Epoch 500/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.3919 - acc: 0.9630 - val_loss: 0.5881 - val_acc: 0.9333\n",
      "Epoch 501/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.3911 - acc: 0.9556 - val_loss: 0.5873 - val_acc: 0.9333\n",
      "Epoch 502/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.3899 - acc: 0.9556 - val_loss: 0.5851 - val_acc: 0.9333\n",
      "Epoch 503/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.3888 - acc: 0.9556 - val_loss: 0.5843 - val_acc: 0.9333\n",
      "Epoch 504/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.3882 - acc: 0.9556 - val_loss: 0.5837 - val_acc: 0.9333\n",
      "Epoch 505/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.3871 - acc: 0.9556 - val_loss: 0.5844 - val_acc: 0.9333\n",
      "Epoch 506/2000\n",
      "135/135 [==============================] - 0s 321us/step - loss: 0.3863 - acc: 0.9556 - val_loss: 0.5806 - val_acc: 0.9333\n",
      "Epoch 507/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.3853 - acc: 0.9556 - val_loss: 0.5789 - val_acc: 0.9333\n",
      "Epoch 508/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.3845 - acc: 0.9630 - val_loss: 0.5786 - val_acc: 0.9333\n",
      "Epoch 509/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.3834 - acc: 0.9556 - val_loss: 0.5767 - val_acc: 0.9333\n",
      "Epoch 510/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.3826 - acc: 0.9556 - val_loss: 0.5746 - val_acc: 0.9333\n",
      "Epoch 511/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.3816 - acc: 0.9556 - val_loss: 0.5728 - val_acc: 0.9333\n",
      "Epoch 512/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.3809 - acc: 0.9556 - val_loss: 0.5733 - val_acc: 0.9333\n",
      "Epoch 513/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.3801 - acc: 0.9556 - val_loss: 0.5718 - val_acc: 0.9333\n",
      "Epoch 514/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.3791 - acc: 0.9556 - val_loss: 0.5716 - val_acc: 0.9333\n",
      "Epoch 515/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.3786 - acc: 0.9630 - val_loss: 0.5717 - val_acc: 0.9333\n",
      "Epoch 516/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.3772 - acc: 0.9556 - val_loss: 0.5699 - val_acc: 0.9333\n",
      "Epoch 517/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.3765 - acc: 0.9556 - val_loss: 0.5661 - val_acc: 0.9333\n",
      "Epoch 518/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.3755 - acc: 0.9556 - val_loss: 0.5631 - val_acc: 0.9333\n",
      "Epoch 519/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.3746 - acc: 0.9704 - val_loss: 0.5635 - val_acc: 0.9333\n",
      "Epoch 520/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.3737 - acc: 0.9556 - val_loss: 0.5631 - val_acc: 0.9333\n",
      "Epoch 521/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.3729 - acc: 0.9704 - val_loss: 0.5654 - val_acc: 0.9333\n",
      "Epoch 522/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.3722 - acc: 0.9556 - val_loss: 0.5629 - val_acc: 0.9333\n",
      "Epoch 523/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.3711 - acc: 0.9556 - val_loss: 0.5605 - val_acc: 0.9333\n",
      "Epoch 524/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.3702 - acc: 0.9630 - val_loss: 0.5601 - val_acc: 0.9333\n",
      "Epoch 525/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.3696 - acc: 0.9630 - val_loss: 0.5592 - val_acc: 0.9333\n",
      "Epoch 526/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.3686 - acc: 0.9556 - val_loss: 0.5583 - val_acc: 0.9333\n",
      "Epoch 527/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 340us/step - loss: 0.3681 - acc: 0.9556 - val_loss: 0.5570 - val_acc: 0.9333\n",
      "Epoch 528/2000\n",
      "135/135 [==============================] - 0s 406us/step - loss: 0.3669 - acc: 0.9704 - val_loss: 0.5575 - val_acc: 0.9333\n",
      "Epoch 529/2000\n",
      "135/135 [==============================] - 0s 316us/step - loss: 0.3660 - acc: 0.9556 - val_loss: 0.5548 - val_acc: 0.9333\n",
      "Epoch 530/2000\n",
      "135/135 [==============================] - 0s 335us/step - loss: 0.3652 - acc: 0.9630 - val_loss: 0.5513 - val_acc: 0.9333\n",
      "Epoch 531/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.3644 - acc: 0.9630 - val_loss: 0.5497 - val_acc: 0.9333\n",
      "Epoch 532/2000\n",
      "135/135 [==============================] - 0s 361us/step - loss: 0.3638 - acc: 0.9556 - val_loss: 0.5495 - val_acc: 0.9333\n",
      "Epoch 533/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.3627 - acc: 0.9556 - val_loss: 0.5463 - val_acc: 0.9333\n",
      "Epoch 534/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 0.3617 - acc: 0.9704 - val_loss: 0.5479 - val_acc: 0.9333\n",
      "Epoch 535/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.3611 - acc: 0.9704 - val_loss: 0.5463 - val_acc: 0.9333\n",
      "Epoch 536/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.3601 - acc: 0.9704 - val_loss: 0.5438 - val_acc: 0.9333\n",
      "Epoch 537/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.3594 - acc: 0.9556 - val_loss: 0.5401 - val_acc: 0.9333\n",
      "Epoch 538/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.3584 - acc: 0.9704 - val_loss: 0.5380 - val_acc: 0.9333\n",
      "Epoch 539/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.3579 - acc: 0.9704 - val_loss: 0.5374 - val_acc: 0.9333\n",
      "Epoch 540/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.3567 - acc: 0.9704 - val_loss: 0.5380 - val_acc: 0.9333\n",
      "Epoch 541/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.3558 - acc: 0.9704 - val_loss: 0.5366 - val_acc: 0.9333\n",
      "Epoch 542/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.3550 - acc: 0.9556 - val_loss: 0.5336 - val_acc: 0.9333\n",
      "Epoch 543/2000\n",
      "135/135 [==============================] - 0s 554us/step - loss: 0.3544 - acc: 0.9556 - val_loss: 0.5291 - val_acc: 0.9333\n",
      "Epoch 544/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.3535 - acc: 0.9704 - val_loss: 0.5282 - val_acc: 0.9333\n",
      "Epoch 545/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.3526 - acc: 0.9704 - val_loss: 0.5276 - val_acc: 0.9333\n",
      "Epoch 546/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.3520 - acc: 0.9704 - val_loss: 0.5264 - val_acc: 0.9333\n",
      "Epoch 547/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.3511 - acc: 0.9704 - val_loss: 0.5254 - val_acc: 0.9333\n",
      "Epoch 548/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.3505 - acc: 0.9630 - val_loss: 0.5227 - val_acc: 0.9333\n",
      "Epoch 549/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.3496 - acc: 0.9704 - val_loss: 0.5210 - val_acc: 0.9333\n",
      "Epoch 550/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.3491 - acc: 0.9704 - val_loss: 0.5195 - val_acc: 0.9333\n",
      "Epoch 551/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.3479 - acc: 0.9704 - val_loss: 0.5179 - val_acc: 0.9333\n",
      "Epoch 552/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.3469 - acc: 0.9704 - val_loss: 0.5185 - val_acc: 0.9333\n",
      "Epoch 553/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.3463 - acc: 0.9556 - val_loss: 0.5185 - val_acc: 0.9333\n",
      "Epoch 554/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.3456 - acc: 0.9630 - val_loss: 0.5191 - val_acc: 0.9333\n",
      "Epoch 555/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.3448 - acc: 0.9704 - val_loss: 0.5170 - val_acc: 0.9333\n",
      "Epoch 556/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.3440 - acc: 0.9704 - val_loss: 0.5161 - val_acc: 0.9333\n",
      "Epoch 557/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.3430 - acc: 0.9704 - val_loss: 0.5148 - val_acc: 0.9333\n",
      "Epoch 558/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.3423 - acc: 0.9630 - val_loss: 0.5134 - val_acc: 0.9333\n",
      "Epoch 559/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.3416 - acc: 0.9630 - val_loss: 0.5097 - val_acc: 0.9333\n",
      "Epoch 560/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.3409 - acc: 0.9704 - val_loss: 0.5095 - val_acc: 0.9333\n",
      "Epoch 561/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.3397 - acc: 0.9704 - val_loss: 0.5078 - val_acc: 0.9333\n",
      "Epoch 562/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.3392 - acc: 0.9704 - val_loss: 0.5068 - val_acc: 0.9333\n",
      "Epoch 563/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.3385 - acc: 0.9630 - val_loss: 0.5021 - val_acc: 1.0000\n",
      "Epoch 564/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.3377 - acc: 0.9630 - val_loss: 0.5028 - val_acc: 0.9333\n",
      "Epoch 565/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.3370 - acc: 0.9704 - val_loss: 0.5013 - val_acc: 0.9333\n",
      "Epoch 566/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.3360 - acc: 0.9704 - val_loss: 0.4990 - val_acc: 1.0000\n",
      "Epoch 567/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.3353 - acc: 0.9704 - val_loss: 0.4967 - val_acc: 1.0000\n",
      "Epoch 568/2000\n",
      "135/135 [==============================] - 0s 318us/step - loss: 0.3348 - acc: 0.9704 - val_loss: 0.4947 - val_acc: 1.0000\n",
      "Epoch 569/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.3337 - acc: 0.9704 - val_loss: 0.4919 - val_acc: 1.0000\n",
      "Epoch 570/2000\n",
      "135/135 [==============================] - 0s 318us/step - loss: 0.3328 - acc: 0.9704 - val_loss: 0.4919 - val_acc: 1.0000\n",
      "Epoch 571/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.3323 - acc: 0.9704 - val_loss: 0.4893 - val_acc: 1.0000\n",
      "Epoch 572/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.3314 - acc: 0.9704 - val_loss: 0.4866 - val_acc: 1.0000\n",
      "Epoch 573/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.3309 - acc: 0.9704 - val_loss: 0.4835 - val_acc: 1.0000\n",
      "Epoch 574/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.3300 - acc: 0.9630 - val_loss: 0.4833 - val_acc: 1.0000\n",
      "Epoch 575/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.3292 - acc: 0.9556 - val_loss: 0.4856 - val_acc: 1.0000\n",
      "Epoch 576/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.3285 - acc: 0.9630 - val_loss: 0.4871 - val_acc: 1.0000\n",
      "Epoch 577/2000\n",
      "135/135 [==============================] - 0s 465us/step - loss: 0.3279 - acc: 0.9704 - val_loss: 0.4824 - val_acc: 1.0000\n",
      "Epoch 578/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.3270 - acc: 0.9630 - val_loss: 0.4817 - val_acc: 1.0000\n",
      "Epoch 579/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.3262 - acc: 0.9630 - val_loss: 0.4827 - val_acc: 1.0000\n",
      "Epoch 580/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.3254 - acc: 0.9630 - val_loss: 0.4828 - val_acc: 1.0000\n",
      "Epoch 581/2000\n",
      "135/135 [==============================] - 0s 359us/step - loss: 0.3249 - acc: 0.9630 - val_loss: 0.4816 - val_acc: 1.0000\n",
      "Epoch 582/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.3239 - acc: 0.9630 - val_loss: 0.4801 - val_acc: 1.0000\n",
      "Epoch 583/2000\n",
      "135/135 [==============================] - 0s 310us/step - loss: 0.3232 - acc: 0.9704 - val_loss: 0.4777 - val_acc: 1.0000\n",
      "Epoch 584/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.3222 - acc: 0.9704 - val_loss: 0.4730 - val_acc: 1.0000\n",
      "Epoch 585/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.3216 - acc: 0.9630 - val_loss: 0.4718 - val_acc: 1.0000\n",
      "Epoch 586/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 384us/step - loss: 0.3210 - acc: 0.9630 - val_loss: 0.4695 - val_acc: 1.0000\n",
      "Epoch 587/2000\n",
      "135/135 [==============================] - 0s 406us/step - loss: 0.3204 - acc: 0.9630 - val_loss: 0.4678 - val_acc: 1.0000\n",
      "Epoch 588/2000\n",
      "135/135 [==============================] - 0s 406us/step - loss: 0.3196 - acc: 0.9556 - val_loss: 0.4676 - val_acc: 1.0000\n",
      "Epoch 589/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.3185 - acc: 0.9704 - val_loss: 0.4651 - val_acc: 1.0000\n",
      "Epoch 590/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.3182 - acc: 0.9630 - val_loss: 0.4658 - val_acc: 1.0000\n",
      "Epoch 591/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.3173 - acc: 0.9630 - val_loss: 0.4662 - val_acc: 1.0000\n",
      "Epoch 592/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.3164 - acc: 0.9630 - val_loss: 0.4663 - val_acc: 1.0000\n",
      "Epoch 593/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.3156 - acc: 0.9630 - val_loss: 0.4638 - val_acc: 1.0000\n",
      "Epoch 594/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.3149 - acc: 0.9630 - val_loss: 0.4613 - val_acc: 1.0000\n",
      "Epoch 595/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.3145 - acc: 0.9630 - val_loss: 0.4597 - val_acc: 1.0000\n",
      "Epoch 596/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.3135 - acc: 0.9630 - val_loss: 0.4601 - val_acc: 1.0000\n",
      "Epoch 597/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.3132 - acc: 0.9704 - val_loss: 0.4573 - val_acc: 1.0000\n",
      "Epoch 598/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.3122 - acc: 0.9704 - val_loss: 0.4533 - val_acc: 1.0000\n",
      "Epoch 599/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.3113 - acc: 0.9556 - val_loss: 0.4575 - val_acc: 1.0000\n",
      "Epoch 600/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.3106 - acc: 0.9630 - val_loss: 0.4556 - val_acc: 1.0000\n",
      "Epoch 601/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.3104 - acc: 0.9704 - val_loss: 0.4524 - val_acc: 1.0000\n",
      "Epoch 602/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.3095 - acc: 0.9630 - val_loss: 0.4488 - val_acc: 1.0000\n",
      "Epoch 603/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.3084 - acc: 0.9630 - val_loss: 0.4484 - val_acc: 1.0000\n",
      "Epoch 604/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.3077 - acc: 0.9630 - val_loss: 0.4455 - val_acc: 1.0000\n",
      "Epoch 605/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.3073 - acc: 0.9630 - val_loss: 0.4456 - val_acc: 1.0000\n",
      "Epoch 606/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.3065 - acc: 0.9556 - val_loss: 0.4437 - val_acc: 1.0000\n",
      "Epoch 607/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.3060 - acc: 0.9556 - val_loss: 0.4430 - val_acc: 1.0000\n",
      "Epoch 608/2000\n",
      "135/135 [==============================] - 0s 376us/step - loss: 0.3052 - acc: 0.9556 - val_loss: 0.4425 - val_acc: 1.0000\n",
      "Epoch 609/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.3043 - acc: 0.9630 - val_loss: 0.4418 - val_acc: 1.0000\n",
      "Epoch 610/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.3036 - acc: 0.9630 - val_loss: 0.4401 - val_acc: 1.0000\n",
      "Epoch 611/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.3030 - acc: 0.9630 - val_loss: 0.4392 - val_acc: 1.0000\n",
      "Epoch 612/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.3021 - acc: 0.9630 - val_loss: 0.4384 - val_acc: 1.0000\n",
      "Epoch 613/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.3016 - acc: 0.9630 - val_loss: 0.4367 - val_acc: 1.0000\n",
      "Epoch 614/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.3008 - acc: 0.9630 - val_loss: 0.4345 - val_acc: 1.0000\n",
      "Epoch 615/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.3000 - acc: 0.9630 - val_loss: 0.4335 - val_acc: 1.0000\n",
      "Epoch 616/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.2996 - acc: 0.9630 - val_loss: 0.4340 - val_acc: 1.0000\n",
      "Epoch 617/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.2989 - acc: 0.9556 - val_loss: 0.4331 - val_acc: 1.0000\n",
      "Epoch 618/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 0.2982 - acc: 0.9556 - val_loss: 0.4332 - val_acc: 1.0000\n",
      "Epoch 619/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.2975 - acc: 0.9630 - val_loss: 0.4305 - val_acc: 1.0000\n",
      "Epoch 620/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.2968 - acc: 0.9630 - val_loss: 0.4292 - val_acc: 1.0000\n",
      "Epoch 621/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.2962 - acc: 0.9630 - val_loss: 0.4282 - val_acc: 1.0000\n",
      "Epoch 622/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.2954 - acc: 0.9630 - val_loss: 0.4270 - val_acc: 1.0000\n",
      "Epoch 623/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.2950 - acc: 0.9630 - val_loss: 0.4262 - val_acc: 1.0000\n",
      "Epoch 624/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.2943 - acc: 0.9630 - val_loss: 0.4206 - val_acc: 1.0000\n",
      "Epoch 625/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.2934 - acc: 0.9630 - val_loss: 0.4200 - val_acc: 1.0000\n",
      "Epoch 626/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.2928 - acc: 0.9630 - val_loss: 0.4175 - val_acc: 1.0000\n",
      "Epoch 627/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.2922 - acc: 0.9630 - val_loss: 0.4154 - val_acc: 1.0000\n",
      "Epoch 628/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.2917 - acc: 0.9630 - val_loss: 0.4139 - val_acc: 1.0000\n",
      "Epoch 629/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.2909 - acc: 0.9481 - val_loss: 0.4128 - val_acc: 1.0000\n",
      "Epoch 630/2000\n",
      "135/135 [==============================] - 0s 318us/step - loss: 0.2904 - acc: 0.9556 - val_loss: 0.4123 - val_acc: 1.0000\n",
      "Epoch 631/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.2894 - acc: 0.9630 - val_loss: 0.4084 - val_acc: 1.0000\n",
      "Epoch 632/2000\n",
      "135/135 [==============================] - 0s 315us/step - loss: 0.2887 - acc: 0.9556 - val_loss: 0.4072 - val_acc: 1.0000\n",
      "Epoch 633/2000\n",
      "135/135 [==============================] - 0s 318us/step - loss: 0.2883 - acc: 0.9556 - val_loss: 0.4079 - val_acc: 1.0000\n",
      "Epoch 634/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.2875 - acc: 0.9556 - val_loss: 0.4060 - val_acc: 1.0000\n",
      "Epoch 635/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.2870 - acc: 0.9556 - val_loss: 0.4052 - val_acc: 1.0000\n",
      "Epoch 636/2000\n",
      "135/135 [==============================] - 0s 436us/step - loss: 0.2864 - acc: 0.9481 - val_loss: 0.4055 - val_acc: 1.0000\n",
      "Epoch 637/2000\n",
      "135/135 [==============================] - 0s 554us/step - loss: 0.2857 - acc: 0.9481 - val_loss: 0.4051 - val_acc: 1.0000\n",
      "Epoch 638/2000\n",
      "135/135 [==============================] - 0s 488us/step - loss: 0.2851 - acc: 0.9556 - val_loss: 0.4045 - val_acc: 1.0000\n",
      "Epoch 639/2000\n",
      "135/135 [==============================] - 0s 406us/step - loss: 0.2842 - acc: 0.9630 - val_loss: 0.4030 - val_acc: 1.0000\n",
      "Epoch 640/2000\n",
      "135/135 [==============================] - 0s 510us/step - loss: 0.2838 - acc: 0.9556 - val_loss: 0.4011 - val_acc: 1.0000\n",
      "Epoch 641/2000\n",
      "135/135 [==============================] - 0s 465us/step - loss: 0.2828 - acc: 0.9481 - val_loss: 0.4011 - val_acc: 1.0000\n",
      "Epoch 642/2000\n",
      "135/135 [==============================] - 0s 443us/step - loss: 0.2823 - acc: 0.9556 - val_loss: 0.3988 - val_acc: 1.0000\n",
      "Epoch 643/2000\n",
      "135/135 [==============================] - 0s 561us/step - loss: 0.2818 - acc: 0.9556 - val_loss: 0.3970 - val_acc: 1.0000\n",
      "Epoch 644/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 0.2812 - acc: 0.9481 - val_loss: 0.3966 - val_acc: 1.0000\n",
      "Epoch 645/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 495us/step - loss: 0.2805 - acc: 0.9556 - val_loss: 0.3943 - val_acc: 1.0000\n",
      "Epoch 646/2000\n",
      "135/135 [==============================] - 0s 561us/step - loss: 0.2798 - acc: 0.9481 - val_loss: 0.3939 - val_acc: 1.0000\n",
      "Epoch 647/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.2792 - acc: 0.9630 - val_loss: 0.3917 - val_acc: 1.0000\n",
      "Epoch 648/2000\n",
      "135/135 [==============================] - 0s 333us/step - loss: 0.2785 - acc: 0.9481 - val_loss: 0.3910 - val_acc: 1.0000\n",
      "Epoch 649/2000\n",
      "135/135 [==============================] - 0s 502us/step - loss: 0.2779 - acc: 0.9481 - val_loss: 0.3921 - val_acc: 1.0000\n",
      "Epoch 650/2000\n",
      "135/135 [==============================] - 0s 539us/step - loss: 0.2771 - acc: 0.9630 - val_loss: 0.3883 - val_acc: 1.0000\n",
      "Epoch 651/2000\n",
      "135/135 [==============================] - 0s 465us/step - loss: 0.2767 - acc: 0.9556 - val_loss: 0.3879 - val_acc: 1.0000\n",
      "Epoch 652/2000\n",
      "135/135 [==============================] - 0s 344us/step - loss: 0.2761 - acc: 0.9630 - val_loss: 0.3840 - val_acc: 1.0000\n",
      "Epoch 653/2000\n",
      "135/135 [==============================] - 0s 400us/step - loss: 0.2756 - acc: 0.9481 - val_loss: 0.3834 - val_acc: 1.0000\n",
      "Epoch 654/2000\n",
      "135/135 [==============================] - 0s 414us/step - loss: 0.2749 - acc: 0.9630 - val_loss: 0.3808 - val_acc: 1.0000\n",
      "Epoch 655/2000\n",
      "135/135 [==============================] - 0s 547us/step - loss: 0.2740 - acc: 0.9556 - val_loss: 0.3813 - val_acc: 1.0000\n",
      "Epoch 656/2000\n",
      "135/135 [==============================] - 0s 495us/step - loss: 0.2737 - acc: 0.9556 - val_loss: 0.3829 - val_acc: 1.0000\n",
      "Epoch 657/2000\n",
      "135/135 [==============================] - 0s 757us/step - loss: 0.2730 - acc: 0.9481 - val_loss: 0.3807 - val_acc: 1.0000\n",
      "Epoch 658/2000\n",
      "135/135 [==============================] - 0s 997us/step - loss: 0.2724 - acc: 0.9556 - val_loss: 0.3802 - val_acc: 1.0000\n",
      "Epoch 659/2000\n",
      "135/135 [==============================] - 0s 458us/step - loss: 0.2718 - acc: 0.9556 - val_loss: 0.3783 - val_acc: 1.0000\n",
      "Epoch 660/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.2713 - acc: 0.9556 - val_loss: 0.3787 - val_acc: 1.0000\n",
      "Epoch 661/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.2708 - acc: 0.9556 - val_loss: 0.3773 - val_acc: 1.0000\n",
      "Epoch 662/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.2699 - acc: 0.9556 - val_loss: 0.3757 - val_acc: 1.0000\n",
      "Epoch 663/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.2694 - acc: 0.9481 - val_loss: 0.3731 - val_acc: 1.0000\n",
      "Epoch 664/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.2690 - acc: 0.9481 - val_loss: 0.3725 - val_acc: 1.0000\n",
      "Epoch 665/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.2683 - acc: 0.9630 - val_loss: 0.3698 - val_acc: 1.0000\n",
      "Epoch 666/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.2676 - acc: 0.9556 - val_loss: 0.3718 - val_acc: 1.0000\n",
      "Epoch 667/2000\n",
      "135/135 [==============================] - 0s 385us/step - loss: 0.2670 - acc: 0.9556 - val_loss: 0.3707 - val_acc: 1.0000\n",
      "Epoch 668/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 0.2665 - acc: 0.9556 - val_loss: 0.3689 - val_acc: 1.0000\n",
      "Epoch 669/2000\n",
      "135/135 [==============================] - 0s 517us/step - loss: 0.2662 - acc: 0.9556 - val_loss: 0.3676 - val_acc: 1.0000\n",
      "Epoch 670/2000\n",
      "135/135 [==============================] - 0s 414us/step - loss: 0.2653 - acc: 0.9556 - val_loss: 0.3656 - val_acc: 1.0000\n",
      "Epoch 671/2000\n",
      "135/135 [==============================] - 0s 451us/step - loss: 0.2647 - acc: 0.9630 - val_loss: 0.3644 - val_acc: 1.0000\n",
      "Epoch 672/2000\n",
      "135/135 [==============================] - 0s 428us/step - loss: 0.2640 - acc: 0.9556 - val_loss: 0.3645 - val_acc: 1.0000\n",
      "Epoch 673/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.2634 - acc: 0.9630 - val_loss: 0.3619 - val_acc: 1.0000\n",
      "Epoch 674/2000\n",
      "135/135 [==============================] - 0s 561us/step - loss: 0.2630 - acc: 0.9556 - val_loss: 0.3573 - val_acc: 1.0000\n",
      "Epoch 675/2000\n",
      "135/135 [==============================] - 0s 539us/step - loss: 0.2625 - acc: 0.9556 - val_loss: 0.3566 - val_acc: 1.0000\n",
      "Epoch 676/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 0.2621 - acc: 0.9556 - val_loss: 0.3545 - val_acc: 1.0000\n",
      "Epoch 677/2000\n",
      "135/135 [==============================] - 0s 480us/step - loss: 0.2611 - acc: 0.9556 - val_loss: 0.3553 - val_acc: 1.0000\n",
      "Epoch 678/2000\n",
      "135/135 [==============================] - 0s 517us/step - loss: 0.2607 - acc: 0.9556 - val_loss: 0.3574 - val_acc: 1.0000\n",
      "Epoch 679/2000\n",
      "135/135 [==============================] - 0s 736us/step - loss: 0.2600 - acc: 0.9556 - val_loss: 0.3560 - val_acc: 1.0000\n",
      "Epoch 680/2000\n",
      "135/135 [==============================] - 0s 561us/step - loss: 0.2595 - acc: 0.9556 - val_loss: 0.3532 - val_acc: 1.0000\n",
      "Epoch 681/2000\n",
      "135/135 [==============================] - 0s 414us/step - loss: 0.2593 - acc: 0.9556 - val_loss: 0.3521 - val_acc: 1.0000\n",
      "Epoch 682/2000\n",
      "135/135 [==============================] - 0s 443us/step - loss: 0.2585 - acc: 0.9556 - val_loss: 0.3509 - val_acc: 1.0000\n",
      "Epoch 683/2000\n",
      "135/135 [==============================] - 0s 465us/step - loss: 0.2578 - acc: 0.9481 - val_loss: 0.3511 - val_acc: 1.0000\n",
      "Epoch 684/2000\n",
      "135/135 [==============================] - 0s 473us/step - loss: 0.2576 - acc: 0.9556 - val_loss: 0.3501 - val_acc: 1.0000\n",
      "Epoch 685/2000\n",
      "135/135 [==============================] - 0s 414us/step - loss: 0.2567 - acc: 0.9556 - val_loss: 0.3498 - val_acc: 1.0000\n",
      "Epoch 686/2000\n",
      "135/135 [==============================] - 0s 628us/step - loss: 0.2562 - acc: 0.9556 - val_loss: 0.3489 - val_acc: 1.0000\n",
      "Epoch 687/2000\n",
      "135/135 [==============================] - 0s 517us/step - loss: 0.2556 - acc: 0.9481 - val_loss: 0.3470 - val_acc: 1.0000\n",
      "Epoch 688/2000\n",
      "135/135 [==============================] - 0s 510us/step - loss: 0.2549 - acc: 0.9481 - val_loss: 0.3459 - val_acc: 1.0000\n",
      "Epoch 689/2000\n",
      "135/135 [==============================] - 0s 421us/step - loss: 0.2547 - acc: 0.9556 - val_loss: 0.3455 - val_acc: 1.0000\n",
      "Epoch 690/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.2539 - acc: 0.9556 - val_loss: 0.3438 - val_acc: 1.0000\n",
      "Epoch 691/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 0.2534 - acc: 0.9481 - val_loss: 0.3402 - val_acc: 1.0000\n",
      "Epoch 692/2000\n",
      "135/135 [==============================] - 0s 487us/step - loss: 0.2531 - acc: 0.9556 - val_loss: 0.3410 - val_acc: 1.0000\n",
      "Epoch 693/2000\n",
      "135/135 [==============================] - 0s 414us/step - loss: 0.2523 - acc: 0.9556 - val_loss: 0.3386 - val_acc: 1.0000\n",
      "Epoch 694/2000\n",
      "135/135 [==============================] - 0s 525us/step - loss: 0.2518 - acc: 0.9630 - val_loss: 0.3367 - val_acc: 1.0000\n",
      "Epoch 695/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.2513 - acc: 0.9556 - val_loss: 0.3366 - val_acc: 1.0000\n",
      "Epoch 696/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.2509 - acc: 0.9556 - val_loss: 0.3353 - val_acc: 1.0000\n",
      "Epoch 697/2000\n",
      "135/135 [==============================] - 0s 421us/step - loss: 0.2503 - acc: 0.9556 - val_loss: 0.3359 - val_acc: 1.0000\n",
      "Epoch 698/2000\n",
      "135/135 [==============================] - 0s 414us/step - loss: 0.2496 - acc: 0.9556 - val_loss: 0.3361 - val_acc: 1.0000\n",
      "Epoch 699/2000\n",
      "135/135 [==============================] - 0s 598us/step - loss: 0.2490 - acc: 0.9556 - val_loss: 0.3329 - val_acc: 1.0000\n",
      "Epoch 700/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.2487 - acc: 0.9556 - val_loss: 0.3329 - val_acc: 1.0000\n",
      "Epoch 701/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.2481 - acc: 0.9556 - val_loss: 0.3337 - val_acc: 1.0000\n",
      "Epoch 702/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.2474 - acc: 0.9556 - val_loss: 0.3310 - val_acc: 1.0000\n",
      "Epoch 703/2000\n",
      "135/135 [==============================] - 0s 318us/step - loss: 0.2470 - acc: 0.9556 - val_loss: 0.3296 - val_acc: 1.0000\n",
      "Epoch 704/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 340us/step - loss: 0.2465 - acc: 0.9556 - val_loss: 0.3295 - val_acc: 1.0000\n",
      "Epoch 705/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.2460 - acc: 0.9630 - val_loss: 0.3262 - val_acc: 1.0000\n",
      "Epoch 706/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.2456 - acc: 0.9481 - val_loss: 0.3251 - val_acc: 1.0000\n",
      "Epoch 707/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.2450 - acc: 0.9556 - val_loss: 0.3260 - val_acc: 1.0000\n",
      "Epoch 708/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.2444 - acc: 0.9481 - val_loss: 0.3242 - val_acc: 1.0000\n",
      "Epoch 709/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.2439 - acc: 0.9481 - val_loss: 0.3215 - val_acc: 1.0000\n",
      "Epoch 710/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.2437 - acc: 0.9556 - val_loss: 0.3229 - val_acc: 1.0000\n",
      "Epoch 711/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.2428 - acc: 0.9556 - val_loss: 0.3213 - val_acc: 1.0000\n",
      "Epoch 712/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.2425 - acc: 0.9556 - val_loss: 0.3200 - val_acc: 1.0000\n",
      "Epoch 713/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.2420 - acc: 0.9630 - val_loss: 0.3173 - val_acc: 1.0000\n",
      "Epoch 714/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.2416 - acc: 0.9556 - val_loss: 0.3184 - val_acc: 1.0000\n",
      "Epoch 715/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.2410 - acc: 0.9556 - val_loss: 0.3187 - val_acc: 1.0000\n",
      "Epoch 716/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.2404 - acc: 0.9556 - val_loss: 0.3190 - val_acc: 1.0000\n",
      "Epoch 717/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.2400 - acc: 0.9556 - val_loss: 0.3188 - val_acc: 1.0000\n",
      "Epoch 718/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.2394 - acc: 0.9556 - val_loss: 0.3175 - val_acc: 1.0000\n",
      "Epoch 719/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.2391 - acc: 0.9556 - val_loss: 0.3151 - val_acc: 1.0000\n",
      "Epoch 720/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.2383 - acc: 0.9556 - val_loss: 0.3134 - val_acc: 1.0000\n",
      "Epoch 721/2000\n",
      "135/135 [==============================] - 0s 414us/step - loss: 0.2379 - acc: 0.9556 - val_loss: 0.3147 - val_acc: 1.0000\n",
      "Epoch 722/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.2376 - acc: 0.9556 - val_loss: 0.3144 - val_acc: 1.0000\n",
      "Epoch 723/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.2370 - acc: 0.9556 - val_loss: 0.3148 - val_acc: 1.0000\n",
      "Epoch 724/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.2366 - acc: 0.9556 - val_loss: 0.3139 - val_acc: 1.0000\n",
      "Epoch 725/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.2360 - acc: 0.9556 - val_loss: 0.3124 - val_acc: 1.0000\n",
      "Epoch 726/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.2354 - acc: 0.9556 - val_loss: 0.3105 - val_acc: 1.0000\n",
      "Epoch 727/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.2350 - acc: 0.9556 - val_loss: 0.3070 - val_acc: 1.0000\n",
      "Epoch 728/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.2347 - acc: 0.9630 - val_loss: 0.3033 - val_acc: 1.0000\n",
      "Epoch 729/2000\n",
      "135/135 [==============================] - 0s 370us/step - loss: 0.2340 - acc: 0.9704 - val_loss: 0.3077 - val_acc: 1.0000\n",
      "Epoch 730/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.2337 - acc: 0.9556 - val_loss: 0.3068 - val_acc: 1.0000\n",
      "Epoch 731/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.2332 - acc: 0.9556 - val_loss: 0.3058 - val_acc: 1.0000\n",
      "Epoch 732/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.2326 - acc: 0.9630 - val_loss: 0.3071 - val_acc: 1.0000\n",
      "Epoch 733/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.2323 - acc: 0.9556 - val_loss: 0.3067 - val_acc: 1.0000\n",
      "Epoch 734/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.2316 - acc: 0.9556 - val_loss: 0.3049 - val_acc: 1.0000\n",
      "Epoch 735/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.2313 - acc: 0.9556 - val_loss: 0.3031 - val_acc: 1.0000\n",
      "Epoch 736/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.2308 - acc: 0.9556 - val_loss: 0.3055 - val_acc: 1.0000\n",
      "Epoch 737/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.2306 - acc: 0.9556 - val_loss: 0.3022 - val_acc: 1.0000\n",
      "Epoch 738/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.2298 - acc: 0.9630 - val_loss: 0.3024 - val_acc: 1.0000\n",
      "Epoch 739/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.2292 - acc: 0.9556 - val_loss: 0.2980 - val_acc: 1.0000\n",
      "Epoch 740/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.2289 - acc: 0.9630 - val_loss: 0.2952 - val_acc: 1.0000\n",
      "Epoch 741/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.2283 - acc: 0.9630 - val_loss: 0.2972 - val_acc: 1.0000\n",
      "Epoch 742/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 0.2282 - acc: 0.9630 - val_loss: 0.2973 - val_acc: 1.0000\n",
      "Epoch 743/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.2277 - acc: 0.9556 - val_loss: 0.2966 - val_acc: 1.0000\n",
      "Epoch 744/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.2271 - acc: 0.9630 - val_loss: 0.2966 - val_acc: 1.0000\n",
      "Epoch 745/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.2266 - acc: 0.9556 - val_loss: 0.2949 - val_acc: 1.0000\n",
      "Epoch 746/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.2259 - acc: 0.9556 - val_loss: 0.2929 - val_acc: 1.0000\n",
      "Epoch 747/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.2256 - acc: 0.9556 - val_loss: 0.2907 - val_acc: 1.0000\n",
      "Epoch 748/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.2254 - acc: 0.9556 - val_loss: 0.2905 - val_acc: 1.0000\n",
      "Epoch 749/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.2247 - acc: 0.9630 - val_loss: 0.2906 - val_acc: 1.0000\n",
      "Epoch 750/2000\n",
      "135/135 [==============================] - 0s 310us/step - loss: 0.2245 - acc: 0.9556 - val_loss: 0.2886 - val_acc: 1.0000\n",
      "Epoch 751/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.2241 - acc: 0.9630 - val_loss: 0.2878 - val_acc: 1.0000\n",
      "Epoch 752/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.2235 - acc: 0.9556 - val_loss: 0.2866 - val_acc: 1.0000\n",
      "Epoch 753/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.2229 - acc: 0.9630 - val_loss: 0.2871 - val_acc: 1.0000\n",
      "Epoch 754/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.2227 - acc: 0.9630 - val_loss: 0.2874 - val_acc: 1.0000\n",
      "Epoch 755/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.2225 - acc: 0.9556 - val_loss: 0.2852 - val_acc: 1.0000\n",
      "Epoch 756/2000\n",
      "135/135 [==============================] - 0s 414us/step - loss: 0.2221 - acc: 0.9630 - val_loss: 0.2851 - val_acc: 1.0000\n",
      "Epoch 757/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.2214 - acc: 0.9630 - val_loss: 0.2849 - val_acc: 1.0000\n",
      "Epoch 758/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.2211 - acc: 0.9556 - val_loss: 0.2831 - val_acc: 1.0000\n",
      "Epoch 759/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.2206 - acc: 0.9556 - val_loss: 0.2822 - val_acc: 1.0000\n",
      "Epoch 760/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.2202 - acc: 0.9630 - val_loss: 0.2819 - val_acc: 1.0000\n",
      "Epoch 761/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.2198 - acc: 0.9630 - val_loss: 0.2813 - val_acc: 1.0000\n",
      "Epoch 762/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.2194 - acc: 0.9556 - val_loss: 0.2807 - val_acc: 1.0000\n",
      "Epoch 763/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 318us/step - loss: 0.2189 - acc: 0.9556 - val_loss: 0.2790 - val_acc: 1.0000\n",
      "Epoch 764/2000\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.3286 - acc: 0.800 - 0s 347us/step - loss: 0.2186 - acc: 0.9630 - val_loss: 0.2771 - val_acc: 1.0000\n",
      "Epoch 765/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.2186 - acc: 0.9556 - val_loss: 0.2769 - val_acc: 1.0000\n",
      "Epoch 766/2000\n",
      "135/135 [==============================] - 0s 436us/step - loss: 0.2176 - acc: 0.9556 - val_loss: 0.2765 - val_acc: 1.0000\n",
      "Epoch 767/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.2169 - acc: 0.9630 - val_loss: 0.2764 - val_acc: 1.0000\n",
      "Epoch 768/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.2167 - acc: 0.9556 - val_loss: 0.2779 - val_acc: 1.0000\n",
      "Epoch 769/2000\n",
      "135/135 [==============================] - 0s 320us/step - loss: 0.2161 - acc: 0.9556 - val_loss: 0.2758 - val_acc: 1.0000\n",
      "Epoch 770/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.2158 - acc: 0.9630 - val_loss: 0.2746 - val_acc: 1.0000\n",
      "Epoch 771/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.2155 - acc: 0.9630 - val_loss: 0.2737 - val_acc: 1.0000\n",
      "Epoch 772/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.2151 - acc: 0.9556 - val_loss: 0.2708 - val_acc: 1.0000\n",
      "Epoch 773/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.2148 - acc: 0.9630 - val_loss: 0.2707 - val_acc: 1.0000\n",
      "Epoch 774/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.2141 - acc: 0.9556 - val_loss: 0.2685 - val_acc: 1.0000\n",
      "Epoch 775/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.2138 - acc: 0.9630 - val_loss: 0.2687 - val_acc: 1.0000\n",
      "Epoch 776/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.2135 - acc: 0.9630 - val_loss: 0.2711 - val_acc: 1.0000\n",
      "Epoch 777/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.2131 - acc: 0.9630 - val_loss: 0.2717 - val_acc: 1.0000\n",
      "Epoch 778/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.2125 - acc: 0.9630 - val_loss: 0.2705 - val_acc: 1.0000\n",
      "Epoch 779/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.2122 - acc: 0.9630 - val_loss: 0.2702 - val_acc: 1.0000\n",
      "Epoch 780/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.2118 - acc: 0.9630 - val_loss: 0.2719 - val_acc: 1.0000\n",
      "Epoch 781/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.2114 - acc: 0.9630 - val_loss: 0.2699 - val_acc: 1.0000\n",
      "Epoch 782/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.2109 - acc: 0.9630 - val_loss: 0.2678 - val_acc: 1.0000\n",
      "Epoch 783/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.2105 - acc: 0.9630 - val_loss: 0.2671 - val_acc: 1.0000\n",
      "Epoch 784/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.2102 - acc: 0.9630 - val_loss: 0.2658 - val_acc: 1.0000\n",
      "Epoch 785/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.2099 - acc: 0.9630 - val_loss: 0.2646 - val_acc: 1.0000\n",
      "Epoch 786/2000\n",
      "135/135 [==============================] - 0s 428us/step - loss: 0.2094 - acc: 0.9630 - val_loss: 0.2643 - val_acc: 1.0000\n",
      "Epoch 787/2000\n",
      "135/135 [==============================] - 0s 414us/step - loss: 0.2094 - acc: 0.9556 - val_loss: 0.2626 - val_acc: 1.0000\n",
      "Epoch 788/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.2085 - acc: 0.9630 - val_loss: 0.2631 - val_acc: 1.0000\n",
      "Epoch 789/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.2081 - acc: 0.9630 - val_loss: 0.2618 - val_acc: 1.0000\n",
      "Epoch 790/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.2079 - acc: 0.9556 - val_loss: 0.2602 - val_acc: 1.0000\n",
      "Epoch 791/2000\n",
      "135/135 [==============================] - 0s 370us/step - loss: 0.2077 - acc: 0.9556 - val_loss: 0.2574 - val_acc: 1.0000\n",
      "Epoch 792/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.2074 - acc: 0.9630 - val_loss: 0.2585 - val_acc: 1.0000\n",
      "Epoch 793/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.2067 - acc: 0.9630 - val_loss: 0.2596 - val_acc: 1.0000\n",
      "Epoch 794/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.2063 - acc: 0.9630 - val_loss: 0.2578 - val_acc: 1.0000\n",
      "Epoch 795/2000\n",
      "135/135 [==============================] - 0s 406us/step - loss: 0.2060 - acc: 0.9556 - val_loss: 0.2564 - val_acc: 1.0000\n",
      "Epoch 796/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.2056 - acc: 0.9704 - val_loss: 0.2583 - val_acc: 1.0000\n",
      "Epoch 797/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.2055 - acc: 0.9630 - val_loss: 0.2569 - val_acc: 1.0000\n",
      "Epoch 798/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.2051 - acc: 0.9630 - val_loss: 0.2578 - val_acc: 1.0000\n",
      "Epoch 799/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.2047 - acc: 0.9630 - val_loss: 0.2566 - val_acc: 1.0000\n",
      "Epoch 800/2000\n",
      "135/135 [==============================] - 0s 406us/step - loss: 0.2044 - acc: 0.9630 - val_loss: 0.2540 - val_acc: 1.0000\n",
      "Epoch 801/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.2039 - acc: 0.9630 - val_loss: 0.2536 - val_acc: 1.0000\n",
      "Epoch 802/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.2035 - acc: 0.9630 - val_loss: 0.2533 - val_acc: 1.0000\n",
      "Epoch 803/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.2031 - acc: 0.9630 - val_loss: 0.2533 - val_acc: 1.0000\n",
      "Epoch 804/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.2026 - acc: 0.9630 - val_loss: 0.2546 - val_acc: 1.0000\n",
      "Epoch 805/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.2023 - acc: 0.9630 - val_loss: 0.2535 - val_acc: 1.0000\n",
      "Epoch 806/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.2019 - acc: 0.9630 - val_loss: 0.2522 - val_acc: 1.0000\n",
      "Epoch 807/2000\n",
      "135/135 [==============================] - 0s 421us/step - loss: 0.2015 - acc: 0.9630 - val_loss: 0.2508 - val_acc: 1.0000\n",
      "Epoch 808/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.2012 - acc: 0.9630 - val_loss: 0.2507 - val_acc: 1.0000\n",
      "Epoch 809/2000\n",
      "135/135 [==============================] - 0s 318us/step - loss: 0.2008 - acc: 0.9630 - val_loss: 0.2498 - val_acc: 1.0000\n",
      "Epoch 810/2000\n",
      "135/135 [==============================] - 0s 399us/step - loss: 0.2005 - acc: 0.9630 - val_loss: 0.2502 - val_acc: 1.0000\n",
      "Epoch 811/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 0.2001 - acc: 0.9630 - val_loss: 0.2457 - val_acc: 1.0000\n",
      "Epoch 812/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.1998 - acc: 0.9630 - val_loss: 0.2454 - val_acc: 1.0000\n",
      "Epoch 813/2000\n",
      "135/135 [==============================] - 0s 428us/step - loss: 0.1996 - acc: 0.9630 - val_loss: 0.2444 - val_acc: 1.0000\n",
      "Epoch 814/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1991 - acc: 0.9630 - val_loss: 0.2440 - val_acc: 1.0000\n",
      "Epoch 815/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.1988 - acc: 0.9630 - val_loss: 0.2461 - val_acc: 1.0000\n",
      "Epoch 816/2000\n",
      "135/135 [==============================] - 0s 399us/step - loss: 0.1981 - acc: 0.9630 - val_loss: 0.2442 - val_acc: 1.0000\n",
      "Epoch 817/2000\n",
      "135/135 [==============================] - 0s 399us/step - loss: 0.1979 - acc: 0.9630 - val_loss: 0.2439 - val_acc: 1.0000\n",
      "Epoch 818/2000\n",
      "135/135 [==============================] - 0s 414us/step - loss: 0.1976 - acc: 0.9630 - val_loss: 0.2432 - val_acc: 1.0000\n",
      "Epoch 819/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1973 - acc: 0.9630 - val_loss: 0.2438 - val_acc: 1.0000\n",
      "Epoch 820/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.1969 - acc: 0.9630 - val_loss: 0.2433 - val_acc: 1.0000\n",
      "Epoch 821/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1964 - acc: 0.9704 - val_loss: 0.2452 - val_acc: 1.0000\n",
      "Epoch 822/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 332us/step - loss: 0.1962 - acc: 0.9630 - val_loss: 0.2425 - val_acc: 1.0000\n",
      "Epoch 823/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 0.1960 - acc: 0.9630 - val_loss: 0.2411 - val_acc: 1.0000\n",
      "Epoch 824/2000\n",
      "135/135 [==============================] - 0s 428us/step - loss: 0.1957 - acc: 0.9630 - val_loss: 0.2401 - val_acc: 1.0000\n",
      "Epoch 825/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.1953 - acc: 0.9630 - val_loss: 0.2380 - val_acc: 1.0000\n",
      "Epoch 826/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.1948 - acc: 0.9704 - val_loss: 0.2414 - val_acc: 1.0000\n",
      "Epoch 827/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1945 - acc: 0.9630 - val_loss: 0.2407 - val_acc: 1.0000\n",
      "Epoch 828/2000\n",
      "135/135 [==============================] - 0s 354us/step - loss: 0.1941 - acc: 0.9630 - val_loss: 0.2400 - val_acc: 1.0000\n",
      "Epoch 829/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1938 - acc: 0.9630 - val_loss: 0.2406 - val_acc: 1.0000\n",
      "Epoch 830/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1934 - acc: 0.9630 - val_loss: 0.2380 - val_acc: 1.0000\n",
      "Epoch 831/2000\n",
      "135/135 [==============================] - 0s 399us/step - loss: 0.1931 - acc: 0.9630 - val_loss: 0.2380 - val_acc: 1.0000\n",
      "Epoch 832/2000\n",
      "135/135 [==============================] - 0s 345us/step - loss: 0.1926 - acc: 0.9630 - val_loss: 0.2382 - val_acc: 1.0000\n",
      "Epoch 833/2000\n",
      "135/135 [==============================] - 0s 399us/step - loss: 0.1926 - acc: 0.9630 - val_loss: 0.2377 - val_acc: 1.0000\n",
      "Epoch 834/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1924 - acc: 0.9630 - val_loss: 0.2368 - val_acc: 1.0000\n",
      "Epoch 835/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1917 - acc: 0.9630 - val_loss: 0.2345 - val_acc: 1.0000\n",
      "Epoch 836/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.1916 - acc: 0.9630 - val_loss: 0.2340 - val_acc: 1.0000\n",
      "Epoch 837/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1911 - acc: 0.9630 - val_loss: 0.2314 - val_acc: 1.0000\n",
      "Epoch 838/2000\n",
      "135/135 [==============================] - 0s 399us/step - loss: 0.1908 - acc: 0.9630 - val_loss: 0.2294 - val_acc: 1.0000\n",
      "Epoch 839/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.1908 - acc: 0.9630 - val_loss: 0.2295 - val_acc: 1.0000\n",
      "Epoch 840/2000\n",
      "135/135 [==============================] - 0s 421us/step - loss: 0.1901 - acc: 0.9704 - val_loss: 0.2322 - val_acc: 1.0000\n",
      "Epoch 841/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1898 - acc: 0.9630 - val_loss: 0.2330 - val_acc: 1.0000\n",
      "Epoch 842/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1898 - acc: 0.9630 - val_loss: 0.2313 - val_acc: 1.0000\n",
      "Epoch 843/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.1892 - acc: 0.9630 - val_loss: 0.2288 - val_acc: 1.0000\n",
      "Epoch 844/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1887 - acc: 0.9704 - val_loss: 0.2297 - val_acc: 1.0000\n",
      "Epoch 845/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1884 - acc: 0.9704 - val_loss: 0.2307 - val_acc: 1.0000\n",
      "Epoch 846/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.1883 - acc: 0.9630 - val_loss: 0.2297 - val_acc: 1.0000\n",
      "Epoch 847/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1880 - acc: 0.9556 - val_loss: 0.2281 - val_acc: 1.0000\n",
      "Epoch 848/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1876 - acc: 0.9630 - val_loss: 0.2281 - val_acc: 1.0000\n",
      "Epoch 849/2000\n",
      "135/135 [==============================] - 0s 406us/step - loss: 0.1873 - acc: 0.9630 - val_loss: 0.2252 - val_acc: 1.0000\n",
      "Epoch 850/2000\n",
      "135/135 [==============================] - 0s 399us/step - loss: 0.1870 - acc: 0.9630 - val_loss: 0.2270 - val_acc: 1.0000\n",
      "Epoch 851/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1868 - acc: 0.9630 - val_loss: 0.2253 - val_acc: 1.0000\n",
      "Epoch 852/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.1865 - acc: 0.9630 - val_loss: 0.2243 - val_acc: 1.0000\n",
      "Epoch 853/2000\n",
      "135/135 [==============================] - 0s 473us/step - loss: 0.1859 - acc: 0.9704 - val_loss: 0.2259 - val_acc: 1.0000\n",
      "Epoch 854/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1857 - acc: 0.9630 - val_loss: 0.2264 - val_acc: 1.0000\n",
      "Epoch 855/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1854 - acc: 0.9630 - val_loss: 0.2249 - val_acc: 1.0000\n",
      "Epoch 856/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.1852 - acc: 0.9630 - val_loss: 0.2238 - val_acc: 1.0000\n",
      "Epoch 857/2000\n",
      "135/135 [==============================] - 0s 576us/step - loss: 0.1849 - acc: 0.9630 - val_loss: 0.2235 - val_acc: 1.0000\n",
      "Epoch 858/2000\n",
      "135/135 [==============================] - 0s 421us/step - loss: 0.1846 - acc: 0.9704 - val_loss: 0.2243 - val_acc: 1.0000\n",
      "Epoch 859/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1845 - acc: 0.9630 - val_loss: 0.2221 - val_acc: 1.0000\n",
      "Epoch 860/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.1838 - acc: 0.9630 - val_loss: 0.2192 - val_acc: 1.0000\n",
      "Epoch 861/2000\n",
      "135/135 [==============================] - 0s 414us/step - loss: 0.1837 - acc: 0.9630 - val_loss: 0.2191 - val_acc: 1.0000\n",
      "Epoch 862/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1833 - acc: 0.9630 - val_loss: 0.2178 - val_acc: 1.0000\n",
      "Epoch 863/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.1831 - acc: 0.9630 - val_loss: 0.2156 - val_acc: 1.0000\n",
      "Epoch 864/2000\n",
      "135/135 [==============================] - 0s 318us/step - loss: 0.1831 - acc: 0.9630 - val_loss: 0.2169 - val_acc: 1.0000\n",
      "Epoch 865/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1827 - acc: 0.9704 - val_loss: 0.2170 - val_acc: 1.0000\n",
      "Epoch 866/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.1822 - acc: 0.9704 - val_loss: 0.2157 - val_acc: 1.0000\n",
      "Epoch 867/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.1819 - acc: 0.9704 - val_loss: 0.2174 - val_acc: 1.0000\n",
      "Epoch 868/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.1816 - acc: 0.9704 - val_loss: 0.2173 - val_acc: 1.0000\n",
      "Epoch 869/2000\n",
      "135/135 [==============================] - 0s 465us/step - loss: 0.1815 - acc: 0.9630 - val_loss: 0.2167 - val_acc: 1.0000\n",
      "Epoch 870/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1808 - acc: 0.9704 - val_loss: 0.2156 - val_acc: 1.0000\n",
      "Epoch 871/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1810 - acc: 0.9630 - val_loss: 0.2137 - val_acc: 1.0000\n",
      "Epoch 872/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1802 - acc: 0.9630 - val_loss: 0.2128 - val_acc: 1.0000\n",
      "Epoch 873/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.1805 - acc: 0.9630 - val_loss: 0.2136 - val_acc: 1.0000\n",
      "Epoch 874/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1798 - acc: 0.9704 - val_loss: 0.2124 - val_acc: 1.0000\n",
      "Epoch 875/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1794 - acc: 0.9704 - val_loss: 0.2123 - val_acc: 1.0000\n",
      "Epoch 876/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1791 - acc: 0.9704 - val_loss: 0.2120 - val_acc: 1.0000\n",
      "Epoch 877/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.1790 - acc: 0.9704 - val_loss: 0.2125 - val_acc: 1.0000\n",
      "Epoch 878/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1789 - acc: 0.9704 - val_loss: 0.2111 - val_acc: 1.0000\n",
      "Epoch 879/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1784 - acc: 0.9704 - val_loss: 0.2132 - val_acc: 1.0000\n",
      "Epoch 880/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.1785 - acc: 0.9630 - val_loss: 0.2102 - val_acc: 1.0000\n",
      "Epoch 881/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 392us/step - loss: 0.1778 - acc: 0.9704 - val_loss: 0.2101 - val_acc: 1.0000\n",
      "Epoch 882/2000\n",
      "135/135 [==============================] - 0s 406us/step - loss: 0.1777 - acc: 0.9704 - val_loss: 0.2115 - val_acc: 1.0000\n",
      "Epoch 883/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.1772 - acc: 0.9630 - val_loss: 0.2103 - val_acc: 1.0000\n",
      "Epoch 884/2000\n",
      "135/135 [==============================] - 0s 308us/step - loss: 0.1768 - acc: 0.9630 - val_loss: 0.2090 - val_acc: 1.0000\n",
      "Epoch 885/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.1770 - acc: 0.9630 - val_loss: 0.2097 - val_acc: 1.0000\n",
      "Epoch 886/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1763 - acc: 0.9630 - val_loss: 0.2082 - val_acc: 1.0000\n",
      "Epoch 887/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.1762 - acc: 0.9704 - val_loss: 0.2089 - val_acc: 1.0000\n",
      "Epoch 888/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1757 - acc: 0.9630 - val_loss: 0.2078 - val_acc: 1.0000\n",
      "Epoch 889/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1759 - acc: 0.9704 - val_loss: 0.2099 - val_acc: 1.0000\n",
      "Epoch 890/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1753 - acc: 0.9704 - val_loss: 0.2098 - val_acc: 1.0000\n",
      "Epoch 891/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1750 - acc: 0.9704 - val_loss: 0.2081 - val_acc: 1.0000\n",
      "Epoch 892/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1746 - acc: 0.9704 - val_loss: 0.2065 - val_acc: 1.0000\n",
      "Epoch 893/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1745 - acc: 0.9630 - val_loss: 0.2052 - val_acc: 1.0000\n",
      "Epoch 894/2000\n",
      "135/135 [==============================] - 0s 378us/step - loss: 0.1741 - acc: 0.9704 - val_loss: 0.2056 - val_acc: 1.0000\n",
      "Epoch 895/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1739 - acc: 0.9704 - val_loss: 0.2060 - val_acc: 1.0000\n",
      "Epoch 896/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1736 - acc: 0.9704 - val_loss: 0.2056 - val_acc: 1.0000\n",
      "Epoch 897/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1733 - acc: 0.9630 - val_loss: 0.2044 - val_acc: 1.0000\n",
      "Epoch 898/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1734 - acc: 0.9630 - val_loss: 0.2031 - val_acc: 1.0000\n",
      "Epoch 899/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.1731 - acc: 0.9704 - val_loss: 0.2047 - val_acc: 1.0000\n",
      "Epoch 900/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1728 - acc: 0.9630 - val_loss: 0.2034 - val_acc: 1.0000\n",
      "Epoch 901/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1722 - acc: 0.9630 - val_loss: 0.2021 - val_acc: 1.0000\n",
      "Epoch 902/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1719 - acc: 0.9630 - val_loss: 0.2011 - val_acc: 1.0000\n",
      "Epoch 903/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1719 - acc: 0.9704 - val_loss: 0.2029 - val_acc: 1.0000\n",
      "Epoch 904/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1715 - acc: 0.9704 - val_loss: 0.2035 - val_acc: 1.0000\n",
      "Epoch 905/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.1717 - acc: 0.9704 - val_loss: 0.2031 - val_acc: 1.0000\n",
      "Epoch 906/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1710 - acc: 0.9704 - val_loss: 0.2056 - val_acc: 1.0000\n",
      "Epoch 907/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1711 - acc: 0.9704 - val_loss: 0.2030 - val_acc: 1.0000\n",
      "Epoch 908/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.1706 - acc: 0.9704 - val_loss: 0.2024 - val_acc: 1.0000\n",
      "Epoch 909/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1704 - acc: 0.9630 - val_loss: 0.2004 - val_acc: 1.0000\n",
      "Epoch 910/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1700 - acc: 0.9630 - val_loss: 0.1973 - val_acc: 1.0000\n",
      "Epoch 911/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1697 - acc: 0.9704 - val_loss: 0.1980 - val_acc: 1.0000\n",
      "Epoch 912/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.1693 - acc: 0.9704 - val_loss: 0.1978 - val_acc: 1.0000\n",
      "Epoch 913/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.1689 - acc: 0.9704 - val_loss: 0.1978 - val_acc: 1.0000\n",
      "Epoch 914/2000\n",
      "135/135 [==============================] - 0s 414us/step - loss: 0.1687 - acc: 0.9704 - val_loss: 0.1962 - val_acc: 1.0000\n",
      "Epoch 915/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.1685 - acc: 0.9704 - val_loss: 0.1947 - val_acc: 1.0000\n",
      "Epoch 916/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.1683 - acc: 0.9630 - val_loss: 0.1936 - val_acc: 1.0000\n",
      "Epoch 917/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1681 - acc: 0.9704 - val_loss: 0.1975 - val_acc: 1.0000\n",
      "Epoch 918/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1679 - acc: 0.9704 - val_loss: 0.1969 - val_acc: 1.0000\n",
      "Epoch 919/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.1677 - acc: 0.9704 - val_loss: 0.1965 - val_acc: 1.0000\n",
      "Epoch 920/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1673 - acc: 0.9704 - val_loss: 0.1974 - val_acc: 1.0000\n",
      "Epoch 921/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 0.1673 - acc: 0.9704 - val_loss: 0.1960 - val_acc: 1.0000\n",
      "Epoch 922/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1669 - acc: 0.9630 - val_loss: 0.1935 - val_acc: 1.0000\n",
      "Epoch 923/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.1670 - acc: 0.9704 - val_loss: 0.1919 - val_acc: 1.0000\n",
      "Epoch 924/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.1664 - acc: 0.9704 - val_loss: 0.1920 - val_acc: 1.0000\n",
      "Epoch 925/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.1661 - acc: 0.9704 - val_loss: 0.1929 - val_acc: 1.0000\n",
      "Epoch 926/2000\n",
      "135/135 [==============================] - 0s 318us/step - loss: 0.1659 - acc: 0.9630 - val_loss: 0.1900 - val_acc: 1.0000\n",
      "Epoch 927/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.1655 - acc: 0.9704 - val_loss: 0.1919 - val_acc: 1.0000\n",
      "Epoch 928/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1655 - acc: 0.9704 - val_loss: 0.1926 - val_acc: 1.0000\n",
      "Epoch 929/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.1652 - acc: 0.9630 - val_loss: 0.1912 - val_acc: 1.0000\n",
      "Epoch 930/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1649 - acc: 0.9704 - val_loss: 0.1916 - val_acc: 1.0000\n",
      "Epoch 931/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1648 - acc: 0.9704 - val_loss: 0.1926 - val_acc: 1.0000\n",
      "Epoch 932/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.1649 - acc: 0.9704 - val_loss: 0.1919 - val_acc: 1.0000\n",
      "Epoch 933/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.1642 - acc: 0.9704 - val_loss: 0.1930 - val_acc: 1.0000\n",
      "Epoch 934/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 0.1641 - acc: 0.9704 - val_loss: 0.1926 - val_acc: 1.0000\n",
      "Epoch 935/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1635 - acc: 0.9704 - val_loss: 0.1942 - val_acc: 1.0000\n",
      "Epoch 936/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 0.1637 - acc: 0.9704 - val_loss: 0.1914 - val_acc: 1.0000\n",
      "Epoch 937/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.1632 - acc: 0.9704 - val_loss: 0.1888 - val_acc: 1.0000\n",
      "Epoch 938/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1632 - acc: 0.9704 - val_loss: 0.1902 - val_acc: 1.0000\n",
      "Epoch 939/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1626 - acc: 0.9704 - val_loss: 0.1908 - val_acc: 1.0000\n",
      "Epoch 940/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 303us/step - loss: 0.1625 - acc: 0.9704 - val_loss: 0.1910 - val_acc: 1.0000\n",
      "Epoch 941/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1625 - acc: 0.9704 - val_loss: 0.1899 - val_acc: 1.0000\n",
      "Epoch 942/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1621 - acc: 0.9704 - val_loss: 0.1870 - val_acc: 1.0000\n",
      "Epoch 943/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.1620 - acc: 0.9704 - val_loss: 0.1863 - val_acc: 1.0000\n",
      "Epoch 944/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1613 - acc: 0.9704 - val_loss: 0.1843 - val_acc: 1.0000\n",
      "Epoch 945/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.1616 - acc: 0.9704 - val_loss: 0.1843 - val_acc: 1.0000\n",
      "Epoch 946/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1612 - acc: 0.9704 - val_loss: 0.1839 - val_acc: 1.0000\n",
      "Epoch 947/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.1612 - acc: 0.9704 - val_loss: 0.1874 - val_acc: 1.0000\n",
      "Epoch 948/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1609 - acc: 0.9704 - val_loss: 0.1859 - val_acc: 1.0000\n",
      "Epoch 949/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1606 - acc: 0.9704 - val_loss: 0.1865 - val_acc: 1.0000\n",
      "Epoch 950/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1600 - acc: 0.9704 - val_loss: 0.1860 - val_acc: 1.0000\n",
      "Epoch 951/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.1603 - acc: 0.9704 - val_loss: 0.1860 - val_acc: 1.0000\n",
      "Epoch 952/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1601 - acc: 0.9704 - val_loss: 0.1863 - val_acc: 1.0000\n",
      "Epoch 953/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1595 - acc: 0.9704 - val_loss: 0.1840 - val_acc: 1.0000\n",
      "Epoch 954/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.1595 - acc: 0.9704 - val_loss: 0.1837 - val_acc: 1.0000\n",
      "Epoch 955/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1593 - acc: 0.9704 - val_loss: 0.1817 - val_acc: 1.0000\n",
      "Epoch 956/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1589 - acc: 0.9704 - val_loss: 0.1809 - val_acc: 1.0000\n",
      "Epoch 957/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1584 - acc: 0.9704 - val_loss: 0.1798 - val_acc: 1.0000\n",
      "Epoch 958/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1586 - acc: 0.9704 - val_loss: 0.1807 - val_acc: 1.0000\n",
      "Epoch 959/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1581 - acc: 0.9704 - val_loss: 0.1789 - val_acc: 1.0000\n",
      "Epoch 960/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.1580 - acc: 0.9704 - val_loss: 0.1798 - val_acc: 1.0000\n",
      "Epoch 961/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.1577 - acc: 0.9704 - val_loss: 0.1801 - val_acc: 1.0000\n",
      "Epoch 962/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.1575 - acc: 0.9704 - val_loss: 0.1801 - val_acc: 1.0000\n",
      "Epoch 963/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1573 - acc: 0.9704 - val_loss: 0.1792 - val_acc: 1.0000\n",
      "Epoch 964/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1572 - acc: 0.9704 - val_loss: 0.1804 - val_acc: 1.0000\n",
      "Epoch 965/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1573 - acc: 0.9704 - val_loss: 0.1799 - val_acc: 1.0000\n",
      "Epoch 966/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 0.1566 - acc: 0.9704 - val_loss: 0.1823 - val_acc: 1.0000\n",
      "Epoch 967/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.1565 - acc: 0.9704 - val_loss: 0.1787 - val_acc: 1.0000\n",
      "Epoch 968/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1563 - acc: 0.9704 - val_loss: 0.1787 - val_acc: 1.0000\n",
      "Epoch 969/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1559 - acc: 0.9704 - val_loss: 0.1787 - val_acc: 1.0000\n",
      "Epoch 970/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1560 - acc: 0.9704 - val_loss: 0.1800 - val_acc: 1.0000\n",
      "Epoch 971/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1555 - acc: 0.9704 - val_loss: 0.1795 - val_acc: 1.0000\n",
      "Epoch 972/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1555 - acc: 0.9704 - val_loss: 0.1795 - val_acc: 1.0000\n",
      "Epoch 973/2000\n",
      "135/135 [==============================] - 0s 354us/step - loss: 0.1553 - acc: 0.9704 - val_loss: 0.1774 - val_acc: 1.0000\n",
      "Epoch 974/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.1552 - acc: 0.9704 - val_loss: 0.1786 - val_acc: 1.0000\n",
      "Epoch 975/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1549 - acc: 0.9704 - val_loss: 0.1775 - val_acc: 1.0000\n",
      "Epoch 976/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1545 - acc: 0.9704 - val_loss: 0.1776 - val_acc: 1.0000\n",
      "Epoch 977/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.1544 - acc: 0.9704 - val_loss: 0.1774 - val_acc: 1.0000\n",
      "Epoch 978/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.1543 - acc: 0.9704 - val_loss: 0.1766 - val_acc: 1.0000\n",
      "Epoch 979/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1542 - acc: 0.9704 - val_loss: 0.1771 - val_acc: 1.0000\n",
      "Epoch 980/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1536 - acc: 0.9704 - val_loss: 0.1756 - val_acc: 1.0000\n",
      "Epoch 981/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1535 - acc: 0.9704 - val_loss: 0.1746 - val_acc: 1.0000\n",
      "Epoch 982/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.1535 - acc: 0.9704 - val_loss: 0.1749 - val_acc: 1.0000\n",
      "Epoch 983/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.1533 - acc: 0.9704 - val_loss: 0.1737 - val_acc: 1.0000\n",
      "Epoch 984/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1529 - acc: 0.9704 - val_loss: 0.1735 - val_acc: 1.0000\n",
      "Epoch 985/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.1526 - acc: 0.9704 - val_loss: 0.1736 - val_acc: 1.0000\n",
      "Epoch 986/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.1525 - acc: 0.9704 - val_loss: 0.1713 - val_acc: 1.0000\n",
      "Epoch 987/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1521 - acc: 0.9704 - val_loss: 0.1723 - val_acc: 1.0000\n",
      "Epoch 988/2000\n",
      "135/135 [==============================] - 0s 370us/step - loss: 0.1521 - acc: 0.9704 - val_loss: 0.1742 - val_acc: 1.0000\n",
      "Epoch 989/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.1518 - acc: 0.9704 - val_loss: 0.1716 - val_acc: 1.0000\n",
      "Epoch 990/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.1517 - acc: 0.9704 - val_loss: 0.1723 - val_acc: 1.0000\n",
      "Epoch 991/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1515 - acc: 0.9704 - val_loss: 0.1728 - val_acc: 1.0000\n",
      "Epoch 992/2000\n",
      "135/135 [==============================] - 0s 428us/step - loss: 0.1514 - acc: 0.9704 - val_loss: 0.1746 - val_acc: 1.0000\n",
      "Epoch 993/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1513 - acc: 0.9704 - val_loss: 0.1726 - val_acc: 1.0000\n",
      "Epoch 994/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.1507 - acc: 0.9704 - val_loss: 0.1737 - val_acc: 1.0000\n",
      "Epoch 995/2000\n",
      "135/135 [==============================] - 0s 318us/step - loss: 0.1506 - acc: 0.9704 - val_loss: 0.1720 - val_acc: 1.0000\n",
      "Epoch 996/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1506 - acc: 0.9704 - val_loss: 0.1731 - val_acc: 1.0000\n",
      "Epoch 997/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.1505 - acc: 0.9704 - val_loss: 0.1717 - val_acc: 1.0000\n",
      "Epoch 998/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.1500 - acc: 0.9704 - val_loss: 0.1692 - val_acc: 1.0000\n",
      "Epoch 999/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 340us/step - loss: 0.1501 - acc: 0.9704 - val_loss: 0.1696 - val_acc: 1.0000\n",
      "Epoch 1000/2000\n",
      "135/135 [==============================] - 0s 399us/step - loss: 0.1500 - acc: 0.9704 - val_loss: 0.1685 - val_acc: 1.0000\n",
      "Epoch 1001/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1494 - acc: 0.9704 - val_loss: 0.1691 - val_acc: 1.0000\n",
      "Epoch 1002/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1492 - acc: 0.9704 - val_loss: 0.1697 - val_acc: 1.0000\n",
      "Epoch 1003/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1494 - acc: 0.9704 - val_loss: 0.1675 - val_acc: 1.0000\n",
      "Epoch 1004/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.1490 - acc: 0.9704 - val_loss: 0.1671 - val_acc: 1.0000\n",
      "Epoch 1005/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1488 - acc: 0.9704 - val_loss: 0.1665 - val_acc: 1.0000\n",
      "Epoch 1006/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.1487 - acc: 0.9704 - val_loss: 0.1666 - val_acc: 1.0000\n",
      "Epoch 1007/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.1485 - acc: 0.9704 - val_loss: 0.1669 - val_acc: 1.0000\n",
      "Epoch 1008/2000\n",
      "135/135 [==============================] - 0s 333us/step - loss: 0.1481 - acc: 0.9704 - val_loss: 0.1675 - val_acc: 1.0000\n",
      "Epoch 1009/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1479 - acc: 0.9704 - val_loss: 0.1658 - val_acc: 1.0000\n",
      "Epoch 1010/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1477 - acc: 0.9704 - val_loss: 0.1661 - val_acc: 1.0000\n",
      "Epoch 1011/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1475 - acc: 0.9704 - val_loss: 0.1661 - val_acc: 1.0000\n",
      "Epoch 1012/2000\n",
      "135/135 [==============================] - 0s 399us/step - loss: 0.1474 - acc: 0.9704 - val_loss: 0.1653 - val_acc: 1.0000\n",
      "Epoch 1013/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.1474 - acc: 0.9704 - val_loss: 0.1653 - val_acc: 1.0000\n",
      "Epoch 1014/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 0.1471 - acc: 0.9704 - val_loss: 0.1669 - val_acc: 1.0000\n",
      "Epoch 1015/2000\n",
      "135/135 [==============================] - 0s 421us/step - loss: 0.1470 - acc: 0.9704 - val_loss: 0.1676 - val_acc: 1.0000\n",
      "Epoch 1016/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 0.1465 - acc: 0.9704 - val_loss: 0.1652 - val_acc: 1.0000\n",
      "Epoch 1017/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1464 - acc: 0.9704 - val_loss: 0.1654 - val_acc: 1.0000\n",
      "Epoch 1018/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1464 - acc: 0.9704 - val_loss: 0.1647 - val_acc: 1.0000\n",
      "Epoch 1019/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1463 - acc: 0.9704 - val_loss: 0.1657 - val_acc: 1.0000\n",
      "Epoch 1020/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1456 - acc: 0.9704 - val_loss: 0.1650 - val_acc: 1.0000\n",
      "Epoch 1021/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1460 - acc: 0.9704 - val_loss: 0.1649 - val_acc: 1.0000\n",
      "Epoch 1022/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.1453 - acc: 0.9704 - val_loss: 0.1661 - val_acc: 1.0000\n",
      "Epoch 1023/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1457 - acc: 0.9704 - val_loss: 0.1658 - val_acc: 1.0000\n",
      "Epoch 1024/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1455 - acc: 0.9704 - val_loss: 0.1644 - val_acc: 1.0000\n",
      "Epoch 1025/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1451 - acc: 0.9704 - val_loss: 0.1655 - val_acc: 1.0000\n",
      "Epoch 1026/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1448 - acc: 0.9704 - val_loss: 0.1625 - val_acc: 1.0000\n",
      "Epoch 1027/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.1448 - acc: 0.9704 - val_loss: 0.1635 - val_acc: 1.0000\n",
      "Epoch 1028/2000\n",
      "135/135 [==============================] - 0s 310us/step - loss: 0.1445 - acc: 0.9704 - val_loss: 0.1627 - val_acc: 1.0000\n",
      "Epoch 1029/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1444 - acc: 0.9704 - val_loss: 0.1651 - val_acc: 1.0000\n",
      "Epoch 1030/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.1440 - acc: 0.9704 - val_loss: 0.1657 - val_acc: 1.0000\n",
      "Epoch 1031/2000\n",
      "135/135 [==============================] - 0s 414us/step - loss: 0.1444 - acc: 0.9704 - val_loss: 0.1642 - val_acc: 1.0000\n",
      "Epoch 1032/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1438 - acc: 0.9704 - val_loss: 0.1622 - val_acc: 1.0000\n",
      "Epoch 1033/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.1437 - acc: 0.9704 - val_loss: 0.1609 - val_acc: 1.0000\n",
      "Epoch 1034/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.1434 - acc: 0.9704 - val_loss: 0.1615 - val_acc: 1.0000\n",
      "Epoch 1035/2000\n",
      "135/135 [==============================] - 0s 318us/step - loss: 0.1435 - acc: 0.9704 - val_loss: 0.1620 - val_acc: 1.0000\n",
      "Epoch 1036/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1430 - acc: 0.9704 - val_loss: 0.1618 - val_acc: 1.0000\n",
      "Epoch 1037/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1433 - acc: 0.9704 - val_loss: 0.1619 - val_acc: 1.0000\n",
      "Epoch 1038/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.1427 - acc: 0.9704 - val_loss: 0.1626 - val_acc: 1.0000\n",
      "Epoch 1039/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1426 - acc: 0.9704 - val_loss: 0.1630 - val_acc: 1.0000\n",
      "Epoch 1040/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.1424 - acc: 0.9704 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 1041/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.1422 - acc: 0.9704 - val_loss: 0.1592 - val_acc: 1.0000\n",
      "Epoch 1042/2000\n",
      "135/135 [==============================] - 0s 532us/step - loss: 0.1417 - acc: 0.9704 - val_loss: 0.1590 - val_acc: 1.0000\n",
      "Epoch 1043/2000\n",
      "135/135 [==============================] - 0s 561us/step - loss: 0.1422 - acc: 0.9704 - val_loss: 0.1593 - val_acc: 1.0000\n",
      "Epoch 1044/2000\n",
      "135/135 [==============================] - 0s 465us/step - loss: 0.1416 - acc: 0.9704 - val_loss: 0.1593 - val_acc: 1.0000\n",
      "Epoch 1045/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 0.1416 - acc: 0.9704 - val_loss: 0.1573 - val_acc: 1.0000\n",
      "Epoch 1046/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.1412 - acc: 0.9704 - val_loss: 0.1578 - val_acc: 1.0000\n",
      "Epoch 1047/2000\n",
      "135/135 [==============================] - 0s 525us/step - loss: 0.1411 - acc: 0.9704 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 1048/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1408 - acc: 0.9704 - val_loss: 0.1586 - val_acc: 1.0000\n",
      "Epoch 1049/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.1411 - acc: 0.9704 - val_loss: 0.1588 - val_acc: 1.0000\n",
      "Epoch 1050/2000\n",
      "135/135 [==============================] - 0s 318us/step - loss: 0.1406 - acc: 0.9704 - val_loss: 0.1582 - val_acc: 1.0000\n",
      "Epoch 1051/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.1403 - acc: 0.9704 - val_loss: 0.1576 - val_acc: 1.0000\n",
      "Epoch 1052/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1402 - acc: 0.9704 - val_loss: 0.1587 - val_acc: 1.0000\n",
      "Epoch 1053/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.1400 - acc: 0.9704 - val_loss: 0.1578 - val_acc: 1.0000\n",
      "Epoch 1054/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1400 - acc: 0.9704 - val_loss: 0.1564 - val_acc: 1.0000\n",
      "Epoch 1055/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.1396 - acc: 0.9704 - val_loss: 0.1570 - val_acc: 1.0000\n",
      "Epoch 1056/2000\n",
      "135/135 [==============================] - 0s 488us/step - loss: 0.1399 - acc: 0.9704 - val_loss: 0.1560 - val_acc: 1.0000\n",
      "Epoch 1057/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 0.1392 - acc: 0.9704 - val_loss: 0.1572 - val_acc: 1.0000\n",
      "Epoch 1058/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 347us/step - loss: 0.1390 - acc: 0.9704 - val_loss: 0.1578 - val_acc: 1.0000\n",
      "Epoch 1059/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.1389 - acc: 0.9704 - val_loss: 0.1561 - val_acc: 1.0000\n",
      "Epoch 1060/2000\n",
      "135/135 [==============================] - 0s 406us/step - loss: 0.1388 - acc: 0.9704 - val_loss: 0.1571 - val_acc: 1.0000\n",
      "Epoch 1061/2000\n",
      "135/135 [==============================] - 0s 318us/step - loss: 0.1385 - acc: 0.9704 - val_loss: 0.1556 - val_acc: 1.0000\n",
      "Epoch 1062/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.1385 - acc: 0.9704 - val_loss: 0.1541 - val_acc: 1.0000\n",
      "Epoch 1063/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1385 - acc: 0.9704 - val_loss: 0.1553 - val_acc: 1.0000\n",
      "Epoch 1064/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.1384 - acc: 0.9704 - val_loss: 0.1559 - val_acc: 1.0000\n",
      "Epoch 1065/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1381 - acc: 0.9704 - val_loss: 0.1563 - val_acc: 1.0000\n",
      "Epoch 1066/2000\n",
      "135/135 [==============================] - 0s 436us/step - loss: 0.1382 - acc: 0.9704 - val_loss: 0.1562 - val_acc: 1.0000\n",
      "Epoch 1067/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.1378 - acc: 0.9704 - val_loss: 0.1580 - val_acc: 1.0000\n",
      "Epoch 1068/2000\n",
      "135/135 [==============================] - 0s 310us/step - loss: 0.1380 - acc: 0.9778 - val_loss: 0.1546 - val_acc: 1.0000\n",
      "Epoch 1069/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.1374 - acc: 0.9704 - val_loss: 0.1566 - val_acc: 1.0000\n",
      "Epoch 1070/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1379 - acc: 0.9704 - val_loss: 0.1574 - val_acc: 1.0000\n",
      "Epoch 1071/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 0.1374 - acc: 0.9704 - val_loss: 0.1540 - val_acc: 1.0000\n",
      "Epoch 1072/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.1370 - acc: 0.9704 - val_loss: 0.1528 - val_acc: 1.0000\n",
      "Epoch 1073/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1366 - acc: 0.9704 - val_loss: 0.1522 - val_acc: 1.0000\n",
      "Epoch 1074/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.1368 - acc: 0.9704 - val_loss: 0.1520 - val_acc: 1.0000\n",
      "Epoch 1075/2000\n",
      "135/135 [==============================] - 0s 310us/step - loss: 0.1365 - acc: 0.9704 - val_loss: 0.1514 - val_acc: 1.0000\n",
      "Epoch 1076/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 0.1361 - acc: 0.9704 - val_loss: 0.1505 - val_acc: 1.0000\n",
      "Epoch 1077/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.1361 - acc: 0.9704 - val_loss: 0.1499 - val_acc: 1.0000\n",
      "Epoch 1078/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 0.1359 - acc: 0.9704 - val_loss: 0.1497 - val_acc: 1.0000\n",
      "Epoch 1079/2000\n",
      "135/135 [==============================] - 0s 318us/step - loss: 0.1359 - acc: 0.9704 - val_loss: 0.1510 - val_acc: 1.0000\n",
      "Epoch 1080/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.1358 - acc: 0.9704 - val_loss: 0.1498 - val_acc: 1.0000\n",
      "Epoch 1081/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1355 - acc: 0.9704 - val_loss: 0.1516 - val_acc: 1.0000\n",
      "Epoch 1082/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.1352 - acc: 0.9704 - val_loss: 0.1510 - val_acc: 1.0000\n",
      "Epoch 1083/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.1354 - acc: 0.9704 - val_loss: 0.1504 - val_acc: 1.0000\n",
      "Epoch 1084/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.1350 - acc: 0.9704 - val_loss: 0.1497 - val_acc: 1.0000\n",
      "Epoch 1085/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.1348 - acc: 0.9704 - val_loss: 0.1503 - val_acc: 1.0000\n",
      "Epoch 1086/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.1349 - acc: 0.9704 - val_loss: 0.1522 - val_acc: 1.0000\n",
      "Epoch 1087/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1347 - acc: 0.9704 - val_loss: 0.1509 - val_acc: 1.0000\n",
      "Epoch 1088/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.1345 - acc: 0.9704 - val_loss: 0.1490 - val_acc: 1.0000\n",
      "Epoch 1089/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1345 - acc: 0.9704 - val_loss: 0.1487 - val_acc: 1.0000\n",
      "Epoch 1090/2000\n",
      "135/135 [==============================] - 0s 406us/step - loss: 0.1338 - acc: 0.9704 - val_loss: 0.1502 - val_acc: 1.0000\n",
      "Epoch 1091/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.1340 - acc: 0.9704 - val_loss: 0.1498 - val_acc: 1.0000\n",
      "Epoch 1092/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.1338 - acc: 0.9704 - val_loss: 0.1483 - val_acc: 1.0000\n",
      "Epoch 1093/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.1337 - acc: 0.9704 - val_loss: 0.1506 - val_acc: 1.0000\n",
      "Epoch 1094/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1334 - acc: 0.9704 - val_loss: 0.1484 - val_acc: 1.0000\n",
      "Epoch 1095/2000\n",
      "135/135 [==============================] - 0s 399us/step - loss: 0.1332 - acc: 0.9704 - val_loss: 0.1481 - val_acc: 1.0000\n",
      "Epoch 1096/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1335 - acc: 0.9704 - val_loss: 0.1482 - val_acc: 1.0000\n",
      "Epoch 1097/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1331 - acc: 0.9704 - val_loss: 0.1466 - val_acc: 1.0000\n",
      "Epoch 1098/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.1330 - acc: 0.9704 - val_loss: 0.1471 - val_acc: 1.0000\n",
      "Epoch 1099/2000\n",
      "135/135 [==============================] - 0s 318us/step - loss: 0.1326 - acc: 0.9704 - val_loss: 0.1461 - val_acc: 1.0000\n",
      "Epoch 1100/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.1328 - acc: 0.9704 - val_loss: 0.1475 - val_acc: 1.0000\n",
      "Epoch 1101/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1325 - acc: 0.9704 - val_loss: 0.1484 - val_acc: 1.0000\n",
      "Epoch 1102/2000\n",
      "135/135 [==============================] - 0s 318us/step - loss: 0.1325 - acc: 0.9704 - val_loss: 0.1457 - val_acc: 1.0000\n",
      "Epoch 1103/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1322 - acc: 0.9704 - val_loss: 0.1470 - val_acc: 1.0000\n",
      "Epoch 1104/2000\n",
      "135/135 [==============================] - 0s 414us/step - loss: 0.1321 - acc: 0.9704 - val_loss: 0.1460 - val_acc: 1.0000\n",
      "Epoch 1105/2000\n",
      "135/135 [==============================] - 0s 525us/step - loss: 0.1319 - acc: 0.9704 - val_loss: 0.1470 - val_acc: 1.0000\n",
      "Epoch 1106/2000\n",
      "135/135 [==============================] - 0s 429us/step - loss: 0.1319 - acc: 0.9704 - val_loss: 0.1467 - val_acc: 1.0000\n",
      "Epoch 1107/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1318 - acc: 0.9704 - val_loss: 0.1448 - val_acc: 1.0000\n",
      "Epoch 1108/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.1315 - acc: 0.9704 - val_loss: 0.1438 - val_acc: 1.0000\n",
      "Epoch 1109/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1315 - acc: 0.9704 - val_loss: 0.1465 - val_acc: 1.0000\n",
      "Epoch 1110/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1317 - acc: 0.9704 - val_loss: 0.1457 - val_acc: 1.0000\n",
      "Epoch 1111/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.1307 - acc: 0.9704 - val_loss: 0.1462 - val_acc: 1.0000\n",
      "Epoch 1112/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.1310 - acc: 0.9704 - val_loss: 0.1455 - val_acc: 1.0000\n",
      "Epoch 1113/2000\n",
      "135/135 [==============================] - 0s 399us/step - loss: 0.1308 - acc: 0.9704 - val_loss: 0.1441 - val_acc: 1.0000\n",
      "Epoch 1114/2000\n",
      "135/135 [==============================] - 0s 296us/step - loss: 0.1305 - acc: 0.9704 - val_loss: 0.1424 - val_acc: 1.0000\n",
      "Epoch 1115/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.1304 - acc: 0.9704 - val_loss: 0.1417 - val_acc: 1.0000\n",
      "Epoch 1116/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1304 - acc: 0.9704 - val_loss: 0.1413 - val_acc: 1.0000\n",
      "Epoch 1117/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 377us/step - loss: 0.1304 - acc: 0.9704 - val_loss: 0.1393 - val_acc: 1.0000\n",
      "Epoch 1118/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1302 - acc: 0.9704 - val_loss: 0.1401 - val_acc: 1.0000\n",
      "Epoch 1119/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1300 - acc: 0.9704 - val_loss: 0.1398 - val_acc: 1.0000\n",
      "Epoch 1120/2000\n",
      "135/135 [==============================] - 0s 318us/step - loss: 0.1297 - acc: 0.9704 - val_loss: 0.1397 - val_acc: 1.0000\n",
      "Epoch 1121/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1293 - acc: 0.9704 - val_loss: 0.1400 - val_acc: 1.0000\n",
      "Epoch 1122/2000\n",
      "135/135 [==============================] - 0s 488us/step - loss: 0.1294 - acc: 0.9704 - val_loss: 0.1406 - val_acc: 1.0000\n",
      "Epoch 1123/2000\n",
      "135/135 [==============================] - 0s 502us/step - loss: 0.1294 - acc: 0.9704 - val_loss: 0.1415 - val_acc: 1.0000\n",
      "Epoch 1124/2000\n",
      "135/135 [==============================] - 0s 473us/step - loss: 0.1291 - acc: 0.9704 - val_loss: 0.1395 - val_acc: 1.0000\n",
      "Epoch 1125/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1289 - acc: 0.9704 - val_loss: 0.1422 - val_acc: 1.0000\n",
      "Epoch 1126/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.1288 - acc: 0.9704 - val_loss: 0.1419 - val_acc: 1.0000\n",
      "Epoch 1127/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1290 - acc: 0.9704 - val_loss: 0.1412 - val_acc: 1.0000\n",
      "Epoch 1128/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.1286 - acc: 0.9704 - val_loss: 0.1414 - val_acc: 1.0000\n",
      "Epoch 1129/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.1284 - acc: 0.9704 - val_loss: 0.1423 - val_acc: 1.0000\n",
      "Epoch 1130/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1282 - acc: 0.9704 - val_loss: 0.1398 - val_acc: 1.0000\n",
      "Epoch 1131/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.1283 - acc: 0.9704 - val_loss: 0.1396 - val_acc: 1.0000\n",
      "Epoch 1132/2000\n",
      "135/135 [==============================] - 0s 399us/step - loss: 0.1281 - acc: 0.9704 - val_loss: 0.1401 - val_acc: 1.0000\n",
      "Epoch 1133/2000\n",
      "135/135 [==============================] - 0s 318us/step - loss: 0.1279 - acc: 0.9704 - val_loss: 0.1405 - val_acc: 1.0000\n",
      "Epoch 1134/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1278 - acc: 0.9704 - val_loss: 0.1399 - val_acc: 1.0000\n",
      "Epoch 1135/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.1276 - acc: 0.9704 - val_loss: 0.1418 - val_acc: 1.0000\n",
      "Epoch 1136/2000\n",
      "135/135 [==============================] - 0s 421us/step - loss: 0.1274 - acc: 0.9704 - val_loss: 0.1406 - val_acc: 1.0000\n",
      "Epoch 1137/2000\n",
      "135/135 [==============================] - 0s 495us/step - loss: 0.1275 - acc: 0.9704 - val_loss: 0.1397 - val_acc: 1.0000\n",
      "Epoch 1138/2000\n",
      "135/135 [==============================] - 0s 502us/step - loss: 0.1272 - acc: 0.9704 - val_loss: 0.1393 - val_acc: 1.0000\n",
      "Epoch 1139/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1271 - acc: 0.9704 - val_loss: 0.1403 - val_acc: 1.0000\n",
      "Epoch 1140/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1271 - acc: 0.9704 - val_loss: 0.1382 - val_acc: 1.0000\n",
      "Epoch 1141/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.1266 - acc: 0.9704 - val_loss: 0.1380 - val_acc: 1.0000\n",
      "Epoch 1142/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.1269 - acc: 0.9704 - val_loss: 0.1379 - val_acc: 1.0000\n",
      "Epoch 1143/2000\n",
      "135/135 [==============================] - 0s 480us/step - loss: 0.1265 - acc: 0.9704 - val_loss: 0.1367 - val_acc: 1.0000\n",
      "Epoch 1144/2000\n",
      "135/135 [==============================] - 0s 421us/step - loss: 0.1267 - acc: 0.9704 - val_loss: 0.1368 - val_acc: 1.0000\n",
      "Epoch 1145/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.1264 - acc: 0.9704 - val_loss: 0.1396 - val_acc: 1.0000\n",
      "Epoch 1146/2000\n",
      "135/135 [==============================] - 0s 310us/step - loss: 0.1265 - acc: 0.9704 - val_loss: 0.1403 - val_acc: 1.0000\n",
      "Epoch 1147/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.1260 - acc: 0.9704 - val_loss: 0.1385 - val_acc: 1.0000\n",
      "Epoch 1148/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.1262 - acc: 0.9704 - val_loss: 0.1399 - val_acc: 1.0000\n",
      "Epoch 1149/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1261 - acc: 0.9704 - val_loss: 0.1395 - val_acc: 1.0000\n",
      "Epoch 1150/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.1257 - acc: 0.9778 - val_loss: 0.1363 - val_acc: 1.0000\n",
      "Epoch 1151/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.1254 - acc: 0.9704 - val_loss: 0.1364 - val_acc: 1.0000\n",
      "Epoch 1152/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 0.1253 - acc: 0.9704 - val_loss: 0.1361 - val_acc: 1.0000\n",
      "Epoch 1153/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1253 - acc: 0.9704 - val_loss: 0.1372 - val_acc: 1.0000\n",
      "Epoch 1154/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1250 - acc: 0.9704 - val_loss: 0.1384 - val_acc: 1.0000\n",
      "Epoch 1155/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1252 - acc: 0.9704 - val_loss: 0.1375 - val_acc: 1.0000\n",
      "Epoch 1156/2000\n",
      "135/135 [==============================] - 0s 320us/step - loss: 0.1252 - acc: 0.9704 - val_loss: 0.1362 - val_acc: 1.0000\n",
      "Epoch 1157/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.1250 - acc: 0.9704 - val_loss: 0.1363 - val_acc: 1.0000\n",
      "Epoch 1158/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1247 - acc: 0.9704 - val_loss: 0.1363 - val_acc: 1.0000\n",
      "Epoch 1159/2000\n",
      "135/135 [==============================] - 0s 414us/step - loss: 0.1246 - acc: 0.9704 - val_loss: 0.1371 - val_acc: 1.0000\n",
      "Epoch 1160/2000\n",
      "135/135 [==============================] - 0s 502us/step - loss: 0.1244 - acc: 0.9704 - val_loss: 0.1354 - val_acc: 1.0000\n",
      "Epoch 1161/2000\n",
      "135/135 [==============================] - 0s 502us/step - loss: 0.1244 - acc: 0.9704 - val_loss: 0.1370 - val_acc: 1.0000\n",
      "Epoch 1162/2000\n",
      "135/135 [==============================] - 0s 428us/step - loss: 0.1243 - acc: 0.9704 - val_loss: 0.1384 - val_acc: 1.0000\n",
      "Epoch 1163/2000\n",
      "135/135 [==============================] - 0s 413us/step - loss: 0.1238 - acc: 0.9704 - val_loss: 0.1390 - val_acc: 1.0000\n",
      "Epoch 1164/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1240 - acc: 0.9778 - val_loss: 0.1366 - val_acc: 1.0000\n",
      "Epoch 1165/2000\n",
      "135/135 [==============================] - 0s 317us/step - loss: 0.1238 - acc: 0.9704 - val_loss: 0.1351 - val_acc: 1.0000\n",
      "Epoch 1166/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.1240 - acc: 0.9704 - val_loss: 0.1352 - val_acc: 1.0000\n",
      "Epoch 1167/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.1233 - acc: 0.9704 - val_loss: 0.1373 - val_acc: 1.0000\n",
      "Epoch 1168/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.1236 - acc: 0.9704 - val_loss: 0.1353 - val_acc: 1.0000\n",
      "Epoch 1169/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.1232 - acc: 0.9704 - val_loss: 0.1335 - val_acc: 1.0000\n",
      "Epoch 1170/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 0.1230 - acc: 0.9704 - val_loss: 0.1333 - val_acc: 1.0000\n",
      "Epoch 1171/2000\n",
      "135/135 [==============================] - 0s 318us/step - loss: 0.1229 - acc: 0.9778 - val_loss: 0.1306 - val_acc: 1.0000\n",
      "Epoch 1172/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1231 - acc: 0.9704 - val_loss: 0.1314 - val_acc: 1.0000\n",
      "Epoch 1173/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1227 - acc: 0.9704 - val_loss: 0.1328 - val_acc: 1.0000\n",
      "Epoch 1174/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.1225 - acc: 0.9704 - val_loss: 0.1347 - val_acc: 1.0000\n",
      "Epoch 1175/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1228 - acc: 0.9704 - val_loss: 0.1349 - val_acc: 1.0000\n",
      "Epoch 1176/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 362us/step - loss: 0.1223 - acc: 0.9704 - val_loss: 0.1348 - val_acc: 1.0000\n",
      "Epoch 1177/2000\n",
      "135/135 [==============================] - 0s 406us/step - loss: 0.1224 - acc: 0.9704 - val_loss: 0.1348 - val_acc: 1.0000\n",
      "Epoch 1178/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.1219 - acc: 0.9704 - val_loss: 0.1346 - val_acc: 1.0000\n",
      "Epoch 1179/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.1220 - acc: 0.9704 - val_loss: 0.1332 - val_acc: 1.0000\n",
      "Epoch 1180/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.1219 - acc: 0.9704 - val_loss: 0.1312 - val_acc: 1.0000\n",
      "Epoch 1181/2000\n",
      "135/135 [==============================] - 0s 328us/step - loss: 0.1222 - acc: 0.9704 - val_loss: 0.1310 - val_acc: 1.0000\n",
      "Epoch 1182/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1217 - acc: 0.9704 - val_loss: 0.1307 - val_acc: 1.0000\n",
      "Epoch 1183/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1218 - acc: 0.9704 - val_loss: 0.1329 - val_acc: 1.0000\n",
      "Epoch 1184/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.1217 - acc: 0.9704 - val_loss: 0.1332 - val_acc: 1.0000\n",
      "Epoch 1185/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1215 - acc: 0.9704 - val_loss: 0.1327 - val_acc: 1.0000\n",
      "Epoch 1186/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1212 - acc: 0.9704 - val_loss: 0.1321 - val_acc: 1.0000\n",
      "Epoch 1187/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1210 - acc: 0.9704 - val_loss: 0.1311 - val_acc: 1.0000\n",
      "Epoch 1188/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1210 - acc: 0.9704 - val_loss: 0.1293 - val_acc: 1.0000\n",
      "Epoch 1189/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1210 - acc: 0.9704 - val_loss: 0.1308 - val_acc: 1.0000\n",
      "Epoch 1190/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1206 - acc: 0.9704 - val_loss: 0.1293 - val_acc: 1.0000\n",
      "Epoch 1191/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1204 - acc: 0.9704 - val_loss: 0.1294 - val_acc: 1.0000\n",
      "Epoch 1192/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1206 - acc: 0.9704 - val_loss: 0.1311 - val_acc: 1.0000\n",
      "Epoch 1193/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1204 - acc: 0.9704 - val_loss: 0.1312 - val_acc: 1.0000\n",
      "Epoch 1194/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.1204 - acc: 0.9704 - val_loss: 0.1315 - val_acc: 1.0000\n",
      "Epoch 1195/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.1199 - acc: 0.9704 - val_loss: 0.1293 - val_acc: 1.0000\n",
      "Epoch 1196/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1200 - acc: 0.9704 - val_loss: 0.1302 - val_acc: 1.0000\n",
      "Epoch 1197/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1200 - acc: 0.9704 - val_loss: 0.1308 - val_acc: 1.0000\n",
      "Epoch 1198/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1200 - acc: 0.9704 - val_loss: 0.1295 - val_acc: 1.0000\n",
      "Epoch 1199/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1200 - acc: 0.9704 - val_loss: 0.1296 - val_acc: 1.0000\n",
      "Epoch 1200/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1195 - acc: 0.9704 - val_loss: 0.1295 - val_acc: 1.0000\n",
      "Epoch 1201/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1198 - acc: 0.9704 - val_loss: 0.1292 - val_acc: 1.0000\n",
      "Epoch 1202/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1197 - acc: 0.9704 - val_loss: 0.1285 - val_acc: 1.0000\n",
      "Epoch 1203/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1195 - acc: 0.9704 - val_loss: 0.1282 - val_acc: 1.0000\n",
      "Epoch 1204/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1190 - acc: 0.9704 - val_loss: 0.1270 - val_acc: 1.0000\n",
      "Epoch 1205/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.1190 - acc: 0.9704 - val_loss: 0.1283 - val_acc: 1.0000\n",
      "Epoch 1206/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.1188 - acc: 0.9704 - val_loss: 0.1285 - val_acc: 1.0000\n",
      "Epoch 1207/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1189 - acc: 0.9704 - val_loss: 0.1293 - val_acc: 1.0000\n",
      "Epoch 1208/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1185 - acc: 0.9704 - val_loss: 0.1302 - val_acc: 1.0000\n",
      "Epoch 1209/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1186 - acc: 0.9704 - val_loss: 0.1296 - val_acc: 1.0000\n",
      "Epoch 1210/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1187 - acc: 0.9704 - val_loss: 0.1298 - val_acc: 1.0000\n",
      "Epoch 1211/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1183 - acc: 0.9704 - val_loss: 0.1285 - val_acc: 1.0000\n",
      "Epoch 1212/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.1181 - acc: 0.9704 - val_loss: 0.1284 - val_acc: 1.0000\n",
      "Epoch 1213/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1179 - acc: 0.9704 - val_loss: 0.1276 - val_acc: 1.0000\n",
      "Epoch 1214/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1180 - acc: 0.9704 - val_loss: 0.1256 - val_acc: 1.0000\n",
      "Epoch 1215/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1180 - acc: 0.9704 - val_loss: 0.1261 - val_acc: 1.0000\n",
      "Epoch 1216/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1179 - acc: 0.9704 - val_loss: 0.1268 - val_acc: 1.0000\n",
      "Epoch 1217/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.1175 - acc: 0.9704 - val_loss: 0.1266 - val_acc: 1.0000\n",
      "Epoch 1218/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1178 - acc: 0.9704 - val_loss: 0.1265 - val_acc: 1.0000\n",
      "Epoch 1219/2000\n",
      "135/135 [==============================] - 0s 318us/step - loss: 0.1172 - acc: 0.9704 - val_loss: 0.1269 - val_acc: 1.0000\n",
      "Epoch 1220/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 0.1174 - acc: 0.9704 - val_loss: 0.1261 - val_acc: 1.0000\n",
      "Epoch 1221/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.1172 - acc: 0.9704 - val_loss: 0.1268 - val_acc: 1.0000\n",
      "Epoch 1222/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1173 - acc: 0.9704 - val_loss: 0.1266 - val_acc: 1.0000\n",
      "Epoch 1223/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.1172 - acc: 0.9704 - val_loss: 0.1255 - val_acc: 1.0000\n",
      "Epoch 1224/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1169 - acc: 0.9704 - val_loss: 0.1265 - val_acc: 1.0000\n",
      "Epoch 1225/2000\n",
      "135/135 [==============================] - 0s 318us/step - loss: 0.1167 - acc: 0.9704 - val_loss: 0.1274 - val_acc: 1.0000\n",
      "Epoch 1226/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1167 - acc: 0.9704 - val_loss: 0.1276 - val_acc: 1.0000\n",
      "Epoch 1227/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.1168 - acc: 0.9704 - val_loss: 0.1270 - val_acc: 1.0000\n",
      "Epoch 1228/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.1165 - acc: 0.9704 - val_loss: 0.1280 - val_acc: 1.0000\n",
      "Epoch 1229/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.1162 - acc: 0.9704 - val_loss: 0.1279 - val_acc: 1.0000\n",
      "Epoch 1230/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1161 - acc: 0.9704 - val_loss: 0.1278 - val_acc: 1.0000\n",
      "Epoch 1231/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.1162 - acc: 0.9704 - val_loss: 0.1257 - val_acc: 1.0000\n",
      "Epoch 1232/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1159 - acc: 0.9704 - val_loss: 0.1268 - val_acc: 1.0000\n",
      "Epoch 1233/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.1159 - acc: 0.9704 - val_loss: 0.1274 - val_acc: 1.0000\n",
      "Epoch 1234/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1157 - acc: 0.9704 - val_loss: 0.1258 - val_acc: 1.0000\n",
      "Epoch 1235/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 362us/step - loss: 0.1156 - acc: 0.9704 - val_loss: 0.1240 - val_acc: 1.0000\n",
      "Epoch 1236/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.1157 - acc: 0.9704 - val_loss: 0.1251 - val_acc: 1.0000\n",
      "Epoch 1237/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1156 - acc: 0.9704 - val_loss: 0.1258 - val_acc: 1.0000\n",
      "Epoch 1238/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1158 - acc: 0.9704 - val_loss: 0.1262 - val_acc: 1.0000\n",
      "Epoch 1239/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1155 - acc: 0.9704 - val_loss: 0.1262 - val_acc: 1.0000\n",
      "Epoch 1240/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1154 - acc: 0.9704 - val_loss: 0.1273 - val_acc: 1.0000\n",
      "Epoch 1241/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1153 - acc: 0.9704 - val_loss: 0.1265 - val_acc: 1.0000\n",
      "Epoch 1242/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1150 - acc: 0.9704 - val_loss: 0.1242 - val_acc: 1.0000\n",
      "Epoch 1243/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1148 - acc: 0.9704 - val_loss: 0.1236 - val_acc: 1.0000\n",
      "Epoch 1244/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1152 - acc: 0.9704 - val_loss: 0.1231 - val_acc: 1.0000\n",
      "Epoch 1245/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1146 - acc: 0.9704 - val_loss: 0.1242 - val_acc: 1.0000\n",
      "Epoch 1246/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1146 - acc: 0.9704 - val_loss: 0.1233 - val_acc: 1.0000\n",
      "Epoch 1247/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1146 - acc: 0.9704 - val_loss: 0.1223 - val_acc: 1.0000\n",
      "Epoch 1248/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1145 - acc: 0.9704 - val_loss: 0.1207 - val_acc: 1.0000\n",
      "Epoch 1249/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1145 - acc: 0.9704 - val_loss: 0.1208 - val_acc: 1.0000\n",
      "Epoch 1250/2000\n",
      "135/135 [==============================] - 0s 473us/step - loss: 0.1144 - acc: 0.9704 - val_loss: 0.1217 - val_acc: 1.0000\n",
      "Epoch 1251/2000\n",
      "135/135 [==============================] - 0s 348us/step - loss: 0.1141 - acc: 0.9704 - val_loss: 0.1217 - val_acc: 1.0000\n",
      "Epoch 1252/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1140 - acc: 0.9704 - val_loss: 0.1219 - val_acc: 1.0000\n",
      "Epoch 1253/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1139 - acc: 0.9704 - val_loss: 0.1233 - val_acc: 1.0000\n",
      "Epoch 1254/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1137 - acc: 0.9704 - val_loss: 0.1220 - val_acc: 1.0000\n",
      "Epoch 1255/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1138 - acc: 0.9704 - val_loss: 0.1238 - val_acc: 1.0000\n",
      "Epoch 1256/2000\n",
      "135/135 [==============================] - 0s 370us/step - loss: 0.1140 - acc: 0.9704 - val_loss: 0.1236 - val_acc: 1.0000\n",
      "Epoch 1257/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.1137 - acc: 0.9704 - val_loss: 0.1213 - val_acc: 1.0000\n",
      "Epoch 1258/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1133 - acc: 0.9704 - val_loss: 0.1203 - val_acc: 1.0000\n",
      "Epoch 1259/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1133 - acc: 0.9704 - val_loss: 0.1186 - val_acc: 1.0000\n",
      "Epoch 1260/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1136 - acc: 0.9704 - val_loss: 0.1207 - val_acc: 1.0000\n",
      "Epoch 1261/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1128 - acc: 0.9704 - val_loss: 0.1222 - val_acc: 1.0000\n",
      "Epoch 1262/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1131 - acc: 0.9704 - val_loss: 0.1237 - val_acc: 1.0000\n",
      "Epoch 1263/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1128 - acc: 0.9704 - val_loss: 0.1250 - val_acc: 1.0000\n",
      "Epoch 1264/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.1126 - acc: 0.9704 - val_loss: 0.1218 - val_acc: 1.0000\n",
      "Epoch 1265/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.1127 - acc: 0.9704 - val_loss: 0.1204 - val_acc: 1.0000\n",
      "Epoch 1266/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1127 - acc: 0.9704 - val_loss: 0.1194 - val_acc: 1.0000\n",
      "Epoch 1267/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1127 - acc: 0.9704 - val_loss: 0.1211 - val_acc: 1.0000\n",
      "Epoch 1268/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1123 - acc: 0.9704 - val_loss: 0.1211 - val_acc: 1.0000\n",
      "Epoch 1269/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.1121 - acc: 0.9704 - val_loss: 0.1219 - val_acc: 1.0000\n",
      "Epoch 1270/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.1125 - acc: 0.9704 - val_loss: 0.1207 - val_acc: 1.0000\n",
      "Epoch 1271/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1124 - acc: 0.9704 - val_loss: 0.1215 - val_acc: 1.0000\n",
      "Epoch 1272/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.1121 - acc: 0.9704 - val_loss: 0.1225 - val_acc: 1.0000\n",
      "Epoch 1273/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.1120 - acc: 0.9704 - val_loss: 0.1223 - val_acc: 1.0000\n",
      "Epoch 1274/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.1117 - acc: 0.9704 - val_loss: 0.1193 - val_acc: 1.0000\n",
      "Epoch 1275/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1115 - acc: 0.9704 - val_loss: 0.1189 - val_acc: 1.0000\n",
      "Epoch 1276/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1117 - acc: 0.9704 - val_loss: 0.1177 - val_acc: 1.0000\n",
      "Epoch 1277/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1117 - acc: 0.9704 - val_loss: 0.1183 - val_acc: 1.0000\n",
      "Epoch 1278/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.1117 - acc: 0.9704 - val_loss: 0.1164 - val_acc: 1.0000\n",
      "Epoch 1279/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.1114 - acc: 0.9704 - val_loss: 0.1171 - val_acc: 1.0000\n",
      "Epoch 1280/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.1115 - acc: 0.9704 - val_loss: 0.1168 - val_acc: 1.0000\n",
      "Epoch 1281/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1114 - acc: 0.9704 - val_loss: 0.1167 - val_acc: 1.0000\n",
      "Epoch 1282/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.1111 - acc: 0.9704 - val_loss: 0.1167 - val_acc: 1.0000\n",
      "Epoch 1283/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1112 - acc: 0.9704 - val_loss: 0.1175 - val_acc: 1.0000\n",
      "Epoch 1284/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.1109 - acc: 0.9704 - val_loss: 0.1162 - val_acc: 1.0000\n",
      "Epoch 1285/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1108 - acc: 0.9704 - val_loss: 0.1184 - val_acc: 1.0000\n",
      "Epoch 1286/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.1107 - acc: 0.9704 - val_loss: 0.1205 - val_acc: 1.0000\n",
      "Epoch 1287/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1105 - acc: 0.9704 - val_loss: 0.1197 - val_acc: 1.0000\n",
      "Epoch 1288/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1108 - acc: 0.9704 - val_loss: 0.1199 - val_acc: 1.0000\n",
      "Epoch 1289/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.1103 - acc: 0.9704 - val_loss: 0.1182 - val_acc: 1.0000\n",
      "Epoch 1290/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.1104 - acc: 0.9704 - val_loss: 0.1186 - val_acc: 1.0000\n",
      "Epoch 1291/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1103 - acc: 0.9704 - val_loss: 0.1183 - val_acc: 1.0000\n",
      "Epoch 1292/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.1102 - acc: 0.9704 - val_loss: 0.1167 - val_acc: 1.0000\n",
      "Epoch 1293/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.1102 - acc: 0.9704 - val_loss: 0.1148 - val_acc: 1.0000\n",
      "Epoch 1294/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 325us/step - loss: 0.1097 - acc: 0.9704 - val_loss: 0.1162 - val_acc: 1.0000\n",
      "Epoch 1295/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1101 - acc: 0.9704 - val_loss: 0.1165 - val_acc: 1.0000\n",
      "Epoch 1296/2000\n",
      "135/135 [==============================] - 0s 399us/step - loss: 0.1096 - acc: 0.9704 - val_loss: 0.1165 - val_acc: 1.0000\n",
      "Epoch 1297/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1100 - acc: 0.9704 - val_loss: 0.1183 - val_acc: 1.0000\n",
      "Epoch 1298/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.1096 - acc: 0.9704 - val_loss: 0.1167 - val_acc: 1.0000\n",
      "Epoch 1299/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1098 - acc: 0.9704 - val_loss: 0.1164 - val_acc: 1.0000\n",
      "Epoch 1300/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1095 - acc: 0.9704 - val_loss: 0.1147 - val_acc: 1.0000\n",
      "Epoch 1301/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1093 - acc: 0.9704 - val_loss: 0.1140 - val_acc: 1.0000\n",
      "Epoch 1302/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1092 - acc: 0.9704 - val_loss: 0.1153 - val_acc: 1.0000\n",
      "Epoch 1303/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1090 - acc: 0.9778 - val_loss: 0.1134 - val_acc: 1.0000\n",
      "Epoch 1304/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1093 - acc: 0.9704 - val_loss: 0.1130 - val_acc: 1.0000\n",
      "Epoch 1305/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1089 - acc: 0.9630 - val_loss: 0.1166 - val_acc: 1.0000\n",
      "Epoch 1306/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1094 - acc: 0.9704 - val_loss: 0.1167 - val_acc: 1.0000\n",
      "Epoch 1307/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1089 - acc: 0.9704 - val_loss: 0.1146 - val_acc: 1.0000\n",
      "Epoch 1308/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1087 - acc: 0.9704 - val_loss: 0.1138 - val_acc: 1.0000\n",
      "Epoch 1309/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1086 - acc: 0.9704 - val_loss: 0.1141 - val_acc: 1.0000\n",
      "Epoch 1310/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1090 - acc: 0.9704 - val_loss: 0.1145 - val_acc: 1.0000\n",
      "Epoch 1311/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1086 - acc: 0.9704 - val_loss: 0.1157 - val_acc: 1.0000\n",
      "Epoch 1312/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1084 - acc: 0.9704 - val_loss: 0.1159 - val_acc: 1.0000\n",
      "Epoch 1313/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.1083 - acc: 0.9704 - val_loss: 0.1147 - val_acc: 1.0000\n",
      "Epoch 1314/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1082 - acc: 0.9704 - val_loss: 0.1125 - val_acc: 1.0000\n",
      "Epoch 1315/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1081 - acc: 0.9778 - val_loss: 0.1108 - val_acc: 1.0000\n",
      "Epoch 1316/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1079 - acc: 0.9704 - val_loss: 0.1114 - val_acc: 1.0000\n",
      "Epoch 1317/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1081 - acc: 0.9704 - val_loss: 0.1131 - val_acc: 1.0000\n",
      "Epoch 1318/2000\n",
      "135/135 [==============================] - 0s 354us/step - loss: 0.1087 - acc: 0.9704 - val_loss: 0.1160 - val_acc: 1.0000\n",
      "Epoch 1319/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1078 - acc: 0.9704 - val_loss: 0.1165 - val_acc: 1.0000\n",
      "Epoch 1320/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1079 - acc: 0.9704 - val_loss: 0.1166 - val_acc: 1.0000\n",
      "Epoch 1321/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1078 - acc: 0.9778 - val_loss: 0.1158 - val_acc: 1.0000\n",
      "Epoch 1322/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1075 - acc: 0.9704 - val_loss: 0.1147 - val_acc: 1.0000\n",
      "Epoch 1323/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.1073 - acc: 0.9704 - val_loss: 0.1158 - val_acc: 1.0000\n",
      "Epoch 1324/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.1076 - acc: 0.9704 - val_loss: 0.1162 - val_acc: 1.0000\n",
      "Epoch 1325/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.1074 - acc: 0.9704 - val_loss: 0.1157 - val_acc: 1.0000\n",
      "Epoch 1326/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1071 - acc: 0.9704 - val_loss: 0.1160 - val_acc: 1.0000\n",
      "Epoch 1327/2000\n",
      "135/135 [==============================] - 0s 318us/step - loss: 0.1071 - acc: 0.9704 - val_loss: 0.1153 - val_acc: 1.0000\n",
      "Epoch 1328/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1069 - acc: 0.9704 - val_loss: 0.1156 - val_acc: 1.0000\n",
      "Epoch 1329/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.1068 - acc: 0.9704 - val_loss: 0.1141 - val_acc: 1.0000\n",
      "Epoch 1330/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.1070 - acc: 0.9704 - val_loss: 0.1155 - val_acc: 1.0000\n",
      "Epoch 1331/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.1066 - acc: 0.9704 - val_loss: 0.1145 - val_acc: 1.0000\n",
      "Epoch 1332/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1066 - acc: 0.9704 - val_loss: 0.1158 - val_acc: 1.0000\n",
      "Epoch 1333/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.1064 - acc: 0.9778 - val_loss: 0.1136 - val_acc: 1.0000\n",
      "Epoch 1334/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1066 - acc: 0.9704 - val_loss: 0.1129 - val_acc: 1.0000\n",
      "Epoch 1335/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.1062 - acc: 0.9704 - val_loss: 0.1115 - val_acc: 1.0000\n",
      "Epoch 1336/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 0.1062 - acc: 0.9704 - val_loss: 0.1149 - val_acc: 1.0000\n",
      "Epoch 1337/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1065 - acc: 0.9704 - val_loss: 0.1130 - val_acc: 1.0000\n",
      "Epoch 1338/2000\n",
      "135/135 [==============================] - 0s 318us/step - loss: 0.1060 - acc: 0.9704 - val_loss: 0.1158 - val_acc: 1.0000\n",
      "Epoch 1339/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1059 - acc: 0.9704 - val_loss: 0.1164 - val_acc: 1.0000\n",
      "Epoch 1340/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1060 - acc: 0.9704 - val_loss: 0.1161 - val_acc: 1.0000\n",
      "Epoch 1341/2000\n",
      "135/135 [==============================] - 0s 414us/step - loss: 0.1062 - acc: 0.9778 - val_loss: 0.1136 - val_acc: 1.0000\n",
      "Epoch 1342/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1057 - acc: 0.9704 - val_loss: 0.1138 - val_acc: 1.0000\n",
      "Epoch 1343/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1060 - acc: 0.9704 - val_loss: 0.1124 - val_acc: 1.0000\n",
      "Epoch 1344/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.1060 - acc: 0.9704 - val_loss: 0.1114 - val_acc: 1.0000\n",
      "Epoch 1345/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1057 - acc: 0.9704 - val_loss: 0.1116 - val_acc: 1.0000\n",
      "Epoch 1346/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1057 - acc: 0.9704 - val_loss: 0.1114 - val_acc: 1.0000\n",
      "Epoch 1347/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1052 - acc: 0.9630 - val_loss: 0.1146 - val_acc: 1.0000\n",
      "Epoch 1348/2000\n",
      "135/135 [==============================] - 0s 525us/step - loss: 0.1055 - acc: 0.9704 - val_loss: 0.1134 - val_acc: 1.0000\n",
      "Epoch 1349/2000\n",
      "135/135 [==============================] - 0s 414us/step - loss: 0.1052 - acc: 0.9704 - val_loss: 0.1147 - val_acc: 1.0000\n",
      "Epoch 1350/2000\n",
      "135/135 [==============================] - 0s 399us/step - loss: 0.1048 - acc: 0.9778 - val_loss: 0.1131 - val_acc: 1.0000\n",
      "Epoch 1351/2000\n",
      "135/135 [==============================] - 0s 547us/step - loss: 0.1048 - acc: 0.9704 - val_loss: 0.1104 - val_acc: 1.0000\n",
      "Epoch 1352/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1050 - acc: 0.9704 - val_loss: 0.1106 - val_acc: 1.0000\n",
      "Epoch 1353/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 340us/step - loss: 0.1050 - acc: 0.9704 - val_loss: 0.1125 - val_acc: 1.0000\n",
      "Epoch 1354/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.1050 - acc: 0.9704 - val_loss: 0.1119 - val_acc: 1.0000\n",
      "Epoch 1355/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1047 - acc: 0.9778 - val_loss: 0.1103 - val_acc: 1.0000\n",
      "Epoch 1356/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 0.1045 - acc: 0.9704 - val_loss: 0.1106 - val_acc: 1.0000\n",
      "Epoch 1357/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1046 - acc: 0.9704 - val_loss: 0.1123 - val_acc: 1.0000\n",
      "Epoch 1358/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.1045 - acc: 0.9704 - val_loss: 0.1118 - val_acc: 1.0000\n",
      "Epoch 1359/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1049 - acc: 0.9704 - val_loss: 0.1125 - val_acc: 1.0000\n",
      "Epoch 1360/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1042 - acc: 0.9704 - val_loss: 0.1115 - val_acc: 1.0000\n",
      "Epoch 1361/2000\n",
      "135/135 [==============================] - 0s 354us/step - loss: 0.1041 - acc: 0.9704 - val_loss: 0.1124 - val_acc: 1.0000\n",
      "Epoch 1362/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1043 - acc: 0.9704 - val_loss: 0.1115 - val_acc: 1.0000\n",
      "Epoch 1363/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1041 - acc: 0.9704 - val_loss: 0.1121 - val_acc: 1.0000\n",
      "Epoch 1364/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1042 - acc: 0.9704 - val_loss: 0.1126 - val_acc: 1.0000\n",
      "Epoch 1365/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1042 - acc: 0.9778 - val_loss: 0.1104 - val_acc: 1.0000\n",
      "Epoch 1366/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1036 - acc: 0.9704 - val_loss: 0.1109 - val_acc: 1.0000\n",
      "Epoch 1367/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1035 - acc: 0.9704 - val_loss: 0.1117 - val_acc: 1.0000\n",
      "Epoch 1368/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1040 - acc: 0.9704 - val_loss: 0.1108 - val_acc: 1.0000\n",
      "Epoch 1369/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1038 - acc: 0.9704 - val_loss: 0.1098 - val_acc: 1.0000\n",
      "Epoch 1370/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1037 - acc: 0.9704 - val_loss: 0.1093 - val_acc: 1.0000\n",
      "Epoch 1371/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.1034 - acc: 0.9704 - val_loss: 0.1105 - val_acc: 1.0000\n",
      "Epoch 1372/2000\n",
      "135/135 [==============================] - 0s 399us/step - loss: 0.1036 - acc: 0.9704 - val_loss: 0.1115 - val_acc: 1.0000\n",
      "Epoch 1373/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.1036 - acc: 0.9704 - val_loss: 0.1095 - val_acc: 1.0000\n",
      "Epoch 1374/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 0.1036 - acc: 0.9704 - val_loss: 0.1099 - val_acc: 1.0000\n",
      "Epoch 1375/2000\n",
      "135/135 [==============================] - 0s 450us/step - loss: 0.1032 - acc: 0.9704 - val_loss: 0.1103 - val_acc: 1.0000\n",
      "Epoch 1376/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1032 - acc: 0.9704 - val_loss: 0.1094 - val_acc: 1.0000\n",
      "Epoch 1377/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 0.1027 - acc: 0.9704 - val_loss: 0.1074 - val_acc: 1.0000\n",
      "Epoch 1378/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1035 - acc: 0.9704 - val_loss: 0.1098 - val_acc: 1.0000\n",
      "Epoch 1379/2000\n",
      "135/135 [==============================] - 0s 414us/step - loss: 0.1030 - acc: 0.9778 - val_loss: 0.1086 - val_acc: 1.0000\n",
      "Epoch 1380/2000\n",
      "135/135 [==============================] - 0s 451us/step - loss: 0.1029 - acc: 0.9704 - val_loss: 0.1098 - val_acc: 1.0000\n",
      "Epoch 1381/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1028 - acc: 0.9704 - val_loss: 0.1096 - val_acc: 1.0000\n",
      "Epoch 1382/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1028 - acc: 0.9704 - val_loss: 0.1084 - val_acc: 1.0000\n",
      "Epoch 1383/2000\n",
      "135/135 [==============================] - 0s 406us/step - loss: 0.1026 - acc: 0.9704 - val_loss: 0.1091 - val_acc: 1.0000\n",
      "Epoch 1384/2000\n",
      "135/135 [==============================] - 0s 406us/step - loss: 0.1025 - acc: 0.9704 - val_loss: 0.1082 - val_acc: 1.0000\n",
      "Epoch 1385/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.1024 - acc: 0.9778 - val_loss: 0.1060 - val_acc: 1.0000\n",
      "Epoch 1386/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1025 - acc: 0.9704 - val_loss: 0.1084 - val_acc: 1.0000\n",
      "Epoch 1387/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1026 - acc: 0.9704 - val_loss: 0.1095 - val_acc: 1.0000\n",
      "Epoch 1388/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1023 - acc: 0.9778 - val_loss: 0.1073 - val_acc: 1.0000\n",
      "Epoch 1389/2000\n",
      "135/135 [==============================] - 0s 348us/step - loss: 0.1024 - acc: 0.9704 - val_loss: 0.1065 - val_acc: 1.0000\n",
      "Epoch 1390/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1022 - acc: 0.9704 - val_loss: 0.1078 - val_acc: 1.0000\n",
      "Epoch 1391/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1020 - acc: 0.9704 - val_loss: 0.1093 - val_acc: 1.0000\n",
      "Epoch 1392/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.1019 - acc: 0.9704 - val_loss: 0.1082 - val_acc: 1.0000\n",
      "Epoch 1393/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1018 - acc: 0.9704 - val_loss: 0.1068 - val_acc: 1.0000\n",
      "Epoch 1394/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.1019 - acc: 0.9704 - val_loss: 0.1071 - val_acc: 1.0000\n",
      "Epoch 1395/2000\n",
      "135/135 [==============================] - 0s 311us/step - loss: 0.1019 - acc: 0.9704 - val_loss: 0.1062 - val_acc: 1.0000\n",
      "Epoch 1396/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.1017 - acc: 0.9704 - val_loss: 0.1076 - val_acc: 1.0000\n",
      "Epoch 1397/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1014 - acc: 0.9704 - val_loss: 0.1056 - val_acc: 1.0000\n",
      "Epoch 1398/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1019 - acc: 0.9704 - val_loss: 0.1070 - val_acc: 1.0000\n",
      "Epoch 1399/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.1015 - acc: 0.9704 - val_loss: 0.1066 - val_acc: 1.0000\n",
      "Epoch 1400/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1013 - acc: 0.9704 - val_loss: 0.1069 - val_acc: 1.0000\n",
      "Epoch 1401/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.1014 - acc: 0.9704 - val_loss: 0.1077 - val_acc: 1.0000\n",
      "Epoch 1402/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1011 - acc: 0.9704 - val_loss: 0.1076 - val_acc: 1.0000\n",
      "Epoch 1403/2000\n",
      "135/135 [==============================] - 0s 310us/step - loss: 0.1013 - acc: 0.9704 - val_loss: 0.1063 - val_acc: 1.0000\n",
      "Epoch 1404/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.1011 - acc: 0.9704 - val_loss: 0.1057 - val_acc: 1.0000\n",
      "Epoch 1405/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.1009 - acc: 0.9704 - val_loss: 0.1054 - val_acc: 1.0000\n",
      "Epoch 1406/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1010 - acc: 0.9704 - val_loss: 0.1055 - val_acc: 1.0000\n",
      "Epoch 1407/2000\n",
      "135/135 [==============================] - 0s 318us/step - loss: 0.1011 - acc: 0.9704 - val_loss: 0.1043 - val_acc: 1.0000\n",
      "Epoch 1408/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1005 - acc: 0.9704 - val_loss: 0.1033 - val_acc: 1.0000\n",
      "Epoch 1409/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.1005 - acc: 0.9704 - val_loss: 0.1054 - val_acc: 1.0000\n",
      "Epoch 1410/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.1002 - acc: 0.9704 - val_loss: 0.1042 - val_acc: 1.0000\n",
      "Epoch 1411/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.1006 - acc: 0.9704 - val_loss: 0.1055 - val_acc: 1.0000\n",
      "Epoch 1412/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 362us/step - loss: 0.1004 - acc: 0.9704 - val_loss: 0.1041 - val_acc: 1.0000\n",
      "Epoch 1413/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1004 - acc: 0.9704 - val_loss: 0.1068 - val_acc: 1.0000\n",
      "Epoch 1414/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1002 - acc: 0.9704 - val_loss: 0.1064 - val_acc: 1.0000\n",
      "Epoch 1415/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1001 - acc: 0.9704 - val_loss: 0.1065 - val_acc: 1.0000\n",
      "Epoch 1416/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1005 - acc: 0.9704 - val_loss: 0.1058 - val_acc: 1.0000\n",
      "Epoch 1417/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1001 - acc: 0.9704 - val_loss: 0.1053 - val_acc: 1.0000\n",
      "Epoch 1418/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1003 - acc: 0.9704 - val_loss: 0.1063 - val_acc: 1.0000\n",
      "Epoch 1419/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1001 - acc: 0.9704 - val_loss: 0.1074 - val_acc: 1.0000\n",
      "Epoch 1420/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1000 - acc: 0.9704 - val_loss: 0.1054 - val_acc: 1.0000\n",
      "Epoch 1421/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0998 - acc: 0.9704 - val_loss: 0.1052 - val_acc: 1.0000\n",
      "Epoch 1422/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.1001 - acc: 0.9704 - val_loss: 0.1058 - val_acc: 1.0000\n",
      "Epoch 1423/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.1002 - acc: 0.9704 - val_loss: 0.1058 - val_acc: 1.0000\n",
      "Epoch 1424/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.1000 - acc: 0.9704 - val_loss: 0.1046 - val_acc: 1.0000\n",
      "Epoch 1425/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0996 - acc: 0.9704 - val_loss: 0.1053 - val_acc: 1.0000\n",
      "Epoch 1426/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0999 - acc: 0.9704 - val_loss: 0.1052 - val_acc: 1.0000\n",
      "Epoch 1427/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0994 - acc: 0.9704 - val_loss: 0.1048 - val_acc: 1.0000\n",
      "Epoch 1428/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0995 - acc: 0.9704 - val_loss: 0.1049 - val_acc: 1.0000\n",
      "Epoch 1429/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0992 - acc: 0.9704 - val_loss: 0.1051 - val_acc: 1.0000\n",
      "Epoch 1430/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0990 - acc: 0.9704 - val_loss: 0.1056 - val_acc: 1.0000\n",
      "Epoch 1431/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0990 - acc: 0.9704 - val_loss: 0.1057 - val_acc: 1.0000\n",
      "Epoch 1432/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0991 - acc: 0.9704 - val_loss: 0.1058 - val_acc: 1.0000\n",
      "Epoch 1433/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0993 - acc: 0.9778 - val_loss: 0.1037 - val_acc: 1.0000\n",
      "Epoch 1434/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0988 - acc: 0.9778 - val_loss: 0.1015 - val_acc: 1.0000\n",
      "Epoch 1435/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0992 - acc: 0.9778 - val_loss: 0.1012 - val_acc: 1.0000\n",
      "Epoch 1436/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0986 - acc: 0.9704 - val_loss: 0.1016 - val_acc: 1.0000\n",
      "Epoch 1437/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0987 - acc: 0.9704 - val_loss: 0.1021 - val_acc: 1.0000\n",
      "Epoch 1438/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0986 - acc: 0.9704 - val_loss: 0.1046 - val_acc: 1.0000\n",
      "Epoch 1439/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0987 - acc: 0.9704 - val_loss: 0.1056 - val_acc: 1.0000\n",
      "Epoch 1440/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0983 - acc: 0.9704 - val_loss: 0.1046 - val_acc: 1.0000\n",
      "Epoch 1441/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0984 - acc: 0.9704 - val_loss: 0.1046 - val_acc: 1.0000\n",
      "Epoch 1442/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.0982 - acc: 0.9704 - val_loss: 0.1049 - val_acc: 1.0000\n",
      "Epoch 1443/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0985 - acc: 0.9704 - val_loss: 0.1041 - val_acc: 1.0000\n",
      "Epoch 1444/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.0981 - acc: 0.9704 - val_loss: 0.1029 - val_acc: 1.0000\n",
      "Epoch 1445/2000\n",
      "135/135 [==============================] - 0s 414us/step - loss: 0.0982 - acc: 0.9704 - val_loss: 0.1028 - val_acc: 1.0000\n",
      "Epoch 1446/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.0983 - acc: 0.9778 - val_loss: 0.1021 - val_acc: 1.0000\n",
      "Epoch 1447/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0985 - acc: 0.9778 - val_loss: 0.1008 - val_acc: 1.0000\n",
      "Epoch 1448/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.0982 - acc: 0.9704 - val_loss: 0.1025 - val_acc: 1.0000\n",
      "Epoch 1449/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0982 - acc: 0.9704 - val_loss: 0.1027 - val_acc: 1.0000\n",
      "Epoch 1450/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0978 - acc: 0.9778 - val_loss: 0.1017 - val_acc: 1.0000\n",
      "Epoch 1451/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0982 - acc: 0.9704 - val_loss: 0.1020 - val_acc: 1.0000\n",
      "Epoch 1452/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0980 - acc: 0.9704 - val_loss: 0.1026 - val_acc: 1.0000\n",
      "Epoch 1453/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0979 - acc: 0.9704 - val_loss: 0.1040 - val_acc: 1.0000\n",
      "Epoch 1454/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0976 - acc: 0.9778 - val_loss: 0.1019 - val_acc: 1.0000\n",
      "Epoch 1455/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0978 - acc: 0.9704 - val_loss: 0.1024 - val_acc: 1.0000\n",
      "Epoch 1456/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0978 - acc: 0.9704 - val_loss: 0.1018 - val_acc: 1.0000\n",
      "Epoch 1457/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0973 - acc: 0.9704 - val_loss: 0.1019 - val_acc: 1.0000\n",
      "Epoch 1458/2000\n",
      "135/135 [==============================] - 0s 310us/step - loss: 0.0975 - acc: 0.9704 - val_loss: 0.1010 - val_acc: 1.0000\n",
      "Epoch 1459/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0973 - acc: 0.9704 - val_loss: 0.1010 - val_acc: 1.0000\n",
      "Epoch 1460/2000\n",
      "135/135 [==============================] - 0s 303us/step - loss: 0.0972 - acc: 0.9704 - val_loss: 0.1023 - val_acc: 1.0000\n",
      "Epoch 1461/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0971 - acc: 0.9704 - val_loss: 0.1009 - val_acc: 1.0000\n",
      "Epoch 1462/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0971 - acc: 0.9704 - val_loss: 0.1012 - val_acc: 1.0000\n",
      "Epoch 1463/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0973 - acc: 0.9704 - val_loss: 0.1017 - val_acc: 1.0000\n",
      "Epoch 1464/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.0970 - acc: 0.9704 - val_loss: 0.1032 - val_acc: 1.0000\n",
      "Epoch 1465/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0968 - acc: 0.9778 - val_loss: 0.1023 - val_acc: 1.0000\n",
      "Epoch 1466/2000\n",
      "135/135 [==============================] - 0s 370us/step - loss: 0.0967 - acc: 0.9704 - val_loss: 0.1025 - val_acc: 1.0000\n",
      "Epoch 1467/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.0967 - acc: 0.9704 - val_loss: 0.1027 - val_acc: 1.0000\n",
      "Epoch 1468/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0969 - acc: 0.9704 - val_loss: 0.1033 - val_acc: 1.0000\n",
      "Epoch 1469/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.0968 - acc: 0.9704 - val_loss: 0.1030 - val_acc: 1.0000\n",
      "Epoch 1470/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0967 - acc: 0.9704 - val_loss: 0.1020 - val_acc: 1.0000\n",
      "Epoch 1471/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 340us/step - loss: 0.0966 - acc: 0.9704 - val_loss: 0.1010 - val_acc: 1.0000\n",
      "Epoch 1472/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.0969 - acc: 0.9704 - val_loss: 0.0997 - val_acc: 1.0000\n",
      "Epoch 1473/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0964 - acc: 0.9704 - val_loss: 0.1002 - val_acc: 1.0000\n",
      "Epoch 1474/2000\n",
      "135/135 [==============================] - 0s 310us/step - loss: 0.0962 - acc: 0.9704 - val_loss: 0.1027 - val_acc: 1.0000\n",
      "Epoch 1475/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0961 - acc: 0.9704 - val_loss: 0.1036 - val_acc: 1.0000\n",
      "Epoch 1476/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0964 - acc: 0.9778 - val_loss: 0.1025 - val_acc: 1.0000\n",
      "Epoch 1477/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0962 - acc: 0.9704 - val_loss: 0.1022 - val_acc: 1.0000\n",
      "Epoch 1478/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0959 - acc: 0.9704 - val_loss: 0.1020 - val_acc: 1.0000\n",
      "Epoch 1479/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0962 - acc: 0.9704 - val_loss: 0.1006 - val_acc: 1.0000\n",
      "Epoch 1480/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0964 - acc: 0.9778 - val_loss: 0.0996 - val_acc: 1.0000\n",
      "Epoch 1481/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0959 - acc: 0.9778 - val_loss: 0.0973 - val_acc: 1.0000\n",
      "Epoch 1482/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0959 - acc: 0.9704 - val_loss: 0.0976 - val_acc: 1.0000\n",
      "Epoch 1483/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0954 - acc: 0.9704 - val_loss: 0.0998 - val_acc: 1.0000\n",
      "Epoch 1484/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0957 - acc: 0.9704 - val_loss: 0.0976 - val_acc: 1.0000\n",
      "Epoch 1485/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0959 - acc: 0.9704 - val_loss: 0.0975 - val_acc: 1.0000\n",
      "Epoch 1486/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0961 - acc: 0.9704 - val_loss: 0.0985 - val_acc: 1.0000\n",
      "Epoch 1487/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0955 - acc: 0.9704 - val_loss: 0.0986 - val_acc: 1.0000\n",
      "Epoch 1488/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0954 - acc: 0.9704 - val_loss: 0.0995 - val_acc: 1.0000\n",
      "Epoch 1489/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0956 - acc: 0.9704 - val_loss: 0.0995 - val_acc: 1.0000\n",
      "Epoch 1490/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0954 - acc: 0.9704 - val_loss: 0.0998 - val_acc: 1.0000\n",
      "Epoch 1491/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.0952 - acc: 0.9704 - val_loss: 0.0994 - val_acc: 1.0000\n",
      "Epoch 1492/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0954 - acc: 0.9778 - val_loss: 0.0983 - val_acc: 1.0000\n",
      "Epoch 1493/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.0952 - acc: 0.9704 - val_loss: 0.1005 - val_acc: 1.0000\n",
      "Epoch 1494/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0954 - acc: 0.9704 - val_loss: 0.1004 - val_acc: 1.0000\n",
      "Epoch 1495/2000\n",
      "135/135 [==============================] - 0s 370us/step - loss: 0.0952 - acc: 0.9778 - val_loss: 0.0991 - val_acc: 1.0000\n",
      "Epoch 1496/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0954 - acc: 0.9704 - val_loss: 0.0968 - val_acc: 1.0000\n",
      "Epoch 1497/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0954 - acc: 0.9704 - val_loss: 0.0998 - val_acc: 1.0000\n",
      "Epoch 1498/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0952 - acc: 0.9704 - val_loss: 0.0990 - val_acc: 1.0000\n",
      "Epoch 1499/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0947 - acc: 0.9778 - val_loss: 0.0975 - val_acc: 1.0000\n",
      "Epoch 1500/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0949 - acc: 0.9704 - val_loss: 0.0984 - val_acc: 1.0000\n",
      "Epoch 1501/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0946 - acc: 0.9704 - val_loss: 0.1004 - val_acc: 1.0000\n",
      "Epoch 1502/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0946 - acc: 0.9778 - val_loss: 0.0997 - val_acc: 1.0000\n",
      "Epoch 1503/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0945 - acc: 0.9630 - val_loss: 0.1012 - val_acc: 1.0000\n",
      "Epoch 1504/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0944 - acc: 0.9778 - val_loss: 0.1002 - val_acc: 1.0000\n",
      "Epoch 1505/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0948 - acc: 0.9778 - val_loss: 0.0987 - val_acc: 1.0000\n",
      "Epoch 1506/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0947 - acc: 0.9704 - val_loss: 0.1007 - val_acc: 1.0000\n",
      "Epoch 1507/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0945 - acc: 0.9704 - val_loss: 0.1023 - val_acc: 1.0000\n",
      "Epoch 1508/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0950 - acc: 0.9778 - val_loss: 0.1020 - val_acc: 1.0000\n",
      "Epoch 1509/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.0947 - acc: 0.9778 - val_loss: 0.1005 - val_acc: 1.0000\n",
      "Epoch 1510/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.0944 - acc: 0.9778 - val_loss: 0.0998 - val_acc: 1.0000\n",
      "Epoch 1511/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.0939 - acc: 0.9704 - val_loss: 0.0999 - val_acc: 1.0000\n",
      "Epoch 1512/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0941 - acc: 0.9778 - val_loss: 0.0985 - val_acc: 1.0000\n",
      "Epoch 1513/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0937 - acc: 0.9704 - val_loss: 0.0992 - val_acc: 1.0000\n",
      "Epoch 1514/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.0937 - acc: 0.9778 - val_loss: 0.0968 - val_acc: 1.0000\n",
      "Epoch 1515/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0940 - acc: 0.9704 - val_loss: 0.0980 - val_acc: 1.0000\n",
      "Epoch 1516/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.0943 - acc: 0.9778 - val_loss: 0.0972 - val_acc: 1.0000\n",
      "Epoch 1517/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.0942 - acc: 0.9704 - val_loss: 0.0981 - val_acc: 1.0000\n",
      "Epoch 1518/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0937 - acc: 0.9778 - val_loss: 0.0977 - val_acc: 1.0000\n",
      "Epoch 1519/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0937 - acc: 0.9778 - val_loss: 0.0982 - val_acc: 1.0000\n",
      "Epoch 1520/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.0940 - acc: 0.9704 - val_loss: 0.0976 - val_acc: 1.0000\n",
      "Epoch 1521/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0937 - acc: 0.9778 - val_loss: 0.0970 - val_acc: 1.0000\n",
      "Epoch 1522/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0934 - acc: 0.9704 - val_loss: 0.0976 - val_acc: 1.0000\n",
      "Epoch 1523/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.0933 - acc: 0.9778 - val_loss: 0.0959 - val_acc: 1.0000\n",
      "Epoch 1524/2000\n",
      "135/135 [==============================] - 0s 370us/step - loss: 0.0933 - acc: 0.9704 - val_loss: 0.0983 - val_acc: 1.0000\n",
      "Epoch 1525/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0935 - acc: 0.9704 - val_loss: 0.0985 - val_acc: 1.0000\n",
      "Epoch 1526/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0933 - acc: 0.9778 - val_loss: 0.0983 - val_acc: 1.0000\n",
      "Epoch 1527/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.0934 - acc: 0.9778 - val_loss: 0.0975 - val_acc: 1.0000\n",
      "Epoch 1528/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0934 - acc: 0.9704 - val_loss: 0.0995 - val_acc: 1.0000\n",
      "Epoch 1529/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.0932 - acc: 0.9778 - val_loss: 0.0994 - val_acc: 1.0000\n",
      "Epoch 1530/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 340us/step - loss: 0.0930 - acc: 0.9778 - val_loss: 0.0983 - val_acc: 1.0000\n",
      "Epoch 1531/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0933 - acc: 0.9704 - val_loss: 0.0976 - val_acc: 1.0000\n",
      "Epoch 1532/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.0930 - acc: 0.9704 - val_loss: 0.0975 - val_acc: 1.0000\n",
      "Epoch 1533/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0929 - acc: 0.9704 - val_loss: 0.0989 - val_acc: 1.0000\n",
      "Epoch 1534/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0927 - acc: 0.9704 - val_loss: 0.0975 - val_acc: 1.0000\n",
      "Epoch 1535/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0929 - acc: 0.9704 - val_loss: 0.0968 - val_acc: 1.0000\n",
      "Epoch 1536/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0928 - acc: 0.9704 - val_loss: 0.0949 - val_acc: 1.0000\n",
      "Epoch 1537/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0926 - acc: 0.9704 - val_loss: 0.0972 - val_acc: 1.0000\n",
      "Epoch 1538/2000\n",
      "135/135 [==============================] - 0s 517us/step - loss: 0.0927 - acc: 0.9704 - val_loss: 0.0983 - val_acc: 1.0000\n",
      "Epoch 1539/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.0926 - acc: 0.9704 - val_loss: 0.0980 - val_acc: 1.0000\n",
      "Epoch 1540/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0927 - acc: 0.9704 - val_loss: 0.0975 - val_acc: 1.0000\n",
      "Epoch 1541/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0925 - acc: 0.9778 - val_loss: 0.0960 - val_acc: 1.0000\n",
      "Epoch 1542/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0925 - acc: 0.9704 - val_loss: 0.0972 - val_acc: 1.0000\n",
      "Epoch 1543/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0926 - acc: 0.9704 - val_loss: 0.0980 - val_acc: 1.0000\n",
      "Epoch 1544/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0922 - acc: 0.9704 - val_loss: 0.0993 - val_acc: 1.0000\n",
      "Epoch 1545/2000\n",
      "135/135 [==============================] - 0s 414us/step - loss: 0.0923 - acc: 0.9704 - val_loss: 0.0975 - val_acc: 1.0000\n",
      "Epoch 1546/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0924 - acc: 0.9778 - val_loss: 0.0955 - val_acc: 1.0000\n",
      "Epoch 1547/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0920 - acc: 0.9704 - val_loss: 0.0966 - val_acc: 1.0000\n",
      "Epoch 1548/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0923 - acc: 0.9704 - val_loss: 0.0959 - val_acc: 1.0000\n",
      "Epoch 1549/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0919 - acc: 0.9704 - val_loss: 0.0955 - val_acc: 1.0000\n",
      "Epoch 1550/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0920 - acc: 0.9704 - val_loss: 0.0956 - val_acc: 1.0000\n",
      "Epoch 1551/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0917 - acc: 0.9704 - val_loss: 0.0970 - val_acc: 1.0000\n",
      "Epoch 1552/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0919 - acc: 0.9704 - val_loss: 0.0962 - val_acc: 1.0000\n",
      "Epoch 1553/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.0922 - acc: 0.9704 - val_loss: 0.0972 - val_acc: 1.0000\n",
      "Epoch 1554/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0919 - acc: 0.9778 - val_loss: 0.0946 - val_acc: 1.0000\n",
      "Epoch 1555/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0914 - acc: 0.9704 - val_loss: 0.0950 - val_acc: 1.0000\n",
      "Epoch 1556/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.0917 - acc: 0.9704 - val_loss: 0.0960 - val_acc: 1.0000\n",
      "Epoch 1557/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0918 - acc: 0.9704 - val_loss: 0.0960 - val_acc: 1.0000\n",
      "Epoch 1558/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 0.0914 - acc: 0.9778 - val_loss: 0.0953 - val_acc: 1.0000\n",
      "Epoch 1559/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.0913 - acc: 0.9778 - val_loss: 0.0939 - val_acc: 1.0000\n",
      "Epoch 1560/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.0917 - acc: 0.9704 - val_loss: 0.0955 - val_acc: 1.0000\n",
      "Epoch 1561/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0913 - acc: 0.9778 - val_loss: 0.0940 - val_acc: 1.0000\n",
      "Epoch 1562/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0915 - acc: 0.9704 - val_loss: 0.0938 - val_acc: 1.0000\n",
      "Epoch 1563/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.0916 - acc: 0.9704 - val_loss: 0.0955 - val_acc: 1.0000\n",
      "Epoch 1564/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0912 - acc: 0.9778 - val_loss: 0.0947 - val_acc: 1.0000\n",
      "Epoch 1565/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.0912 - acc: 0.9778 - val_loss: 0.0937 - val_acc: 1.0000\n",
      "Epoch 1566/2000\n",
      "135/135 [==============================] - 0s 318us/step - loss: 0.0913 - acc: 0.9704 - val_loss: 0.0941 - val_acc: 1.0000\n",
      "Epoch 1567/2000\n",
      "135/135 [==============================] - 0s 421us/step - loss: 0.0908 - acc: 0.9778 - val_loss: 0.0919 - val_acc: 1.0000\n",
      "Epoch 1568/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0909 - acc: 0.9704 - val_loss: 0.0925 - val_acc: 1.0000\n",
      "Epoch 1569/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0909 - acc: 0.9778 - val_loss: 0.0930 - val_acc: 1.0000\n",
      "Epoch 1570/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0909 - acc: 0.9704 - val_loss: 0.0955 - val_acc: 1.0000\n",
      "Epoch 1571/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0909 - acc: 0.9778 - val_loss: 0.0944 - val_acc: 1.0000\n",
      "Epoch 1572/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.0907 - acc: 0.9704 - val_loss: 0.0957 - val_acc: 1.0000\n",
      "Epoch 1573/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0908 - acc: 0.9704 - val_loss: 0.0955 - val_acc: 1.0000\n",
      "Epoch 1574/2000\n",
      "135/135 [==============================] - 0s 310us/step - loss: 0.0906 - acc: 0.9704 - val_loss: 0.0969 - val_acc: 1.0000\n",
      "Epoch 1575/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0905 - acc: 0.9778 - val_loss: 0.0949 - val_acc: 1.0000\n",
      "Epoch 1576/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 0.0909 - acc: 0.9704 - val_loss: 0.0939 - val_acc: 1.0000\n",
      "Epoch 1577/2000\n",
      "135/135 [==============================] - 0s 333us/step - loss: 0.0906 - acc: 0.9704 - val_loss: 0.0961 - val_acc: 1.0000\n",
      "Epoch 1578/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0907 - acc: 0.9704 - val_loss: 0.0974 - val_acc: 1.0000\n",
      "Epoch 1579/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0907 - acc: 0.9704 - val_loss: 0.0959 - val_acc: 1.0000\n",
      "Epoch 1580/2000\n",
      "135/135 [==============================] - 0s 333us/step - loss: 0.0902 - acc: 0.9778 - val_loss: 0.0936 - val_acc: 1.0000\n",
      "Epoch 1581/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0906 - acc: 0.9778 - val_loss: 0.0940 - val_acc: 1.0000\n",
      "Epoch 1582/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.0903 - acc: 0.9704 - val_loss: 0.0956 - val_acc: 1.0000\n",
      "Epoch 1583/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0903 - acc: 0.9778 - val_loss: 0.0952 - val_acc: 1.0000\n",
      "Epoch 1584/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.0902 - acc: 0.9704 - val_loss: 0.0943 - val_acc: 1.0000\n",
      "Epoch 1585/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0902 - acc: 0.9704 - val_loss: 0.0940 - val_acc: 1.0000\n",
      "Epoch 1586/2000\n",
      "135/135 [==============================] - 0s 370us/step - loss: 0.0905 - acc: 0.9704 - val_loss: 0.0949 - val_acc: 1.0000\n",
      "Epoch 1587/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.0901 - acc: 0.9630 - val_loss: 0.0965 - val_acc: 1.0000\n",
      "Epoch 1588/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0902 - acc: 0.9704 - val_loss: 0.0958 - val_acc: 1.0000\n",
      "Epoch 1589/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 362us/step - loss: 0.0901 - acc: 0.9778 - val_loss: 0.0942 - val_acc: 1.0000\n",
      "Epoch 1590/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0900 - acc: 0.9778 - val_loss: 0.0949 - val_acc: 1.0000\n",
      "Epoch 1591/2000\n",
      "135/135 [==============================] - 0s 331us/step - loss: 0.0901 - acc: 0.9704 - val_loss: 0.0940 - val_acc: 1.0000\n",
      "Epoch 1592/2000\n",
      "135/135 [==============================] - 0s 390us/step - loss: 0.0901 - acc: 0.9778 - val_loss: 0.0922 - val_acc: 1.0000\n",
      "Epoch 1593/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0901 - acc: 0.9704 - val_loss: 0.0919 - val_acc: 1.0000\n",
      "Epoch 1594/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0896 - acc: 0.9704 - val_loss: 0.0922 - val_acc: 1.0000\n",
      "Epoch 1595/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0898 - acc: 0.9778 - val_loss: 0.0941 - val_acc: 1.0000\n",
      "Epoch 1596/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0898 - acc: 0.9778 - val_loss: 0.0936 - val_acc: 1.0000\n",
      "Epoch 1597/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0896 - acc: 0.9704 - val_loss: 0.0931 - val_acc: 1.0000\n",
      "Epoch 1598/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0896 - acc: 0.9778 - val_loss: 0.0935 - val_acc: 1.0000\n",
      "Epoch 1599/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0893 - acc: 0.9704 - val_loss: 0.0954 - val_acc: 1.0000\n",
      "Epoch 1600/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0894 - acc: 0.9778 - val_loss: 0.0964 - val_acc: 1.0000\n",
      "Epoch 1601/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0893 - acc: 0.9778 - val_loss: 0.0929 - val_acc: 1.0000\n",
      "Epoch 1602/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0894 - acc: 0.9778 - val_loss: 0.0922 - val_acc: 1.0000\n",
      "Epoch 1603/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0892 - acc: 0.9704 - val_loss: 0.0937 - val_acc: 1.0000\n",
      "Epoch 1604/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0893 - acc: 0.9704 - val_loss: 0.0927 - val_acc: 1.0000\n",
      "Epoch 1605/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0892 - acc: 0.9704 - val_loss: 0.0935 - val_acc: 1.0000\n",
      "Epoch 1606/2000\n",
      "135/135 [==============================] - 0s 370us/step - loss: 0.0893 - acc: 0.9778 - val_loss: 0.0933 - val_acc: 1.0000\n",
      "Epoch 1607/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0891 - acc: 0.9704 - val_loss: 0.0945 - val_acc: 1.0000\n",
      "Epoch 1608/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0891 - acc: 0.9778 - val_loss: 0.0942 - val_acc: 1.0000\n",
      "Epoch 1609/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0889 - acc: 0.9778 - val_loss: 0.0919 - val_acc: 1.0000\n",
      "Epoch 1610/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0891 - acc: 0.9778 - val_loss: 0.0918 - val_acc: 1.0000\n",
      "Epoch 1611/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0891 - acc: 0.9778 - val_loss: 0.0925 - val_acc: 1.0000\n",
      "Epoch 1612/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0889 - acc: 0.9778 - val_loss: 0.0907 - val_acc: 1.0000\n",
      "Epoch 1613/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0888 - acc: 0.9704 - val_loss: 0.0909 - val_acc: 1.0000\n",
      "Epoch 1614/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0887 - acc: 0.9778 - val_loss: 0.0913 - val_acc: 1.0000\n",
      "Epoch 1615/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0885 - acc: 0.9704 - val_loss: 0.0926 - val_acc: 1.0000\n",
      "Epoch 1616/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0887 - acc: 0.9704 - val_loss: 0.0922 - val_acc: 1.0000\n",
      "Epoch 1617/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0884 - acc: 0.9778 - val_loss: 0.0901 - val_acc: 1.0000\n",
      "Epoch 1618/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0883 - acc: 0.9704 - val_loss: 0.0904 - val_acc: 1.0000\n",
      "Epoch 1619/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0887 - acc: 0.9704 - val_loss: 0.0913 - val_acc: 1.0000\n",
      "Epoch 1620/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0883 - acc: 0.9704 - val_loss: 0.0911 - val_acc: 1.0000\n",
      "Epoch 1621/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0887 - acc: 0.9704 - val_loss: 0.0929 - val_acc: 1.0000\n",
      "Epoch 1622/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 0.0882 - acc: 0.9704 - val_loss: 0.0923 - val_acc: 1.0000\n",
      "Epoch 1623/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0879 - acc: 0.9704 - val_loss: 0.0929 - val_acc: 1.0000\n",
      "Epoch 1624/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0884 - acc: 0.9778 - val_loss: 0.0918 - val_acc: 1.0000\n",
      "Epoch 1625/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.0883 - acc: 0.9704 - val_loss: 0.0933 - val_acc: 1.0000\n",
      "Epoch 1626/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0883 - acc: 0.9704 - val_loss: 0.0923 - val_acc: 1.0000\n",
      "Epoch 1627/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.0883 - acc: 0.9704 - val_loss: 0.0937 - val_acc: 1.0000\n",
      "Epoch 1628/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0879 - acc: 0.9778 - val_loss: 0.0917 - val_acc: 1.0000\n",
      "Epoch 1629/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0882 - acc: 0.9778 - val_loss: 0.0895 - val_acc: 1.0000\n",
      "Epoch 1630/2000\n",
      "135/135 [==============================] - 0s 399us/step - loss: 0.0882 - acc: 0.9704 - val_loss: 0.0890 - val_acc: 1.0000\n",
      "Epoch 1631/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.0880 - acc: 0.9778 - val_loss: 0.0890 - val_acc: 1.0000\n",
      "Epoch 1632/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0880 - acc: 0.9704 - val_loss: 0.0893 - val_acc: 1.0000\n",
      "Epoch 1633/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0877 - acc: 0.9778 - val_loss: 0.0896 - val_acc: 1.0000\n",
      "Epoch 1634/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0881 - acc: 0.9704 - val_loss: 0.0919 - val_acc: 1.0000\n",
      "Epoch 1635/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0877 - acc: 0.9778 - val_loss: 0.0921 - val_acc: 1.0000\n",
      "Epoch 1636/2000\n",
      "135/135 [==============================] - 0s 428us/step - loss: 0.0876 - acc: 0.9778 - val_loss: 0.0912 - val_acc: 1.0000\n",
      "Epoch 1637/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0878 - acc: 0.9704 - val_loss: 0.0915 - val_acc: 1.0000\n",
      "Epoch 1638/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0877 - acc: 0.9704 - val_loss: 0.0931 - val_acc: 1.0000\n",
      "Epoch 1639/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.0873 - acc: 0.9778 - val_loss: 0.0913 - val_acc: 1.0000\n",
      "Epoch 1640/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0877 - acc: 0.9778 - val_loss: 0.0902 - val_acc: 1.0000\n",
      "Epoch 1641/2000\n",
      "135/135 [==============================] - 0s 436us/step - loss: 0.0874 - acc: 0.9778 - val_loss: 0.0892 - val_acc: 1.0000\n",
      "Epoch 1642/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.0876 - acc: 0.9778 - val_loss: 0.0911 - val_acc: 1.0000\n",
      "Epoch 1643/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0872 - acc: 0.9778 - val_loss: 0.0893 - val_acc: 1.0000\n",
      "Epoch 1644/2000\n",
      "135/135 [==============================] - 0s 404us/step - loss: 0.0875 - acc: 0.9704 - val_loss: 0.0912 - val_acc: 1.0000\n",
      "Epoch 1645/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.0873 - acc: 0.9778 - val_loss: 0.0891 - val_acc: 1.0000\n",
      "Epoch 1646/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0875 - acc: 0.9704 - val_loss: 0.0899 - val_acc: 1.0000\n",
      "Epoch 1647/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0876 - acc: 0.9778 - val_loss: 0.0881 - val_acc: 1.0000\n",
      "Epoch 1648/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 333us/step - loss: 0.0872 - acc: 0.9704 - val_loss: 0.0884 - val_acc: 1.0000\n",
      "Epoch 1649/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.0870 - acc: 0.9778 - val_loss: 0.0903 - val_acc: 1.0000\n",
      "Epoch 1650/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0870 - acc: 0.9704 - val_loss: 0.0898 - val_acc: 1.0000\n",
      "Epoch 1651/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0872 - acc: 0.9704 - val_loss: 0.0904 - val_acc: 1.0000\n",
      "Epoch 1652/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0870 - acc: 0.9704 - val_loss: 0.0918 - val_acc: 1.0000\n",
      "Epoch 1653/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0870 - acc: 0.9778 - val_loss: 0.0897 - val_acc: 1.0000\n",
      "Epoch 1654/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0868 - acc: 0.9778 - val_loss: 0.0878 - val_acc: 1.0000\n",
      "Epoch 1655/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0867 - acc: 0.9778 - val_loss: 0.0878 - val_acc: 1.0000\n",
      "Epoch 1656/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0870 - acc: 0.9704 - val_loss: 0.0880 - val_acc: 1.0000\n",
      "Epoch 1657/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0867 - acc: 0.9704 - val_loss: 0.0873 - val_acc: 1.0000\n",
      "Epoch 1658/2000\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.0292 - acc: 1.000 - 0s 355us/step - loss: 0.0866 - acc: 0.9704 - val_loss: 0.0883 - val_acc: 1.0000\n",
      "Epoch 1659/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0866 - acc: 0.9778 - val_loss: 0.0865 - val_acc: 1.0000\n",
      "Epoch 1660/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0867 - acc: 0.9704 - val_loss: 0.0884 - val_acc: 1.0000\n",
      "Epoch 1661/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0869 - acc: 0.9704 - val_loss: 0.0893 - val_acc: 1.0000\n",
      "Epoch 1662/2000\n",
      "135/135 [==============================] - 0s 517us/step - loss: 0.0866 - acc: 0.9704 - val_loss: 0.0888 - val_acc: 1.0000\n",
      "Epoch 1663/2000\n",
      "135/135 [==============================] - 0s 717us/step - loss: 0.0867 - acc: 0.9778 - val_loss: 0.0896 - val_acc: 1.0000\n",
      "Epoch 1664/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0863 - acc: 0.9704 - val_loss: 0.0904 - val_acc: 1.0000\n",
      "Epoch 1665/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0864 - acc: 0.9778 - val_loss: 0.0884 - val_acc: 1.0000\n",
      "Epoch 1666/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0865 - acc: 0.9778 - val_loss: 0.0874 - val_acc: 1.0000\n",
      "Epoch 1667/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 0.0864 - acc: 0.9778 - val_loss: 0.0879 - val_acc: 1.0000\n",
      "Epoch 1668/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0864 - acc: 0.9704 - val_loss: 0.0898 - val_acc: 1.0000\n",
      "Epoch 1669/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0863 - acc: 0.9704 - val_loss: 0.0903 - val_acc: 1.0000\n",
      "Epoch 1670/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0861 - acc: 0.9778 - val_loss: 0.0884 - val_acc: 1.0000\n",
      "Epoch 1671/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0862 - acc: 0.9704 - val_loss: 0.0901 - val_acc: 1.0000\n",
      "Epoch 1672/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0863 - acc: 0.9704 - val_loss: 0.0897 - val_acc: 1.0000\n",
      "Epoch 1673/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0864 - acc: 0.9778 - val_loss: 0.0875 - val_acc: 1.0000\n",
      "Epoch 1674/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0862 - acc: 0.9704 - val_loss: 0.0888 - val_acc: 1.0000\n",
      "Epoch 1675/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.0861 - acc: 0.9778 - val_loss: 0.0896 - val_acc: 1.0000\n",
      "Epoch 1676/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0858 - acc: 0.9704 - val_loss: 0.0915 - val_acc: 1.0000\n",
      "Epoch 1677/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.0857 - acc: 0.9704 - val_loss: 0.0928 - val_acc: 1.0000\n",
      "Epoch 1678/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.0861 - acc: 0.9778 - val_loss: 0.0918 - val_acc: 1.0000\n",
      "Epoch 1679/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0859 - acc: 0.9778 - val_loss: 0.0908 - val_acc: 1.0000\n",
      "Epoch 1680/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0857 - acc: 0.9778 - val_loss: 0.0895 - val_acc: 1.0000\n",
      "Epoch 1681/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.0855 - acc: 0.9778 - val_loss: 0.0877 - val_acc: 1.0000\n",
      "Epoch 1682/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0857 - acc: 0.9778 - val_loss: 0.0877 - val_acc: 1.0000\n",
      "Epoch 1683/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0858 - acc: 0.9704 - val_loss: 0.0880 - val_acc: 1.0000\n",
      "Epoch 1684/2000\n",
      "135/135 [==============================] - 0s 399us/step - loss: 0.0852 - acc: 0.9778 - val_loss: 0.0887 - val_acc: 1.0000\n",
      "Epoch 1685/2000\n",
      "135/135 [==============================] - 0s 421us/step - loss: 0.0853 - acc: 0.9852 - val_loss: 0.0861 - val_acc: 1.0000\n",
      "Epoch 1686/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0856 - acc: 0.9778 - val_loss: 0.0859 - val_acc: 1.0000\n",
      "Epoch 1687/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 0.0854 - acc: 0.9704 - val_loss: 0.0872 - val_acc: 1.0000\n",
      "Epoch 1688/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0859 - acc: 0.9704 - val_loss: 0.0875 - val_acc: 1.0000\n",
      "Epoch 1689/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.0856 - acc: 0.9778 - val_loss: 0.0873 - val_acc: 1.0000\n",
      "Epoch 1690/2000\n",
      "135/135 [==============================] - 0s 318us/step - loss: 0.0853 - acc: 0.9704 - val_loss: 0.0888 - val_acc: 1.0000\n",
      "Epoch 1691/2000\n",
      "135/135 [==============================] - 0s 414us/step - loss: 0.0852 - acc: 0.9778 - val_loss: 0.0876 - val_acc: 1.0000\n",
      "Epoch 1692/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.0850 - acc: 0.9704 - val_loss: 0.0877 - val_acc: 1.0000\n",
      "Epoch 1693/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0854 - acc: 0.9778 - val_loss: 0.0879 - val_acc: 1.0000\n",
      "Epoch 1694/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0854 - acc: 0.9778 - val_loss: 0.0883 - val_acc: 1.0000\n",
      "Epoch 1695/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0849 - acc: 0.9778 - val_loss: 0.0874 - val_acc: 1.0000\n",
      "Epoch 1696/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0848 - acc: 0.9778 - val_loss: 0.0859 - val_acc: 1.0000\n",
      "Epoch 1697/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.0854 - acc: 0.9704 - val_loss: 0.0884 - val_acc: 1.0000\n",
      "Epoch 1698/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.0849 - acc: 0.9778 - val_loss: 0.0888 - val_acc: 1.0000\n",
      "Epoch 1699/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0850 - acc: 0.9704 - val_loss: 0.0876 - val_acc: 1.0000\n",
      "Epoch 1700/2000\n",
      "135/135 [==============================] - 0s 399us/step - loss: 0.0851 - acc: 0.9704 - val_loss: 0.0879 - val_acc: 1.0000\n",
      "Epoch 1701/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.0848 - acc: 0.9778 - val_loss: 0.0876 - val_acc: 1.0000\n",
      "Epoch 1702/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0852 - acc: 0.9704 - val_loss: 0.0873 - val_acc: 1.0000\n",
      "Epoch 1703/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0852 - acc: 0.9778 - val_loss: 0.0880 - val_acc: 1.0000\n",
      "Epoch 1704/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0849 - acc: 0.9704 - val_loss: 0.0882 - val_acc: 1.0000\n",
      "Epoch 1705/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0849 - acc: 0.9778 - val_loss: 0.0857 - val_acc: 1.0000\n",
      "Epoch 1706/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.0848 - acc: 0.9704 - val_loss: 0.0866 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1707/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.0847 - acc: 0.9778 - val_loss: 0.0862 - val_acc: 1.0000\n",
      "Epoch 1708/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.0845 - acc: 0.9778 - val_loss: 0.0856 - val_acc: 1.0000\n",
      "Epoch 1709/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0846 - acc: 0.9778 - val_loss: 0.0853 - val_acc: 1.0000\n",
      "Epoch 1710/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0851 - acc: 0.9778 - val_loss: 0.0850 - val_acc: 1.0000\n",
      "Epoch 1711/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0843 - acc: 0.9778 - val_loss: 0.0868 - val_acc: 1.0000\n",
      "Epoch 1712/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0845 - acc: 0.9778 - val_loss: 0.0852 - val_acc: 1.0000\n",
      "Epoch 1713/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0842 - acc: 0.9778 - val_loss: 0.0868 - val_acc: 1.0000\n",
      "Epoch 1714/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0845 - acc: 0.9778 - val_loss: 0.0856 - val_acc: 1.0000\n",
      "Epoch 1715/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0845 - acc: 0.9778 - val_loss: 0.0849 - val_acc: 1.0000\n",
      "Epoch 1716/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0844 - acc: 0.9778 - val_loss: 0.0855 - val_acc: 1.0000\n",
      "Epoch 1717/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0843 - acc: 0.9778 - val_loss: 0.0864 - val_acc: 1.0000\n",
      "Epoch 1718/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 0.0842 - acc: 0.9778 - val_loss: 0.0850 - val_acc: 1.0000\n",
      "Epoch 1719/2000\n",
      "135/135 [==============================] - 0s 318us/step - loss: 0.0845 - acc: 0.9778 - val_loss: 0.0844 - val_acc: 1.0000\n",
      "Epoch 1720/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0842 - acc: 0.9778 - val_loss: 0.0817 - val_acc: 1.0000\n",
      "Epoch 1721/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0845 - acc: 0.9630 - val_loss: 0.0842 - val_acc: 1.0000\n",
      "Epoch 1722/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0840 - acc: 0.9778 - val_loss: 0.0838 - val_acc: 1.0000\n",
      "Epoch 1723/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.0838 - acc: 0.9704 - val_loss: 0.0846 - val_acc: 1.0000\n",
      "Epoch 1724/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.0841 - acc: 0.9704 - val_loss: 0.0861 - val_acc: 1.0000\n",
      "Epoch 1725/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0844 - acc: 0.9704 - val_loss: 0.0861 - val_acc: 1.0000\n",
      "Epoch 1726/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0841 - acc: 0.9778 - val_loss: 0.0863 - val_acc: 1.0000\n",
      "Epoch 1727/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.0834 - acc: 0.9778 - val_loss: 0.0848 - val_acc: 1.0000\n",
      "Epoch 1728/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.0844 - acc: 0.9704 - val_loss: 0.0861 - val_acc: 1.0000\n",
      "Epoch 1729/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0838 - acc: 0.9778 - val_loss: 0.0839 - val_acc: 1.0000\n",
      "Epoch 1730/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0835 - acc: 0.9704 - val_loss: 0.0860 - val_acc: 1.0000\n",
      "Epoch 1731/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0838 - acc: 0.9778 - val_loss: 0.0848 - val_acc: 1.0000\n",
      "Epoch 1732/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0839 - acc: 0.9778 - val_loss: 0.0854 - val_acc: 1.0000\n",
      "Epoch 1733/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.0837 - acc: 0.9778 - val_loss: 0.0856 - val_acc: 1.0000\n",
      "Epoch 1734/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0838 - acc: 0.9778 - val_loss: 0.0857 - val_acc: 1.0000\n",
      "Epoch 1735/2000\n",
      "135/135 [==============================] - 0s 421us/step - loss: 0.0837 - acc: 0.9778 - val_loss: 0.0843 - val_acc: 1.0000\n",
      "Epoch 1736/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0832 - acc: 0.9704 - val_loss: 0.0861 - val_acc: 1.0000\n",
      "Epoch 1737/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0838 - acc: 0.9778 - val_loss: 0.0855 - val_acc: 1.0000\n",
      "Epoch 1738/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0832 - acc: 0.9704 - val_loss: 0.0870 - val_acc: 1.0000\n",
      "Epoch 1739/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.0835 - acc: 0.9778 - val_loss: 0.0861 - val_acc: 1.0000\n",
      "Epoch 1740/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.0835 - acc: 0.9704 - val_loss: 0.0865 - val_acc: 1.0000\n",
      "Epoch 1741/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0830 - acc: 0.9778 - val_loss: 0.0842 - val_acc: 1.0000\n",
      "Epoch 1742/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.0840 - acc: 0.9704 - val_loss: 0.0829 - val_acc: 1.0000\n",
      "Epoch 1743/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.0828 - acc: 0.9704 - val_loss: 0.0859 - val_acc: 1.0000\n",
      "Epoch 1744/2000\n",
      "135/135 [==============================] - 0s 318us/step - loss: 0.0832 - acc: 0.9778 - val_loss: 0.0855 - val_acc: 1.0000\n",
      "Epoch 1745/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0831 - acc: 0.9778 - val_loss: 0.0855 - val_acc: 1.0000\n",
      "Epoch 1746/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0834 - acc: 0.9778 - val_loss: 0.0860 - val_acc: 1.0000\n",
      "Epoch 1747/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0833 - acc: 0.9778 - val_loss: 0.0872 - val_acc: 1.0000\n",
      "Epoch 1748/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0827 - acc: 0.9778 - val_loss: 0.0860 - val_acc: 1.0000\n",
      "Epoch 1749/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0832 - acc: 0.9778 - val_loss: 0.0855 - val_acc: 1.0000\n",
      "Epoch 1750/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0833 - acc: 0.9778 - val_loss: 0.0840 - val_acc: 1.0000\n",
      "Epoch 1751/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0827 - acc: 0.9778 - val_loss: 0.0819 - val_acc: 1.0000\n",
      "Epoch 1752/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0833 - acc: 0.9778 - val_loss: 0.0819 - val_acc: 1.0000\n",
      "Epoch 1753/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0829 - acc: 0.9704 - val_loss: 0.0841 - val_acc: 1.0000\n",
      "Epoch 1754/2000\n",
      "135/135 [==============================] - 0s 421us/step - loss: 0.0827 - acc: 0.9778 - val_loss: 0.0825 - val_acc: 1.0000\n",
      "Epoch 1755/2000\n",
      "135/135 [==============================] - 0s 318us/step - loss: 0.0827 - acc: 0.9778 - val_loss: 0.0831 - val_acc: 1.0000\n",
      "Epoch 1756/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0827 - acc: 0.9704 - val_loss: 0.0837 - val_acc: 1.0000\n",
      "Epoch 1757/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 0.0826 - acc: 0.9704 - val_loss: 0.0854 - val_acc: 1.0000\n",
      "Epoch 1758/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0827 - acc: 0.9704 - val_loss: 0.0856 - val_acc: 1.0000\n",
      "Epoch 1759/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0832 - acc: 0.9704 - val_loss: 0.0856 - val_acc: 1.0000\n",
      "Epoch 1760/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0823 - acc: 0.9778 - val_loss: 0.0856 - val_acc: 1.0000\n",
      "Epoch 1761/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.0825 - acc: 0.9778 - val_loss: 0.0841 - val_acc: 1.0000\n",
      "Epoch 1762/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0827 - acc: 0.9778 - val_loss: 0.0842 - val_acc: 1.0000\n",
      "Epoch 1763/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.0824 - acc: 0.9778 - val_loss: 0.0843 - val_acc: 1.0000\n",
      "Epoch 1764/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0826 - acc: 0.9704 - val_loss: 0.0838 - val_acc: 1.0000\n",
      "Epoch 1765/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0822 - acc: 0.9704 - val_loss: 0.0846 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1766/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.0827 - acc: 0.9704 - val_loss: 0.0865 - val_acc: 1.0000\n",
      "Epoch 1767/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0822 - acc: 0.9778 - val_loss: 0.0845 - val_acc: 1.0000\n",
      "Epoch 1768/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0825 - acc: 0.9704 - val_loss: 0.0857 - val_acc: 1.0000\n",
      "Epoch 1769/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0822 - acc: 0.9778 - val_loss: 0.0862 - val_acc: 1.0000\n",
      "Epoch 1770/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0824 - acc: 0.9778 - val_loss: 0.0851 - val_acc: 1.0000\n",
      "Epoch 1771/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0819 - acc: 0.9778 - val_loss: 0.0848 - val_acc: 1.0000\n",
      "Epoch 1772/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.0822 - acc: 0.9778 - val_loss: 0.0843 - val_acc: 1.0000\n",
      "Epoch 1773/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0823 - acc: 0.9778 - val_loss: 0.0836 - val_acc: 1.0000\n",
      "Epoch 1774/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0824 - acc: 0.9778 - val_loss: 0.0842 - val_acc: 1.0000\n",
      "Epoch 1775/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0823 - acc: 0.9704 - val_loss: 0.0857 - val_acc: 1.0000\n",
      "Epoch 1776/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0818 - acc: 0.9778 - val_loss: 0.0833 - val_acc: 1.0000\n",
      "Epoch 1777/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0819 - acc: 0.9778 - val_loss: 0.0837 - val_acc: 1.0000\n",
      "Epoch 1778/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0818 - acc: 0.9778 - val_loss: 0.0820 - val_acc: 1.0000\n",
      "Epoch 1779/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0822 - acc: 0.9778 - val_loss: 0.0827 - val_acc: 1.0000\n",
      "Epoch 1780/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0819 - acc: 0.9704 - val_loss: 0.0843 - val_acc: 1.0000\n",
      "Epoch 1781/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0821 - acc: 0.9778 - val_loss: 0.0836 - val_acc: 1.0000\n",
      "Epoch 1782/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0818 - acc: 0.9778 - val_loss: 0.0824 - val_acc: 1.0000\n",
      "Epoch 1783/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0813 - acc: 0.9778 - val_loss: 0.0824 - val_acc: 1.0000\n",
      "Epoch 1784/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0815 - acc: 0.9704 - val_loss: 0.0833 - val_acc: 1.0000\n",
      "Epoch 1785/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0816 - acc: 0.9778 - val_loss: 0.0821 - val_acc: 1.0000\n",
      "Epoch 1786/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0818 - acc: 0.9778 - val_loss: 0.0816 - val_acc: 1.0000\n",
      "Epoch 1787/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0814 - acc: 0.9778 - val_loss: 0.0820 - val_acc: 1.0000\n",
      "Epoch 1788/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0818 - acc: 0.9778 - val_loss: 0.0832 - val_acc: 1.0000\n",
      "Epoch 1789/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0820 - acc: 0.9704 - val_loss: 0.0828 - val_acc: 1.0000\n",
      "Epoch 1790/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0816 - acc: 0.9778 - val_loss: 0.0829 - val_acc: 1.0000\n",
      "Epoch 1791/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0816 - acc: 0.9704 - val_loss: 0.0839 - val_acc: 1.0000\n",
      "Epoch 1792/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.0815 - acc: 0.9778 - val_loss: 0.0841 - val_acc: 1.0000\n",
      "Epoch 1793/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0819 - acc: 0.9704 - val_loss: 0.0852 - val_acc: 1.0000\n",
      "Epoch 1794/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.0817 - acc: 0.9778 - val_loss: 0.0861 - val_acc: 1.0000\n",
      "Epoch 1795/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0813 - acc: 0.9778 - val_loss: 0.0844 - val_acc: 1.0000\n",
      "Epoch 1796/2000\n",
      "135/135 [==============================] - 0s 310us/step - loss: 0.0814 - acc: 0.9778 - val_loss: 0.0841 - val_acc: 1.0000\n",
      "Epoch 1797/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0811 - acc: 0.9852 - val_loss: 0.0811 - val_acc: 1.0000\n",
      "Epoch 1798/2000\n",
      "135/135 [==============================] - 0s 414us/step - loss: 0.0821 - acc: 0.9704 - val_loss: 0.0838 - val_acc: 1.0000\n",
      "Epoch 1799/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.0814 - acc: 0.9778 - val_loss: 0.0847 - val_acc: 1.0000\n",
      "Epoch 1800/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.0812 - acc: 0.9778 - val_loss: 0.0837 - val_acc: 1.0000\n",
      "Epoch 1801/2000\n",
      "135/135 [==============================] - 0s 370us/step - loss: 0.0816 - acc: 0.9778 - val_loss: 0.0821 - val_acc: 1.0000\n",
      "Epoch 1802/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0810 - acc: 0.9778 - val_loss: 0.0839 - val_acc: 1.0000\n",
      "Epoch 1803/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0810 - acc: 0.9778 - val_loss: 0.0850 - val_acc: 1.0000\n",
      "Epoch 1804/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0813 - acc: 0.9778 - val_loss: 0.0831 - val_acc: 1.0000\n",
      "Epoch 1805/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0803 - acc: 0.9778 - val_loss: 0.0826 - val_acc: 1.0000\n",
      "Epoch 1806/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.0808 - acc: 0.9778 - val_loss: 0.0830 - val_acc: 1.0000\n",
      "Epoch 1807/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.0806 - acc: 0.9778 - val_loss: 0.0804 - val_acc: 1.0000\n",
      "Epoch 1808/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0808 - acc: 0.9778 - val_loss: 0.0805 - val_acc: 1.0000\n",
      "Epoch 1809/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0811 - acc: 0.9778 - val_loss: 0.0811 - val_acc: 1.0000\n",
      "Epoch 1810/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.0811 - acc: 0.9778 - val_loss: 0.0810 - val_acc: 1.0000\n",
      "Epoch 1811/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0808 - acc: 0.9704 - val_loss: 0.0841 - val_acc: 1.0000\n",
      "Epoch 1812/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0809 - acc: 0.9778 - val_loss: 0.0847 - val_acc: 1.0000\n",
      "Epoch 1813/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0806 - acc: 0.9778 - val_loss: 0.0846 - val_acc: 1.0000\n",
      "Epoch 1814/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.0809 - acc: 0.9778 - val_loss: 0.0860 - val_acc: 1.0000\n",
      "Epoch 1815/2000\n",
      "135/135 [==============================] - 0s 318us/step - loss: 0.0807 - acc: 0.9778 - val_loss: 0.0850 - val_acc: 1.0000\n",
      "Epoch 1816/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0806 - acc: 0.9778 - val_loss: 0.0814 - val_acc: 1.0000\n",
      "Epoch 1817/2000\n",
      "135/135 [==============================] - 0s 318us/step - loss: 0.0807 - acc: 0.9778 - val_loss: 0.0812 - val_acc: 1.0000\n",
      "Epoch 1818/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0802 - acc: 0.9778 - val_loss: 0.0839 - val_acc: 1.0000\n",
      "Epoch 1819/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0801 - acc: 0.9852 - val_loss: 0.0803 - val_acc: 1.0000\n",
      "Epoch 1820/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.0805 - acc: 0.9704 - val_loss: 0.0816 - val_acc: 1.0000\n",
      "Epoch 1821/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.0804 - acc: 0.9778 - val_loss: 0.0819 - val_acc: 1.0000\n",
      "Epoch 1822/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.0806 - acc: 0.9778 - val_loss: 0.0811 - val_acc: 1.0000\n",
      "Epoch 1823/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0803 - acc: 0.9778 - val_loss: 0.0827 - val_acc: 1.0000\n",
      "Epoch 1824/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0802 - acc: 0.9778 - val_loss: 0.0827 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1825/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.0808 - acc: 0.9778 - val_loss: 0.0826 - val_acc: 1.0000\n",
      "Epoch 1826/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 0.0800 - acc: 0.9852 - val_loss: 0.0804 - val_acc: 1.0000\n",
      "Epoch 1827/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0804 - acc: 0.9778 - val_loss: 0.0807 - val_acc: 1.0000\n",
      "Epoch 1828/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0804 - acc: 0.9778 - val_loss: 0.0798 - val_acc: 1.0000\n",
      "Epoch 1829/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0805 - acc: 0.9778 - val_loss: 0.0800 - val_acc: 1.0000\n",
      "Epoch 1830/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.0804 - acc: 0.9704 - val_loss: 0.0804 - val_acc: 1.0000\n",
      "Epoch 1831/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0801 - acc: 0.9778 - val_loss: 0.0802 - val_acc: 1.0000\n",
      "Epoch 1832/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0802 - acc: 0.9778 - val_loss: 0.0804 - val_acc: 1.0000\n",
      "Epoch 1833/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0803 - acc: 0.9704 - val_loss: 0.0813 - val_acc: 1.0000\n",
      "Epoch 1834/2000\n",
      "135/135 [==============================] - 0s 510us/step - loss: 0.0797 - acc: 0.9778 - val_loss: 0.0809 - val_acc: 1.0000\n",
      "Epoch 1835/2000\n",
      "135/135 [==============================] - 0s 375us/step - loss: 0.0802 - acc: 0.9704 - val_loss: 0.0812 - val_acc: 1.0000\n",
      "Epoch 1836/2000\n",
      "135/135 [==============================] - 0s 364us/step - loss: 0.0798 - acc: 0.9778 - val_loss: 0.0808 - val_acc: 1.0000\n",
      "Epoch 1837/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0801 - acc: 0.9852 - val_loss: 0.0789 - val_acc: 1.0000\n",
      "Epoch 1838/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0797 - acc: 0.9778 - val_loss: 0.0803 - val_acc: 1.0000\n",
      "Epoch 1839/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0796 - acc: 0.9704 - val_loss: 0.0804 - val_acc: 1.0000\n",
      "Epoch 1840/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 0.0800 - acc: 0.9778 - val_loss: 0.0805 - val_acc: 1.0000\n",
      "Epoch 1841/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0798 - acc: 0.9778 - val_loss: 0.0805 - val_acc: 1.0000\n",
      "Epoch 1842/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0797 - acc: 0.9778 - val_loss: 0.0798 - val_acc: 1.0000\n",
      "Epoch 1843/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0798 - acc: 0.9778 - val_loss: 0.0793 - val_acc: 1.0000\n",
      "Epoch 1844/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0795 - acc: 0.9778 - val_loss: 0.0802 - val_acc: 1.0000\n",
      "Epoch 1845/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0796 - acc: 0.9778 - val_loss: 0.0815 - val_acc: 1.0000\n",
      "Epoch 1846/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0803 - acc: 0.9778 - val_loss: 0.0796 - val_acc: 1.0000\n",
      "Epoch 1847/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0798 - acc: 0.9778 - val_loss: 0.0800 - val_acc: 1.0000\n",
      "Epoch 1848/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0796 - acc: 0.9778 - val_loss: 0.0789 - val_acc: 1.0000\n",
      "Epoch 1849/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0796 - acc: 0.9704 - val_loss: 0.0808 - val_acc: 1.0000\n",
      "Epoch 1850/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0791 - acc: 0.9778 - val_loss: 0.0800 - val_acc: 1.0000\n",
      "Epoch 1851/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0794 - acc: 0.9778 - val_loss: 0.0810 - val_acc: 1.0000\n",
      "Epoch 1852/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0797 - acc: 0.9778 - val_loss: 0.0792 - val_acc: 1.0000\n",
      "Epoch 1853/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.0795 - acc: 0.9778 - val_loss: 0.0798 - val_acc: 1.0000\n",
      "Epoch 1854/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0791 - acc: 0.9778 - val_loss: 0.0790 - val_acc: 1.0000\n",
      "Epoch 1855/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0795 - acc: 0.9704 - val_loss: 0.0793 - val_acc: 1.0000\n",
      "Epoch 1856/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0791 - acc: 0.9778 - val_loss: 0.0792 - val_acc: 1.0000\n",
      "Epoch 1857/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0796 - acc: 0.9704 - val_loss: 0.0783 - val_acc: 1.0000\n",
      "Epoch 1858/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.0790 - acc: 0.9778 - val_loss: 0.0776 - val_acc: 1.0000\n",
      "Epoch 1859/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.0790 - acc: 0.9704 - val_loss: 0.0788 - val_acc: 1.0000\n",
      "Epoch 1860/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.0790 - acc: 0.9778 - val_loss: 0.0784 - val_acc: 1.0000\n",
      "Epoch 1861/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.0791 - acc: 0.9778 - val_loss: 0.0786 - val_acc: 1.0000\n",
      "Epoch 1862/2000\n",
      "135/135 [==============================] - 0s 318us/step - loss: 0.0792 - acc: 0.9778 - val_loss: 0.0783 - val_acc: 1.0000\n",
      "Epoch 1863/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0791 - acc: 0.9778 - val_loss: 0.0803 - val_acc: 1.0000\n",
      "Epoch 1864/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.0787 - acc: 0.9778 - val_loss: 0.0826 - val_acc: 1.0000\n",
      "Epoch 1865/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0793 - acc: 0.9778 - val_loss: 0.0821 - val_acc: 1.0000\n",
      "Epoch 1866/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0792 - acc: 0.9778 - val_loss: 0.0821 - val_acc: 1.0000\n",
      "Epoch 1867/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0788 - acc: 0.9704 - val_loss: 0.0833 - val_acc: 1.0000\n",
      "Epoch 1868/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0791 - acc: 0.9778 - val_loss: 0.0813 - val_acc: 1.0000\n",
      "Epoch 1869/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.0792 - acc: 0.9778 - val_loss: 0.0803 - val_acc: 1.0000\n",
      "Epoch 1870/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0785 - acc: 0.9778 - val_loss: 0.0793 - val_acc: 1.0000\n",
      "Epoch 1871/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0789 - acc: 0.9704 - val_loss: 0.0802 - val_acc: 1.0000\n",
      "Epoch 1872/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.0787 - acc: 0.9704 - val_loss: 0.0812 - val_acc: 1.0000\n",
      "Epoch 1873/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0787 - acc: 0.9778 - val_loss: 0.0800 - val_acc: 1.0000\n",
      "Epoch 1874/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0787 - acc: 0.9778 - val_loss: 0.0791 - val_acc: 1.0000\n",
      "Epoch 1875/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 0.0788 - acc: 0.9778 - val_loss: 0.0791 - val_acc: 1.0000\n",
      "Epoch 1876/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.0785 - acc: 0.9778 - val_loss: 0.0774 - val_acc: 1.0000\n",
      "Epoch 1877/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.0785 - acc: 0.9778 - val_loss: 0.0784 - val_acc: 1.0000\n",
      "Epoch 1878/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0785 - acc: 0.9778 - val_loss: 0.0787 - val_acc: 1.0000\n",
      "Epoch 1879/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.0785 - acc: 0.9778 - val_loss: 0.0787 - val_acc: 1.0000\n",
      "Epoch 1880/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0784 - acc: 0.9704 - val_loss: 0.0805 - val_acc: 1.0000\n",
      "Epoch 1881/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.0782 - acc: 0.9778 - val_loss: 0.0789 - val_acc: 1.0000\n",
      "Epoch 1882/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0787 - acc: 0.9778 - val_loss: 0.0796 - val_acc: 1.0000\n",
      "Epoch 1883/2000\n",
      "135/135 [==============================] - 0s 318us/step - loss: 0.0781 - acc: 0.9778 - val_loss: 0.0814 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1884/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0786 - acc: 0.9778 - val_loss: 0.0796 - val_acc: 1.0000\n",
      "Epoch 1885/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 0.0784 - acc: 0.9778 - val_loss: 0.0792 - val_acc: 1.0000\n",
      "Epoch 1886/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0781 - acc: 0.9704 - val_loss: 0.0817 - val_acc: 1.0000\n",
      "Epoch 1887/2000\n",
      "135/135 [==============================] - 0s 343us/step - loss: 0.0785 - acc: 0.9778 - val_loss: 0.0810 - val_acc: 1.0000\n",
      "Epoch 1888/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0786 - acc: 0.9778 - val_loss: 0.0811 - val_acc: 1.0000\n",
      "Epoch 1889/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0784 - acc: 0.9778 - val_loss: 0.0801 - val_acc: 1.0000\n",
      "Epoch 1890/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0780 - acc: 0.9778 - val_loss: 0.0806 - val_acc: 1.0000\n",
      "Epoch 1891/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0781 - acc: 0.9778 - val_loss: 0.0821 - val_acc: 1.0000\n",
      "Epoch 1892/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0780 - acc: 0.9704 - val_loss: 0.0835 - val_acc: 1.0000\n",
      "Epoch 1893/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0783 - acc: 0.9778 - val_loss: 0.0826 - val_acc: 1.0000\n",
      "Epoch 1894/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0784 - acc: 0.9778 - val_loss: 0.0827 - val_acc: 1.0000\n",
      "Epoch 1895/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0779 - acc: 0.9778 - val_loss: 0.0819 - val_acc: 1.0000\n",
      "Epoch 1896/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0778 - acc: 0.9778 - val_loss: 0.0809 - val_acc: 1.0000\n",
      "Epoch 1897/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0779 - acc: 0.9778 - val_loss: 0.0794 - val_acc: 1.0000\n",
      "Epoch 1898/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0779 - acc: 0.9778 - val_loss: 0.0809 - val_acc: 1.0000\n",
      "Epoch 1899/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0782 - acc: 0.9778 - val_loss: 0.0812 - val_acc: 1.0000\n",
      "Epoch 1900/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0781 - acc: 0.9778 - val_loss: 0.0799 - val_acc: 1.0000\n",
      "Epoch 1901/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0781 - acc: 0.9778 - val_loss: 0.0800 - val_acc: 1.0000\n",
      "Epoch 1902/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0781 - acc: 0.9704 - val_loss: 0.0813 - val_acc: 1.0000\n",
      "Epoch 1903/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0779 - acc: 0.9778 - val_loss: 0.0822 - val_acc: 1.0000\n",
      "Epoch 1904/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0776 - acc: 0.9778 - val_loss: 0.0811 - val_acc: 1.0000\n",
      "Epoch 1905/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0776 - acc: 0.9778 - val_loss: 0.0801 - val_acc: 1.0000\n",
      "Epoch 1906/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0774 - acc: 0.9852 - val_loss: 0.0780 - val_acc: 1.0000\n",
      "Epoch 1907/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0777 - acc: 0.9704 - val_loss: 0.0790 - val_acc: 1.0000\n",
      "Epoch 1908/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0779 - acc: 0.9704 - val_loss: 0.0806 - val_acc: 1.0000\n",
      "Epoch 1909/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.0781 - acc: 0.9778 - val_loss: 0.0789 - val_acc: 1.0000\n",
      "Epoch 1910/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0774 - acc: 0.9778 - val_loss: 0.0763 - val_acc: 1.0000\n",
      "Epoch 1911/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0777 - acc: 0.9778 - val_loss: 0.0771 - val_acc: 1.0000\n",
      "Epoch 1912/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.0777 - acc: 0.9704 - val_loss: 0.0785 - val_acc: 1.0000\n",
      "Epoch 1913/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.0776 - acc: 0.9704 - val_loss: 0.0798 - val_acc: 1.0000\n",
      "Epoch 1914/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0775 - acc: 0.9778 - val_loss: 0.0805 - val_acc: 1.0000\n",
      "Epoch 1915/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0772 - acc: 0.9852 - val_loss: 0.0768 - val_acc: 1.0000\n",
      "Epoch 1916/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.0777 - acc: 0.9778 - val_loss: 0.0776 - val_acc: 1.0000\n",
      "Epoch 1917/2000\n",
      "135/135 [==============================] - 0s 406us/step - loss: 0.0775 - acc: 0.9778 - val_loss: 0.0783 - val_acc: 1.0000\n",
      "Epoch 1918/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0772 - acc: 0.9778 - val_loss: 0.0782 - val_acc: 1.0000\n",
      "Epoch 1919/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.0772 - acc: 0.9778 - val_loss: 0.0764 - val_acc: 1.0000\n",
      "Epoch 1920/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0774 - acc: 0.9778 - val_loss: 0.0786 - val_acc: 1.0000\n",
      "Epoch 1921/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0774 - acc: 0.9778 - val_loss: 0.0780 - val_acc: 1.0000\n",
      "Epoch 1922/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.0772 - acc: 0.9778 - val_loss: 0.0780 - val_acc: 1.0000\n",
      "Epoch 1923/2000\n",
      "135/135 [==============================] - 0s 384us/step - loss: 0.0774 - acc: 0.9778 - val_loss: 0.0785 - val_acc: 1.0000\n",
      "Epoch 1924/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.0774 - acc: 0.9778 - val_loss: 0.0778 - val_acc: 1.0000\n",
      "Epoch 1925/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 0.0771 - acc: 0.9778 - val_loss: 0.0795 - val_acc: 1.0000\n",
      "Epoch 1926/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0771 - acc: 0.9778 - val_loss: 0.0779 - val_acc: 1.0000\n",
      "Epoch 1927/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0773 - acc: 0.9778 - val_loss: 0.0770 - val_acc: 1.0000\n",
      "Epoch 1928/2000\n",
      "135/135 [==============================] - 0s 310us/step - loss: 0.0772 - acc: 0.9704 - val_loss: 0.0776 - val_acc: 1.0000\n",
      "Epoch 1929/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0769 - acc: 0.9630 - val_loss: 0.0794 - val_acc: 1.0000\n",
      "Epoch 1930/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0773 - acc: 0.9778 - val_loss: 0.0790 - val_acc: 1.0000\n",
      "Epoch 1931/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0772 - acc: 0.9778 - val_loss: 0.0766 - val_acc: 1.0000\n",
      "Epoch 1932/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 0.0769 - acc: 0.9778 - val_loss: 0.0752 - val_acc: 1.0000\n",
      "Epoch 1933/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.0771 - acc: 0.9704 - val_loss: 0.0769 - val_acc: 1.0000\n",
      "Epoch 1934/2000\n",
      "135/135 [==============================] - 0s 451us/step - loss: 0.0766 - acc: 0.9778 - val_loss: 0.0763 - val_acc: 1.0000\n",
      "Epoch 1935/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0768 - acc: 0.9778 - val_loss: 0.0776 - val_acc: 1.0000\n",
      "Epoch 1936/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0768 - acc: 0.9778 - val_loss: 0.0789 - val_acc: 1.0000\n",
      "Epoch 1937/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0767 - acc: 0.9778 - val_loss: 0.0773 - val_acc: 1.0000\n",
      "Epoch 1938/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.0769 - acc: 0.9778 - val_loss: 0.0780 - val_acc: 1.0000\n",
      "Epoch 1939/2000\n",
      "135/135 [==============================] - 0s 406us/step - loss: 0.0767 - acc: 0.9778 - val_loss: 0.0792 - val_acc: 1.0000\n",
      "Epoch 1940/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0768 - acc: 0.9778 - val_loss: 0.0778 - val_acc: 1.0000\n",
      "Epoch 1941/2000\n",
      "135/135 [==============================] - 0s 318us/step - loss: 0.0768 - acc: 0.9778 - val_loss: 0.0777 - val_acc: 1.0000\n",
      "Epoch 1942/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0766 - acc: 0.9778 - val_loss: 0.0789 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1943/2000\n",
      "135/135 [==============================] - 0s 399us/step - loss: 0.0768 - acc: 0.9778 - val_loss: 0.0776 - val_acc: 1.0000\n",
      "Epoch 1944/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0765 - acc: 0.9778 - val_loss: 0.0769 - val_acc: 1.0000\n",
      "Epoch 1945/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0767 - acc: 0.9778 - val_loss: 0.0760 - val_acc: 1.0000\n",
      "Epoch 1946/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 0.0768 - acc: 0.9778 - val_loss: 0.0756 - val_acc: 1.0000\n",
      "Epoch 1947/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0765 - acc: 0.9778 - val_loss: 0.0774 - val_acc: 1.0000\n",
      "Epoch 1948/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.0767 - acc: 0.9778 - val_loss: 0.0779 - val_acc: 1.0000\n",
      "Epoch 1949/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0762 - acc: 0.9778 - val_loss: 0.0760 - val_acc: 1.0000\n",
      "Epoch 1950/2000\n",
      "135/135 [==============================] - 0s 392us/step - loss: 0.0765 - acc: 0.9778 - val_loss: 0.0766 - val_acc: 1.0000\n",
      "Epoch 1951/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0760 - acc: 0.9778 - val_loss: 0.0763 - val_acc: 1.0000\n",
      "Epoch 1952/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0765 - acc: 0.9778 - val_loss: 0.0777 - val_acc: 1.0000\n",
      "Epoch 1953/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0764 - acc: 0.9778 - val_loss: 0.0784 - val_acc: 1.0000\n",
      "Epoch 1954/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0763 - acc: 0.9778 - val_loss: 0.0788 - val_acc: 1.0000\n",
      "Epoch 1955/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0765 - acc: 0.9778 - val_loss: 0.0777 - val_acc: 1.0000\n",
      "Epoch 1956/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0763 - acc: 0.9704 - val_loss: 0.0793 - val_acc: 1.0000\n",
      "Epoch 1957/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0764 - acc: 0.9778 - val_loss: 0.0804 - val_acc: 1.0000\n",
      "Epoch 1958/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0760 - acc: 0.9778 - val_loss: 0.0779 - val_acc: 1.0000\n",
      "Epoch 1959/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0767 - acc: 0.9778 - val_loss: 0.0768 - val_acc: 1.0000\n",
      "Epoch 1960/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0760 - acc: 0.9778 - val_loss: 0.0787 - val_acc: 1.0000\n",
      "Epoch 1961/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.0758 - acc: 0.9778 - val_loss: 0.0775 - val_acc: 1.0000\n",
      "Epoch 1962/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0760 - acc: 0.9704 - val_loss: 0.0792 - val_acc: 1.0000\n",
      "Epoch 1963/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0761 - acc: 0.9704 - val_loss: 0.0805 - val_acc: 1.0000\n",
      "Epoch 1964/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0761 - acc: 0.9778 - val_loss: 0.0792 - val_acc: 1.0000\n",
      "Epoch 1965/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0757 - acc: 0.9778 - val_loss: 0.0788 - val_acc: 1.0000\n",
      "Epoch 1966/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0762 - acc: 0.9778 - val_loss: 0.0785 - val_acc: 1.0000\n",
      "Epoch 1967/2000\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.0759 - acc: 0.9778 - val_loss: 0.0778 - val_acc: 1.0000\n",
      "Epoch 1968/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0762 - acc: 0.9778 - val_loss: 0.0772 - val_acc: 1.0000\n",
      "Epoch 1969/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0759 - acc: 0.9778 - val_loss: 0.0750 - val_acc: 1.0000\n",
      "Epoch 1970/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0759 - acc: 0.9778 - val_loss: 0.0747 - val_acc: 1.0000\n",
      "Epoch 1971/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0759 - acc: 0.9778 - val_loss: 0.0749 - val_acc: 1.0000\n",
      "Epoch 1972/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0759 - acc: 0.9778 - val_loss: 0.0773 - val_acc: 1.0000\n",
      "Epoch 1973/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0760 - acc: 0.9778 - val_loss: 0.0782 - val_acc: 1.0000\n",
      "Epoch 1974/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.0757 - acc: 0.9778 - val_loss: 0.0782 - val_acc: 1.0000\n",
      "Epoch 1975/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0757 - acc: 0.9852 - val_loss: 0.0764 - val_acc: 1.0000\n",
      "Epoch 1976/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0760 - acc: 0.9778 - val_loss: 0.0760 - val_acc: 1.0000\n",
      "Epoch 1977/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0757 - acc: 0.9778 - val_loss: 0.0756 - val_acc: 1.0000\n",
      "Epoch 1978/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0760 - acc: 0.9704 - val_loss: 0.0778 - val_acc: 1.0000\n",
      "Epoch 1979/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0757 - acc: 0.9778 - val_loss: 0.0765 - val_acc: 1.0000\n",
      "Epoch 1980/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0756 - acc: 0.9778 - val_loss: 0.0779 - val_acc: 1.0000\n",
      "Epoch 1981/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0756 - acc: 0.9778 - val_loss: 0.0791 - val_acc: 1.0000\n",
      "Epoch 1982/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0757 - acc: 0.9778 - val_loss: 0.0770 - val_acc: 1.0000\n",
      "Epoch 1983/2000\n",
      "135/135 [==============================] - 0s 333us/step - loss: 0.0756 - acc: 0.9778 - val_loss: 0.0743 - val_acc: 1.0000\n",
      "Epoch 1984/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0755 - acc: 0.9704 - val_loss: 0.0764 - val_acc: 1.0000\n",
      "Epoch 1985/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0755 - acc: 0.9778 - val_loss: 0.0767 - val_acc: 1.0000\n",
      "Epoch 1986/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0752 - acc: 0.9778 - val_loss: 0.0771 - val_acc: 1.0000\n",
      "Epoch 1987/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.0755 - acc: 0.9778 - val_loss: 0.0772 - val_acc: 1.0000\n",
      "Epoch 1988/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.0753 - acc: 0.9778 - val_loss: 0.0753 - val_acc: 1.0000\n",
      "Epoch 1989/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0754 - acc: 0.9704 - val_loss: 0.0790 - val_acc: 1.0000\n",
      "Epoch 1990/2000\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.0754 - acc: 0.9852 - val_loss: 0.0764 - val_acc: 1.0000\n",
      "Epoch 1991/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0754 - acc: 0.9778 - val_loss: 0.0768 - val_acc: 1.0000\n",
      "Epoch 1992/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0754 - acc: 0.9778 - val_loss: 0.0752 - val_acc: 1.0000\n",
      "Epoch 1993/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0754 - acc: 0.9852 - val_loss: 0.0730 - val_acc: 1.0000\n",
      "Epoch 1994/2000\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.0751 - acc: 0.9778 - val_loss: 0.0731 - val_acc: 1.0000\n",
      "Epoch 1995/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0753 - acc: 0.9778 - val_loss: 0.0750 - val_acc: 1.0000\n",
      "Epoch 1996/2000\n",
      "135/135 [==============================] - 0s 377us/step - loss: 0.0753 - acc: 0.9778 - val_loss: 0.0775 - val_acc: 1.0000\n",
      "Epoch 1997/2000\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.0752 - acc: 0.9778 - val_loss: 0.0778 - val_acc: 1.0000\n",
      "Epoch 1998/2000\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.0752 - acc: 0.9778 - val_loss: 0.0786 - val_acc: 1.0000\n",
      "Epoch 1999/2000\n",
      "135/135 [==============================] - 0s 362us/step - loss: 0.0750 - acc: 0.9704 - val_loss: 0.0801 - val_acc: 1.0000\n",
      "Epoch 2000/2000\n",
      "135/135 [==============================] - 0s 369us/step - loss: 0.0750 - acc: 0.9852 - val_loss: 0.0784 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "hist=model.fit(X,Y, validation_split=0.10, epochs=2000, batch_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trained _fit_ method returns to us a history object with a summary of what happened throughout the training period. We will use this object in the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Model Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now that we have a trained model we will usually want to look at the training curves: the loss as a function of the epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'], label='Training Loss')\n",
    "plt.plot(hist.history['val_loss'], label='Validation Loss')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With some luck you should see a nice easy decline in the loss. The validation (testing) loss should stay above the training loss; the model is minimizing the training loss, the validation loss going down is a side effect of this.\n",
    "\n",
    "If you let your model train for long enough you might also start to see overfitting, if your model is large enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good way to do testing is to use K-fold cross validation. You divide your data set into K equal parts, and then grab the first part and make it your testing set, and train on the other K-1 parts. You then record whatever testing metric you want to keep track of (generally the accuracy). Then you go back and pick the second of the K parts to be the testing and re-train a brand new (unoptimized weights) model with the K-1 parts, record the metric. You repeat until you've picked each of the K parts to be the testing set once.\n",
    "\n",
    "What this will do is simulate how well the model: optimizes (since you'll have to optimize K times), and generalizes (since the training and testing data are always changing.)\n",
    "\n",
    "A common K to pick is 10, ie 10-fold cross validation.\n",
    "\n",
    "An important detail is that you want the testing set to replicate the same distribution of labels as the training set. This is called stratefied K-fold cross validation. If your data has 50:50 split between labels, then should your training set. So it's not enough to pick random splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should implement a 5-fold cross validation. Don't worry about it being stratefied for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "So now we've done all this work... but did it answer our original question? For this data set it should be fairly easy to construct something that generalizes okay-ish to our testing set, but maybe we want to push higher accuracy? At this point we might want to go back to step 1 and make new plots if something else has ocurred to us. Or maybe we will want to clea up the data differently (maybe whiten it this time? how big of an impact will that make?). What if we add more hidden layers? or less? More neurons or less neurons? Should we add regularization? And then obviously we need to rigorously test all this to make sure it is making sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play around!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
